{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The HEAL Platform \u00b6 The HEAL Platform is a cloud-based and multifunctional web interface that provides a secure environment for discovery and analysis of NIH HEAL results and data. It is designed to serve users with a variety of objectives, backgrounds, and specialties. The HEAL Platform represents a dynamic Data Ecosystem that aggregates and presents data from multiple resources to make data discovery and access easy for users. The platform provides a way to search and query over study metadata and diverse data types, generated by different projects and organizations and stored across multiple secure repositories. The HEAL Platform also offers a secure and cost-effective cloud-computing environment for data analysis, empowering collaborative research and development of new analytical tools. New workflows and results of analyses can be shared with the HEAL community to enable collaborative, high-impact publications that address the opioid crisis. The HEAL Platform is powered by the open-source software \u201cGen3\u201d . Gen3 was created by and is actively developed at the University of Chicago\u2019s Center for Translational Data Science (CTDS) with the aim of creating interoperable cloud-based data resources for the scientific research community. HEAL Example Analyses \u00b6 The Jupyter notebooks contained in this notebook viewer pull data from various sources to generate and output useful tables, charts, graphs, and models. Each notebook is static, meaning the data being used by the notebooks is not updated in real time. Most of these notebooks are also available in the Gen3 Tutorials Workspace. Please note these notebooks are meant for illustrative purposes only, and are not meant to portray peer-reviewed research. Powered by","title":"Home"},{"location":"#the-heal-platform","text":"The HEAL Platform is a cloud-based and multifunctional web interface that provides a secure environment for discovery and analysis of NIH HEAL results and data. It is designed to serve users with a variety of objectives, backgrounds, and specialties. The HEAL Platform represents a dynamic Data Ecosystem that aggregates and presents data from multiple resources to make data discovery and access easy for users. The platform provides a way to search and query over study metadata and diverse data types, generated by different projects and organizations and stored across multiple secure repositories. The HEAL Platform also offers a secure and cost-effective cloud-computing environment for data analysis, empowering collaborative research and development of new analytical tools. New workflows and results of analyses can be shared with the HEAL community to enable collaborative, high-impact publications that address the opioid crisis. The HEAL Platform is powered by the open-source software \u201cGen3\u201d . Gen3 was created by and is actively developed at the University of Chicago\u2019s Center for Translational Data Science (CTDS) with the aim of creating interoperable cloud-based data resources for the scientific research community.","title":"The HEAL Platform"},{"location":"#heal-example-analyses","text":"The Jupyter notebooks contained in this notebook viewer pull data from various sources to generate and output useful tables, charts, graphs, and models. Each notebook is static, meaning the data being used by the notebooks is not updated in real time. Most of these notebooks are also available in the Gen3 Tutorials Workspace. Please note these notebooks are meant for illustrative purposes only, and are not meant to portray peer-reviewed research. Powered by","title":"HEAL Example Analyses"},{"location":"contact/","text":"Contact \u00b6 Need help? Please contact our help desk . Powered by","title":"Contact"},{"location":"contact/#contact","text":"Need help? Please contact our help desk . Powered by","title":"Contact"},{"location":"faq/","text":"FAQs \u00b6 How can I access the data used in these analyses? The HEAL Platform Documentation has information on how you can discover shared data through the HEAL Discovery Page , and how you can request access to a study . How can I work with the data in HEAL Workspaces? The HEAL Workspaces documentation has information on how you may access and use HEAL Workspaces. Can I share a notebook that my team has developed for analyzing data accessed through the HEAL Data Platform? Yes! We encourage investigators (and their students & trainees!) to share materials they've developed through the secondary use of HEAL data. Whether it's replicating published results, combining data from multiple studies, or extending analyses, we would be glad to share those notebooks on the HEAL Data Platform and credit your team. If you have a notebook you'd like to share, please email us at heal-support@gen3.org .","title":"FAQs"},{"location":"faq/#faqs","text":"How can I access the data used in these analyses? The HEAL Platform Documentation has information on how you can discover shared data through the HEAL Discovery Page , and how you can request access to a study . How can I work with the data in HEAL Workspaces? The HEAL Workspaces documentation has information on how you may access and use HEAL Workspaces. Can I share a notebook that my team has developed for analyzing data accessed through the HEAL Data Platform? Yes! We encourage investigators (and their students & trainees!) to share materials they've developed through the secondary use of HEAL data. Whether it's replicating published results, combining data from multiple studies, or extending analyses, we would be glad to share those notebooks on the HEAL Data Platform and credit your team. If you have a notebook you'd like to share, please email us at heal-support@gen3.org .","title":"FAQs"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/","text":"BACPAC Synthetic Data Analysis \u00b6 Qiong Liu \u00b6 April 2nd, 2021 \u00b6 In this Jupyter notebook, we used the BACPAC study as an example to demonstrate how to navigate datasets within the workspace in HEAL and conduct data analysis using Python libraries. Table of Content \u00b6 Set up notebook Pull file objects using the Gen3 SDK Demographic characteristics of participants in BACPAC Opiod pain medication profiling at two time points Physical function outcomes Set up notebook \u00b6 # Uncomment the line to install python libraries by removing # ! pip install kaleido == 0.2.1 - q import pandas as pd import kaleido import plotly import plotly.graph_objects as go import plotly.express as px from plotly.subplots import make_subplots import plotly.io as pio from pathlib import Path import numpy as np import json import requests import os plotly . offline . init_notebook_mode () from IPython.display import Markdown , Image , display os . makedirs ( 'img/BACPAC_Synthetic_Data_Analysis' ) Query study metadata \u00b6 Users can query study metadata in HEAL data commons using our metadata service (MDS). The cell below shows how to retrieve the metadata of the BACPAC study by interacting with the gen3 MDS endpoint. # Query the metadata of BACPAC using the project number \"1U24AR076730-01\" response = requests . get ( \"https://healdata.org/mds/metadata?data=True&limit=1000&gen3_discovery.project_number=1U24AR076730-01\" ) metadata_text = response . text metadata_object = json . loads ( metadata_text ) meta_df = pd . json_normalize ([ sub [ 'gen3_discovery' ] for sub in metadata_object . values () if 'gen3_discovery' in sub . keys ()]) Markdown ( meta_df [[ 'research_focus_area' , 'study_metadata.minimal_info.study_description' , 'institutions' ]] . transpose () . to_markdown ()) 0 research_focus_area Clinical Research in Pain Management study_metadata.minimal_info.study_description The BACPAC Research Programs Data Integration, Algorithm Development, and Operations Management Center (DAC) will bring cohesion to research performed by the participating Mechanistic Research Centers, Technology Research Sites, and Phase 2 Clinical Trials Centers. DAC Investigators will share their vision and provide scientific leadership and organizational support to the BACPAC Consortium. The research plan consists of supporting design and conduct of clinical trials with precision interventions that focus on identifying the best treatments for individual patients. The DAC will enhance collaboration and research progress with experienced leadership, innovative design and analysis methodologies, comprehensive research operations support, a state-of-the-art data management and integration system, and superior administrative support. This integrated structure will set the stage for technology assessments, solicitation of patient input and utilities, and the evaluation of high-impact interventions through the innovative design and sound execution of clinical trials, leading to effective personalized treatment approaches for patients with chronic lower back pain. institutions UNIV OF NORTH CAROLINA CHAPEL HILL Pull file objects using the Gen3 SDK \u00b6 ! gen3 drs - pull object dg . H34L / 80 f0a338 - 18e0 - 48 de - b70f - cdabd63f67d9 ! gen3 drs - pull object dg . H34L / 530 fd95c - 48 b6 - 488 e - a699 - 9377180 bd82d ! gen3 drs - pull object dg . H34L / 654 d7f1f - b61c - 49 a9 - 8 a74 - c82400fa4c27 {\"succeeded\": [\"dg.H34L/80f0a338-18e0-48de-b70f-cdabd63f67d9\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/530fd95c-48b6-488e-a699-9377180bd82d\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/654d7f1f-b61c-49a9-8a74-c82400fa4c27\"], \"failed\": []} Demographic characteristics of participants in BACPAC \u00b6 # Read the demographic tsv file into dataframe demo_bacpac = pd . read_csv ( \"./participant_SMART.tsv\" , sep = \" \\t \" , encoding = \"utf-8\" ) # Define age groups within participants age_list = list ( demo_bacpac [ \"age_in_years\" ]) def age_group ( agelist ): min_age = min ( agelist ) grouplabel1 = str ( min_age ) + \"-55 yr\" grouplabel2 = \">55 yr\" grouplist = [] for i in agelist : if i <= 55 : grouplist . append ( grouplabel1 ) else : grouplist . append ( grouplabel2 ) return grouplist agegrouplist = age_group ( age_list ) demo_bacpac [ \"age_group\" ] = agegrouplist # Compute three frequency tables using demographic factors df1 = pd . crosstab ( index = demo_bacpac [ 'race' ], columns = demo_bacpac [ 'sex' ]) df2 = pd . crosstab ( index = demo_bacpac [ 'ethnicity' ], columns = demo_bacpac [ 'sex' ]) df3 = pd . crosstab ( index = demo_bacpac [ 'age_group' ], columns = demo_bacpac [ 'sex' ]) # Dsiplay concatenated tables Markdown ( pd . concat ([ df1 , df2 , df3 ], keys = [ 'race' , 'ethnicity' , 'age_group' ]) . to_markdown ()) Female Intersex Male Unknown ('race', 'American Indian or Alaska Native') 5 1 3 1 ('race', 'Asian') 2 0 3 0 ('race', 'Black or African American') 9 3 6 2 ('race', 'Multiple') 5 1 4 0 ('race', 'Native Hawaiian or Pacific Islander') 5 0 1 2 ('race', 'Not reported') 4 2 2 1 ('race', 'Unknown') 3 2 3 1 ('race', 'White') 37 4 26 12 ('ethnicity', 'Hispanic or Latino') 18 5 12 6 ('ethnicity', 'Not Hispanic or Latino') 36 4 27 6 ('ethnicity', 'Not reported') 7 1 4 4 ('ethnicity', 'Unknown') 9 3 5 3 ('age_group', '20-55 yr') 42 9 29 14 ('age_group', '>55 yr') 28 4 19 5 # Generate a stacked bar chart of participants in BACPAC new_df2 = pd . DataFrame ( df2 . stack ()) new_df2 . reset_index ( inplace = True ) new_df2 = new_df2 . rename ({ 0 : \"Count\" , \"sex\" : \"Sex\" , \"ethnicity\" : \"Ethnicity\" }, axis = \"columns\" ) fig = go . Figure () fig = px . bar ( new_df2 , x = \"Sex\" , y = \"Count\" , color = \"Ethnicity\" , title = \"Ethnicity and Sex Characteristics of Participants in the BACPAC Study\" , width = 800 , height = 500 ) fig . write_image ( 'img/BACPAC/figure1.png' ) Image ( filename = \"img/BACPAC_Synthetic_Data_Analysis/figure1.png\" ) Opiod pain medication profiling at two time points \u00b6 # Read substance use tsv file into dataframe substance_df = pd . read_csv ( \"./substance_use_SMART.tsv\" , sep = \" \\t \" , encoding = \"utf-8\" ) # Combine substance use df and demographic df based on participant id def find_participant ( mydf , endstr ): participant_id = [] for i in list ( mydf [ \"submitter_id\" ]): i_participant = i . rstrip ( endstr ) participant_id . append ( i_participant ) return participant_id substance_participant_id = find_participant ( substance_df , \"_sc\" ) substance_df [ \"participant_id\" ] = substance_participant_id demo_combine_substance = substance_df . merge ( demo_bacpac , left_on = \"participant_id\" , right_on = \"submitter_id\" , how = \"outer\" ) # Add one property of time point in the df def find_timepoint ( mydf ): timepoint = [] for i in list ( mydf [ \"visits.submitter_id\" ]): if i . endswith ( \"Week 0\" ): timepoint . append ( \"Week 0\" ) else : timepoint . append ( \"Week 12\" ) return timepoint demo_combine_substance [ \"time_point\" ] = find_timepoint ( demo_combine_substance ) # Compute a frequency table using opioid medication factor and time point factor opioid_crosstab = pd . crosstab ( index = demo_combine_substance [ 'OPIOID01' ], columns = demo_combine_substance [ 'time_point' ]) new_opioid = pd . DataFrame ( opioid_crosstab . stack ()) new_opioid . reset_index ( inplace = True ) new_opioid = new_opioid . rename ({ 0 : \"Count\" , \"OPIOID01\" : \"Taking Opioid\" , \"time_point\" : \"Time Point\" }, axis = \"columns\" ) fig2 = go . Figure () fig2 = px . bar ( new_opioid , x = \"Taking Opioid\" , y = \"Count\" , color = \"Taking Opioid\" , facet_row = \"Time Point\" , width = 800 , height = 400 ) fig2 . update_layout ( title_text = \"Self-Report of Opioid Pain Medication Use at Baseline and Twelve Weeks\" , title_font_size = 20 ) for data in fig2 . data : data [ \"width\" ] = 0.6 fig2 . write_image ( 'img/BACPAC_Synthetic_Data_Analysis/figure2.png' ) Image ( filename = \"img/BACPAC_Synthetic_Data_Analysis/figure2.png\" ) We observed an increase of participants taking opioid pain medication at the week 12 time point compared to baseline. # Generate a bar chart showing the opioid taking at two time points in different sex groups opioid_gender = pd . crosstab ( index = [ demo_combine_substance [ 'OPIOID01' ], demo_combine_substance [ 'sex' ]], columns = demo_combine_substance [ 'time_point' ]) new_opioid_gender = pd . DataFrame ( opioid_gender . stack ()) new_opioid_gender . reset_index ( inplace = True ) new_opioid_gender = new_opioid_gender . rename ({ 0 : \"Count\" , \"OPIOID01\" : \"Taking Opioid\" , \"time_point\" : \"Time Point\" , \"sex\" : \"Sex\" }, axis = \"columns\" ) fig3 = go . Figure () fig3 = px . bar ( new_opioid_gender , y = \"Sex\" , x = \"Count\" , color = \"Taking Opioid\" , facet_col = \"Time Point\" , width = 800 , height = 400 , orientation = 'h' , category_orders = { \"Sex\" : [ \"Intersex\" , \"Unknown\" , \"Male\" , \"Female\" ]}) fig3 . update_layout ( title_text = \"Opioid Pain Medication at Two Time Points in Different Sex Groups\" , title_font_size = 20 ) fig3 . write_image ( 'img/BACPAC_Synthetic_Data_Analysis/figure3.png' ) Image ( filename = \"img/BACPAC_Synthetic_Data_Analysis/figure3.png\" ) We observed an increase of particpants taking opioid medication at week 12 in both male and femal groups compared to baseline week 0. Physical function outcomes \u00b6 The cell below uses the Physical Function 6b T-Score to display physical function outcomes in different ethnicity groups at week 0 and week 12. # Read physical_function_SMART.tsv into dataframe and merge the df with demographic function_df = pd . read_csv ( \"./physical_function_SMART.tsv\" , sep = \" \\t \" , encoding = \"utf-16\" ) function_participant_id = find_participant ( function_df , \"_pf\" ) function_df [ \"participant_id\" ] = function_participant_id demo_combine_function = function_df . merge ( demo_bacpac , left_on = \"participant_id\" , right_on = \"submitter_id\" , how = \"outer\" ) demo_combine_function [ \"time_point\" ] = find_timepoint ( demo_combine_function ) # Summary table of ROMIS-Physical Function 6b T-Score in different ethnicity groups ethnicity_PRPF6BT = demo_combine_function [[ \"time_point\" , \"PRPF6BT\" , \"ethnicity\" ]] . groupby ([ 'time_point' , 'ethnicity' ]) . describe () Markdown ( ethnicity_PRPF6BT . to_markdown ()) ('PRPF6BT', 'count') ('PRPF6BT', 'mean') ('PRPF6BT', 'std') ('PRPF6BT', 'min') ('PRPF6BT', '25%') ('PRPF6BT', '50%') ('PRPF6BT', '75%') ('PRPF6BT', 'max') ('Week 0', 'Hispanic or Latino') 41 38.2854 3.16501 32.5 36 38.5 39.3 48.7 ('Week 0', 'Not Hispanic or Latino') 73 37.5411 2.59823 31.5 35.1 37.6 39.3 44.2 ('Week 0', 'Not reported') 16 37.6125 2.93754 33.4 35.1 38.05 40.2 43.1 ('Week 0', 'Unknown') 20 38.195 2.46736 31.5 37.4 38.5 39.3 42.1 ('Week 12', 'Hispanic or Latino') 41 37.5366 3.06299 29.1 35.1 37.6 39.3 43.1 ('Week 12', 'Not Hispanic or Latino') 73 37.589 3.24267 31.5 35.1 37.6 40.2 44.2 ('Week 12', 'Not reported') 16 37.7438 2.74007 33.4 36 36.8 39.525 43.1 ('Week 12', 'Unknown') 20 36.925 3.26366 29.1 35.1 36 38.7 44.2 # Visualize the distribution of Physical Function 6b T-Score # at two time points for hispanic and non-hispanic ethnicity groups fig4 = go . Figure () fig4 = make_subplots ( rows = 2 , cols = 2 , specs = [[{ \"colspan\" : 2 }, None ], [{}, {}]], subplot_titles = ( \"PROMIS-Physical Function 6b T-Score Distribution at Two Time Points\" , \"Hispanic or Latino\" , \"Not Hispanic or Latino\" )) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [ demo_combine_function [ \"time_point\" ] == \"Week 0\" ][ \"PRPF6BT\" ], marker_color = '#EB89B5' , opacity = 0.75 , nbinsx = 20 , name = \"Week 0\" ), row = 1 , col = 1 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [ demo_combine_function [ \"time_point\" ] == \"Week 12\" ][ \"PRPF6BT\" ], marker_color = '#2B6CBE' , opacity = 0.75 , nbinsx = 20 , name = \"Week 12\" ), row = 1 , col = 1 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [( demo_combine_function [ \"time_point\" ] == \"Week 0\" ) & ( demo_combine_function [ \"ethnicity\" ] == \"Hispanic or Latino\" )][ \"PRPF6BT\" ], marker_color = '#EB89B5' , opacity = 0.75 , nbinsx = 20 , showlegend = False ), row = 2 , col = 1 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [( demo_combine_function [ \"time_point\" ] == \"Week 12\" ) & ( demo_combine_function [ \"ethnicity\" ] == \"Hispanic or Latino\" )][ \"PRPF6BT\" ], marker_color = '#2B6CBE' , opacity = 0.75 , nbinsx = 20 , showlegend = False ), row = 2 , col = 1 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [( demo_combine_function [ \"time_point\" ] == \"Week 0\" ) & ( demo_combine_function [ \"ethnicity\" ] == \"Not Hispanic or Latino\" )][ \"PRPF6BT\" ], marker_color = '#EB89B5' , opacity = 0.75 , nbinsx = 20 , showlegend = False ), row = 2 , col = 2 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [( demo_combine_function [ \"time_point\" ] == \"Week 12\" ) & ( demo_combine_function [ \"ethnicity\" ] == \"Not Hispanic or Latino\" )][ \"PRPF6BT\" ], marker_color = '#2B6CBE' , opacity = 0.75 , nbinsx = 20 , showlegend = False ), row = 2 , col = 2 ) fig4 . update_layout ( barmode = 'overlay' , width = 800 , height = 500 , legend_title_text = 'Time Point' ) fig4 . update_layout ( margin = dict ( l = 20 , r = 20 , t = 50 , b = 20 , pad = 2 )) fig4 . update_yaxes ( title_text = \"Count\" , title_font_size = 15 , range = [ 0 , 40 ], row = 1 , col = 1 ) fig4 . update_xaxes ( title_text = \"PROMIS-Physical Function 6b T-Score\" , title_font_size = 15 , range = [ 29 , 49 ], row = 1 , col = 1 ) fig4 . update_yaxes ( title_text = \"Count\" , title_font_size = 15 , range = [ 0 , 15 ], row = 2 , col = 1 ) fig4 . update_xaxes ( title_text = \"PROMIS-Physical Function 6b T-Score\" , title_font_size = 15 , range = [ 29 , 49 ], row = 2 , col = 1 ) fig4 . update_yaxes ( title_text = \"Count\" , title_font_size = 15 , range = [ 0 , 15 ], row = 2 , col = 2 ) fig4 . update_xaxes ( title_text = \"PROMIS-Physical Function 6b T-Score\" , title_font_size = 15 , range = [ 29 , 49 ], row = 2 , col = 2 ) fig4 . write_image ( 'img/BACPAC_Synthetic_Data_Analysis/figure4.png' ) Image ( filename = \"img/BACPAC_Synthetic_Data_Analysis/figure4.png\" )","title":"BACPAC Synthetic Data Analysis"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#bacpac-synthetic-data-analysis","text":"","title":"BACPAC Synthetic Data Analysis"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#qiong-liu","text":"","title":"Qiong Liu"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#april-2nd-2021","text":"In this Jupyter notebook, we used the BACPAC study as an example to demonstrate how to navigate datasets within the workspace in HEAL and conduct data analysis using Python libraries.","title":"April 2nd, 2021"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#table-of-content","text":"Set up notebook Pull file objects using the Gen3 SDK Demographic characteristics of participants in BACPAC Opiod pain medication profiling at two time points Physical function outcomes","title":"Table of Content"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#set-up-notebook","text":"# Uncomment the line to install python libraries by removing # ! pip install kaleido == 0.2.1 - q import pandas as pd import kaleido import plotly import plotly.graph_objects as go import plotly.express as px from plotly.subplots import make_subplots import plotly.io as pio from pathlib import Path import numpy as np import json import requests import os plotly . offline . init_notebook_mode () from IPython.display import Markdown , Image , display os . makedirs ( 'img/BACPAC_Synthetic_Data_Analysis' )","title":"Set up notebook"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#query-study-metadata","text":"Users can query study metadata in HEAL data commons using our metadata service (MDS). The cell below shows how to retrieve the metadata of the BACPAC study by interacting with the gen3 MDS endpoint. # Query the metadata of BACPAC using the project number \"1U24AR076730-01\" response = requests . get ( \"https://healdata.org/mds/metadata?data=True&limit=1000&gen3_discovery.project_number=1U24AR076730-01\" ) metadata_text = response . text metadata_object = json . loads ( metadata_text ) meta_df = pd . json_normalize ([ sub [ 'gen3_discovery' ] for sub in metadata_object . values () if 'gen3_discovery' in sub . keys ()]) Markdown ( meta_df [[ 'research_focus_area' , 'study_metadata.minimal_info.study_description' , 'institutions' ]] . transpose () . to_markdown ()) 0 research_focus_area Clinical Research in Pain Management study_metadata.minimal_info.study_description The BACPAC Research Programs Data Integration, Algorithm Development, and Operations Management Center (DAC) will bring cohesion to research performed by the participating Mechanistic Research Centers, Technology Research Sites, and Phase 2 Clinical Trials Centers. DAC Investigators will share their vision and provide scientific leadership and organizational support to the BACPAC Consortium. The research plan consists of supporting design and conduct of clinical trials with precision interventions that focus on identifying the best treatments for individual patients. The DAC will enhance collaboration and research progress with experienced leadership, innovative design and analysis methodologies, comprehensive research operations support, a state-of-the-art data management and integration system, and superior administrative support. This integrated structure will set the stage for technology assessments, solicitation of patient input and utilities, and the evaluation of high-impact interventions through the innovative design and sound execution of clinical trials, leading to effective personalized treatment approaches for patients with chronic lower back pain. institutions UNIV OF NORTH CAROLINA CHAPEL HILL","title":"Query study metadata"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#pull-file-objects-using-the-gen3-sdk","text":"! gen3 drs - pull object dg . H34L / 80 f0a338 - 18e0 - 48 de - b70f - cdabd63f67d9 ! gen3 drs - pull object dg . H34L / 530 fd95c - 48 b6 - 488 e - a699 - 9377180 bd82d ! gen3 drs - pull object dg . H34L / 654 d7f1f - b61c - 49 a9 - 8 a74 - c82400fa4c27 {\"succeeded\": [\"dg.H34L/80f0a338-18e0-48de-b70f-cdabd63f67d9\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/530fd95c-48b6-488e-a699-9377180bd82d\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/654d7f1f-b61c-49a9-8a74-c82400fa4c27\"], \"failed\": []}","title":"Pull file objects using the Gen3 SDK"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#demographic-characteristics-of-participants-in-bacpac","text":"# Read the demographic tsv file into dataframe demo_bacpac = pd . read_csv ( \"./participant_SMART.tsv\" , sep = \" \\t \" , encoding = \"utf-8\" ) # Define age groups within participants age_list = list ( demo_bacpac [ \"age_in_years\" ]) def age_group ( agelist ): min_age = min ( agelist ) grouplabel1 = str ( min_age ) + \"-55 yr\" grouplabel2 = \">55 yr\" grouplist = [] for i in agelist : if i <= 55 : grouplist . append ( grouplabel1 ) else : grouplist . append ( grouplabel2 ) return grouplist agegrouplist = age_group ( age_list ) demo_bacpac [ \"age_group\" ] = agegrouplist # Compute three frequency tables using demographic factors df1 = pd . crosstab ( index = demo_bacpac [ 'race' ], columns = demo_bacpac [ 'sex' ]) df2 = pd . crosstab ( index = demo_bacpac [ 'ethnicity' ], columns = demo_bacpac [ 'sex' ]) df3 = pd . crosstab ( index = demo_bacpac [ 'age_group' ], columns = demo_bacpac [ 'sex' ]) # Dsiplay concatenated tables Markdown ( pd . concat ([ df1 , df2 , df3 ], keys = [ 'race' , 'ethnicity' , 'age_group' ]) . to_markdown ()) Female Intersex Male Unknown ('race', 'American Indian or Alaska Native') 5 1 3 1 ('race', 'Asian') 2 0 3 0 ('race', 'Black or African American') 9 3 6 2 ('race', 'Multiple') 5 1 4 0 ('race', 'Native Hawaiian or Pacific Islander') 5 0 1 2 ('race', 'Not reported') 4 2 2 1 ('race', 'Unknown') 3 2 3 1 ('race', 'White') 37 4 26 12 ('ethnicity', 'Hispanic or Latino') 18 5 12 6 ('ethnicity', 'Not Hispanic or Latino') 36 4 27 6 ('ethnicity', 'Not reported') 7 1 4 4 ('ethnicity', 'Unknown') 9 3 5 3 ('age_group', '20-55 yr') 42 9 29 14 ('age_group', '>55 yr') 28 4 19 5 # Generate a stacked bar chart of participants in BACPAC new_df2 = pd . DataFrame ( df2 . stack ()) new_df2 . reset_index ( inplace = True ) new_df2 = new_df2 . rename ({ 0 : \"Count\" , \"sex\" : \"Sex\" , \"ethnicity\" : \"Ethnicity\" }, axis = \"columns\" ) fig = go . Figure () fig = px . bar ( new_df2 , x = \"Sex\" , y = \"Count\" , color = \"Ethnicity\" , title = \"Ethnicity and Sex Characteristics of Participants in the BACPAC Study\" , width = 800 , height = 500 ) fig . write_image ( 'img/BACPAC/figure1.png' ) Image ( filename = \"img/BACPAC_Synthetic_Data_Analysis/figure1.png\" )","title":"Demographic characteristics of participants in BACPAC"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#opiod-pain-medication-profiling-at-two-time-points","text":"# Read substance use tsv file into dataframe substance_df = pd . read_csv ( \"./substance_use_SMART.tsv\" , sep = \" \\t \" , encoding = \"utf-8\" ) # Combine substance use df and demographic df based on participant id def find_participant ( mydf , endstr ): participant_id = [] for i in list ( mydf [ \"submitter_id\" ]): i_participant = i . rstrip ( endstr ) participant_id . append ( i_participant ) return participant_id substance_participant_id = find_participant ( substance_df , \"_sc\" ) substance_df [ \"participant_id\" ] = substance_participant_id demo_combine_substance = substance_df . merge ( demo_bacpac , left_on = \"participant_id\" , right_on = \"submitter_id\" , how = \"outer\" ) # Add one property of time point in the df def find_timepoint ( mydf ): timepoint = [] for i in list ( mydf [ \"visits.submitter_id\" ]): if i . endswith ( \"Week 0\" ): timepoint . append ( \"Week 0\" ) else : timepoint . append ( \"Week 12\" ) return timepoint demo_combine_substance [ \"time_point\" ] = find_timepoint ( demo_combine_substance ) # Compute a frequency table using opioid medication factor and time point factor opioid_crosstab = pd . crosstab ( index = demo_combine_substance [ 'OPIOID01' ], columns = demo_combine_substance [ 'time_point' ]) new_opioid = pd . DataFrame ( opioid_crosstab . stack ()) new_opioid . reset_index ( inplace = True ) new_opioid = new_opioid . rename ({ 0 : \"Count\" , \"OPIOID01\" : \"Taking Opioid\" , \"time_point\" : \"Time Point\" }, axis = \"columns\" ) fig2 = go . Figure () fig2 = px . bar ( new_opioid , x = \"Taking Opioid\" , y = \"Count\" , color = \"Taking Opioid\" , facet_row = \"Time Point\" , width = 800 , height = 400 ) fig2 . update_layout ( title_text = \"Self-Report of Opioid Pain Medication Use at Baseline and Twelve Weeks\" , title_font_size = 20 ) for data in fig2 . data : data [ \"width\" ] = 0.6 fig2 . write_image ( 'img/BACPAC_Synthetic_Data_Analysis/figure2.png' ) Image ( filename = \"img/BACPAC_Synthetic_Data_Analysis/figure2.png\" ) We observed an increase of participants taking opioid pain medication at the week 12 time point compared to baseline. # Generate a bar chart showing the opioid taking at two time points in different sex groups opioid_gender = pd . crosstab ( index = [ demo_combine_substance [ 'OPIOID01' ], demo_combine_substance [ 'sex' ]], columns = demo_combine_substance [ 'time_point' ]) new_opioid_gender = pd . DataFrame ( opioid_gender . stack ()) new_opioid_gender . reset_index ( inplace = True ) new_opioid_gender = new_opioid_gender . rename ({ 0 : \"Count\" , \"OPIOID01\" : \"Taking Opioid\" , \"time_point\" : \"Time Point\" , \"sex\" : \"Sex\" }, axis = \"columns\" ) fig3 = go . Figure () fig3 = px . bar ( new_opioid_gender , y = \"Sex\" , x = \"Count\" , color = \"Taking Opioid\" , facet_col = \"Time Point\" , width = 800 , height = 400 , orientation = 'h' , category_orders = { \"Sex\" : [ \"Intersex\" , \"Unknown\" , \"Male\" , \"Female\" ]}) fig3 . update_layout ( title_text = \"Opioid Pain Medication at Two Time Points in Different Sex Groups\" , title_font_size = 20 ) fig3 . write_image ( 'img/BACPAC_Synthetic_Data_Analysis/figure3.png' ) Image ( filename = \"img/BACPAC_Synthetic_Data_Analysis/figure3.png\" ) We observed an increase of particpants taking opioid medication at week 12 in both male and femal groups compared to baseline week 0.","title":"Opiod pain medication profiling at two time points"},{"location":"notebooks/BACPAC_Synthetic_Data_Analysis/#physical-function-outcomes","text":"The cell below uses the Physical Function 6b T-Score to display physical function outcomes in different ethnicity groups at week 0 and week 12. # Read physical_function_SMART.tsv into dataframe and merge the df with demographic function_df = pd . read_csv ( \"./physical_function_SMART.tsv\" , sep = \" \\t \" , encoding = \"utf-16\" ) function_participant_id = find_participant ( function_df , \"_pf\" ) function_df [ \"participant_id\" ] = function_participant_id demo_combine_function = function_df . merge ( demo_bacpac , left_on = \"participant_id\" , right_on = \"submitter_id\" , how = \"outer\" ) demo_combine_function [ \"time_point\" ] = find_timepoint ( demo_combine_function ) # Summary table of ROMIS-Physical Function 6b T-Score in different ethnicity groups ethnicity_PRPF6BT = demo_combine_function [[ \"time_point\" , \"PRPF6BT\" , \"ethnicity\" ]] . groupby ([ 'time_point' , 'ethnicity' ]) . describe () Markdown ( ethnicity_PRPF6BT . to_markdown ()) ('PRPF6BT', 'count') ('PRPF6BT', 'mean') ('PRPF6BT', 'std') ('PRPF6BT', 'min') ('PRPF6BT', '25%') ('PRPF6BT', '50%') ('PRPF6BT', '75%') ('PRPF6BT', 'max') ('Week 0', 'Hispanic or Latino') 41 38.2854 3.16501 32.5 36 38.5 39.3 48.7 ('Week 0', 'Not Hispanic or Latino') 73 37.5411 2.59823 31.5 35.1 37.6 39.3 44.2 ('Week 0', 'Not reported') 16 37.6125 2.93754 33.4 35.1 38.05 40.2 43.1 ('Week 0', 'Unknown') 20 38.195 2.46736 31.5 37.4 38.5 39.3 42.1 ('Week 12', 'Hispanic or Latino') 41 37.5366 3.06299 29.1 35.1 37.6 39.3 43.1 ('Week 12', 'Not Hispanic or Latino') 73 37.589 3.24267 31.5 35.1 37.6 40.2 44.2 ('Week 12', 'Not reported') 16 37.7438 2.74007 33.4 36 36.8 39.525 43.1 ('Week 12', 'Unknown') 20 36.925 3.26366 29.1 35.1 36 38.7 44.2 # Visualize the distribution of Physical Function 6b T-Score # at two time points for hispanic and non-hispanic ethnicity groups fig4 = go . Figure () fig4 = make_subplots ( rows = 2 , cols = 2 , specs = [[{ \"colspan\" : 2 }, None ], [{}, {}]], subplot_titles = ( \"PROMIS-Physical Function 6b T-Score Distribution at Two Time Points\" , \"Hispanic or Latino\" , \"Not Hispanic or Latino\" )) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [ demo_combine_function [ \"time_point\" ] == \"Week 0\" ][ \"PRPF6BT\" ], marker_color = '#EB89B5' , opacity = 0.75 , nbinsx = 20 , name = \"Week 0\" ), row = 1 , col = 1 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [ demo_combine_function [ \"time_point\" ] == \"Week 12\" ][ \"PRPF6BT\" ], marker_color = '#2B6CBE' , opacity = 0.75 , nbinsx = 20 , name = \"Week 12\" ), row = 1 , col = 1 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [( demo_combine_function [ \"time_point\" ] == \"Week 0\" ) & ( demo_combine_function [ \"ethnicity\" ] == \"Hispanic or Latino\" )][ \"PRPF6BT\" ], marker_color = '#EB89B5' , opacity = 0.75 , nbinsx = 20 , showlegend = False ), row = 2 , col = 1 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [( demo_combine_function [ \"time_point\" ] == \"Week 12\" ) & ( demo_combine_function [ \"ethnicity\" ] == \"Hispanic or Latino\" )][ \"PRPF6BT\" ], marker_color = '#2B6CBE' , opacity = 0.75 , nbinsx = 20 , showlegend = False ), row = 2 , col = 1 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [( demo_combine_function [ \"time_point\" ] == \"Week 0\" ) & ( demo_combine_function [ \"ethnicity\" ] == \"Not Hispanic or Latino\" )][ \"PRPF6BT\" ], marker_color = '#EB89B5' , opacity = 0.75 , nbinsx = 20 , showlegend = False ), row = 2 , col = 2 ) fig4 . add_trace ( go . Histogram ( x = demo_combine_function [( demo_combine_function [ \"time_point\" ] == \"Week 12\" ) & ( demo_combine_function [ \"ethnicity\" ] == \"Not Hispanic or Latino\" )][ \"PRPF6BT\" ], marker_color = '#2B6CBE' , opacity = 0.75 , nbinsx = 20 , showlegend = False ), row = 2 , col = 2 ) fig4 . update_layout ( barmode = 'overlay' , width = 800 , height = 500 , legend_title_text = 'Time Point' ) fig4 . update_layout ( margin = dict ( l = 20 , r = 20 , t = 50 , b = 20 , pad = 2 )) fig4 . update_yaxes ( title_text = \"Count\" , title_font_size = 15 , range = [ 0 , 40 ], row = 1 , col = 1 ) fig4 . update_xaxes ( title_text = \"PROMIS-Physical Function 6b T-Score\" , title_font_size = 15 , range = [ 29 , 49 ], row = 1 , col = 1 ) fig4 . update_yaxes ( title_text = \"Count\" , title_font_size = 15 , range = [ 0 , 15 ], row = 2 , col = 1 ) fig4 . update_xaxes ( title_text = \"PROMIS-Physical Function 6b T-Score\" , title_font_size = 15 , range = [ 29 , 49 ], row = 2 , col = 1 ) fig4 . update_yaxes ( title_text = \"Count\" , title_font_size = 15 , range = [ 0 , 15 ], row = 2 , col = 2 ) fig4 . update_xaxes ( title_text = \"PROMIS-Physical Function 6b T-Score\" , title_font_size = 15 , range = [ 29 , 49 ], row = 2 , col = 2 ) fig4 . write_image ( 'img/BACPAC_Synthetic_Data_Analysis/figure4.png' ) Image ( filename = \"img/BACPAC_Synthetic_Data_Analysis/figure4.png\" )","title":"Physical function outcomes"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/","text":"Analysis Of A Non-Opioid Treatment For Neuropathic Pain (HDP00384) \u00b6 By J M Maxwell - Data Science, Sr. Analyst - CTDS \u00b6 In this notebook, we'll be analyzing data from the study High-Resolution, Spinal Cord Stimulation for Non-Opioid Treatment of Neuropathic Pain by Bryan McLaughlin. The study was conducted in two phases, and this analysis utilizes the pre and post operation results from five indices for the subject's self reported pain, depression, or pain inducing disability. This work was strictly done to demonstrate the advantages of the HEAL Platform's Workspace feature and the ability to utilize data that is joined under the HEAL data mesh. All the following work was completed by J M. Maxwell and members of the HEAL Platform team, but was based on the data provided in High-Resolution, Spinal Cord Stimulation for Non-Opioid Treatment of Neuropathic Pain and influenced by the work of McLaughlin et al. in Correlating Evoked Electromyography and Anatomic Factors During Spinal Cord Stimulation Implantation With Short-Term Outcomes . The work here does not represent the official opinions, recommendations, or conclusions of Bryan McLaughlin and this work does not represent policy or medical recommendations on behalf of the NIH HEAL Initiative, The Center For Translational Data Science, or The University of Chicago. McLaughlin, Bryan (2024), \u201cHigh-Resolution, Spinal Cord Stimulation for Non-Opioid Treatment of Neuropathic Pain (U44NS115111)\u201d, Mendeley Data, V1, doi: 10.17632/rmj2kngzbp.1 Access Data \u00b6 To access the data from this study make sure you are logged in to the InCommon login option and then: 1) Go to the HEAL Discovery page to select the study 2) Select the 'Open In Workspace' option and choose the (Tutorials) Example Analysis Jupyter Lab Notebooks workspace option 3) Use the exported study manifest to download the study. Otherwise you may run the following gen3-sdk command to download the relevant CSV file from the study. ! gen3 drs - pull object dg . H34L / b8b871b8 - aadd - 4017 - 9 f67 - 184 b17ab3580 ! gen3 drs - pull object dg . H34L / ffde8647 - 1 ec2 - 4459 - 8409 - bd41c0736c86 {\"succeeded\": [\"dg.H34L/b8b871b8-aadd-4017-9f67-184b17ab3580\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/ffde8647-1ec2-4459-8409-bd41c0736c86\"], \"failed\": []} About the Study \u00b6 The study, High-Resolution, Spinal Cord Stimulation for Non-Opioid Treatment of Neuropathic Pain , investigated the outcomes of elliciting EMGs (electromyography) in subject's regions of pain during surgery. Data for evaluating the treatment effect were collected from 21 patients in two phases. Subject outcomes were measured using: the Numerical Rating Scale, McGill Pain Questionnaire, Beck Depression Inventory, Oswestry Disability Index, and Pain Catastrophizing Score, and were recorded preoperatively and at three months following the procedure. Load Packages and Data \u00b6 ! pip install matplotlib - q import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) import pandas as pd import numpy as np import matplotlib.pyplot as plt from scipy import stats as stats import os pd . set_option ( 'max_colwidth' , 800 ) from IPython.display import Markdown , Image , display os . makedirs ( 'img/Non-Opioid_Treatment_Analysis' ) Read In Data and Clean Data \u00b6 After reading in the data, we perform standard data cleaning steps to improve the usability of the data, remove extraneous data features, and engineer new features measuring the percent change in treatment effects from before and after the each sample subject's operation. participants_df = pd . read_excel ( 'Microleads - Participant level data.xlsx' ) pain_scores_df = pd . read_excel ( 'Pain-MRI scores.xlsx' ) pain_scores_df = pain_scores_df . iloc [: 21 , :] df = pd . merge ( left = participants_df , right = pain_scores_df , how = 'left' , on = [ 'Phase' , 'Patient' ]) df [ list ( df . select_dtypes ( include = 'float64' ))] = df [ list ( df . select_dtypes ( include = 'float64' ))] . astype ( 'float32' ) df . replace ( '-' , np . nan , inplace = True ) df . rename ( columns = { 'NRS Pre-op' : 'NRS Pre-Op' , 'NRS Post-op' : 'NRS Post-Op' , 'MPQ pre-op' : 'MPQ Pre-Op' , 'MPQ post-op' : 'MPQ Post-Op' , 'Gender' : 'Sex' }, inplace = True ) df . drop ([ 'Patient' , 'Race' , 'Ethnicity' , 'Age Unit' ], axis = 1 , inplace = True ) delta_cols = [ 'NRS' , 'MPQ' , 'ODI' , 'PCS' , 'BDI' ] for col in delta_cols : df [ f ' { col } _pct_change' ] = np . round ( 100 * (( df [ f ' { col } Post-Op' ] - df [ f ' { col } Pre-Op' ]) / df [ f ' { col } Post-Op' ]), 2 ) df . replace ( np . float64 ( '-inf' ), np . nan , inplace = True ) Markdown ( df . to_markdown ()) Phase Sex Age NRS Pre-Op NRS Post-Op MPQ Pre-Op MPQ Post-Op ODI Pre-Op ODI Post-Op PCS Pre-Op PCS Post-Op BDI Pre-Op BDI Post-Op AP column Diameter (mm) Interpedicular distance (mm) Dorsal CSF Thickness (mm) NRS_pct_change MPQ_pct_change ODI_pct_change PCS_pct_change BDI_pct_change 0 1 F 54 9 4 6 6 68 44 14 7 10 5 12.8 16.5 3 -125 0 -54.55 -100 -100 1 1 M 60 9 5 8 7 62 36 34 16 15 11 15.8 20 4 -80 -14.29 -72.22 -112.5 -36.36 2 1 M 46 7 3 9 8 54 30 17 4 17 7 11.3 14.8 2.5 -133.33 -12.5 -80 -325 -142.86 3 1 M 29 8 5 9 5 52 54 20 7 5 8 15.2 19.5 5 -60 -80 3.7 -185.71 37.5 4 1 F 43 8 3 6 5 78 nan 42 38 46 23 14.8 19.6 5 -166.67 -20 nan -10.53 -100 5 1 F 40 2 0 5 nan 12 nan 2 nan 4 nan 17 21.5 4.8 nan nan nan nan nan 6 1 F 52 7 8 4 5 60 62 2 26 7 16 17.6 18.8 3.9 12.5 20 3.23 92.31 56.25 7 1 M 67 6 4 1 nan 62 nan 24 nan 19 nan 19 19.3 5.3 -50 nan nan nan nan 8 1 F 57 7 7 1 14 73 74 14 6 16 5 18.1 20 5.4 0 92.86 1.35 -133.33 -220 9 1 F 36 10 8 9 13 76 76 39 23 34 40 17 21.8 5.7 -25 30.77 0 -69.57 15 10 1 M 71 6 nan 5 nan 60 nan 39 nan 23 nan 13.9 21.3 3.9 nan nan nan nan nan 11 1 F 78 5 5 4 11 37.8 31 30 35 21 14 18 21.5 4.7 0 63.64 -21.94 14.29 -50 12 2 F 57 8 3 11 5 64 36 27 7 19 12 nan nan nan -166.67 -120 -77.78 -285.71 -58.33 13 2 F 60 8 3 4 2 56 38 42 22 27 15 15 17.6 4.3 -166.67 -100 -47.37 -90.91 -80 14 2 F 67 8 0 5 0 64 0 24 0 13 0 14.1 17.3 3.1 nan nan nan nan nan 15 2 F 51 8 6 4 15 60 50 8 42 0 7 14.4 17.5 4.8 -33.33 73.33 -20 80.95 100 16 2 F 78 8 8 8 8 38 42 26 29 5 7 15.2 19.3 4.9 0 0 9.52 10.34 28.57 17 2 M 75 8 2 11 4 49 40 11 8 5 2 12.2 18 4.7 -300 -175 -22.5 -37.5 -150 18 2 F 34 8 5 21 10 62 50 38 41 33 32 14.4 17.2 3.6 -60 -110 -24 7.32 -3.12 19 2 M 71 6.5 2 22 0 30 4 19 1 9 2 12.3 21.4 5.6 -225 nan -650 -1800 -350 20 2 F 49 7 3 13 4 42 21 29 24 7 14 14.8 18.7 6.2 -133.33 -225 -100 -20.83 50 Summary Statistics \u00b6 First, let us look at the summary statistics for our measured treatment effects and our engineer treatment effects. characteristics = [ 'Sex M/F' , 'Age' , 'Anterior-posterior diameter (mean \u00b1 SD in mm)' , 'Interpedicular distance (mean \u00b1 SD in mm)' , 'Dorsal CSF thickness (mean \u00b1 SD in mm)' , 'Numerical Rating Scale (mean \u00b1 SD)' , 'McGill Pain Questionnaire (mean \u00b1 SD)' , 'Oswestry Disability Index (mean \u00b1 SD)' , 'Pain Catastrophizing Scale (mean \u00b1 SD)' , 'Beck Depression Index (mean \u00b1 SD' ] cols = [ 'Age' , 'AP column Diameter (mm)' , 'Interpedicular distance (mm)' , 'Dorsal CSF Thickness (mm)' , 'NRS Pre-Op' , 'MPQ Pre-Op' , 'ODI Pre-Op' , 'PCS Pre-Op' , 'BDI Pre-Op' , ] x = df . Sex . value_counts () . values values = [ f ' { int ( x [ 1 ]) } / { int ( x [ 0 ]) } ' ] for col in cols : values . append ( f ' { np . round ( float ( df [ col ] . mean ()), decimals = 1 ) } ' + u \" \\u00B1 \" + f ' { np . round ( float ( df [ col ] . std ()), 1 ) } ' ) table_df1 = pd . DataFrame ({ 'Patient Information and Clinical Characteristics' : characteristics , 'Values' : values }) Markdown ( table_df1 . to_markdown ()) Patient Information and Clinical Characteristics Values 0 Sex M/F 7 / 14 1 Age 56.0 \u00b1 14.6 2 Anterior-posterior diameter (mean \u00b1 SD in mm) 15.1 \u00b1 2.1 3 Interpedicular distance (mean \u00b1 SD in mm) 19.1 \u00b1 1.9 4 Dorsal CSF thickness (mean \u00b1 SD in mm) 4.5 \u00b1 1.0 5 Numerical Rating Scale (mean \u00b1 SD) 7.3 \u00b1 1.7 6 McGill Pain Questionnaire (mean \u00b1 SD) 7.9 \u00b1 5.5 7 Oswestry Disability Index (mean \u00b1 SD) 55.2 \u00b1 16.0 8 Pain Catastrophizing Scale (mean \u00b1 SD) 23.9 \u00b1 12.6 9 Beck Depression Index (mean \u00b1 SD 16.0 \u00b1 11.7 characteristics = [ 'Numerical Rating Scale Percent Change (mean \u00b1 SD)' , 'McGill Pain Questionnaire Percent Change (mean \u00b1 SD)' , 'Oswestry Disability Index Percent Change (mean \u00b1 SD)' , 'Pain Catastrophizing Scale Percent Change (mean \u00b1 SD)' , 'Beck Depression Index Percent Change (mean \u00b1 SD' ] cols = [ 'NRS_pct_change' , 'MPQ_pct_change' , 'ODI_pct_change' , 'PCS_pct_change' , 'BDI_pct_change' ] values = [] for col in cols : values . append ( f ' { np . round ( float ( df [ col ] . mean ()), decimals = 1 ) } ' + u \" \\u00B1 \" + f ' { np . round ( float ( df [ col ] . std ()), 1 ) } ' ) table_df2 = pd . DataFrame ({ 'Patient Information and Clinical Characteristics' : characteristics , 'Values' : values }) Markdown ( table_df2 . to_markdown ()) Patient Information and Clinical Characteristics Values 0 Numerical Rating Scale Percent Change (mean \u00b1 SD) -95.1 \u00b1 87.5 1 McGill Pain Questionnaire Percent Change (mean \u00b1 SD) -36.0 \u00b1 90.8 2 Oswestry Disability Index Percent Change (mean \u00b1 SD) -72.0 \u00b1 158.0 3 Pain Catastrophizing Scale Percent Change (mean \u00b1 SD) -174.5 \u00b1 434.1 4 Beck Depression Index Percent Change (mean \u00b1 SD -59.0 \u00b1 113.6 Statistical Testing \u00b6 We're interested in comparing the treatment effects pre and post subject's operations. To begin with, we can use the Shapiro-Wilk Test to determine if the differences between each set of distributions are potentially normally distributed. (h1)= The null hypothesis is that the difference between the distributions of each treatment effect pre and post operation are not normally distributed. If we reject the null hypothesis, then we will proceed assuming the difference in distributions is not normally distributed. If we fail to reject the null hypothesis, then we will assume the distributions could be normally distributed. fig , axes = plt . subplots ( 2 , 3 , figsize = ( 12 , 6 )) # Adjust the figure size as needed axes = axes . flatten () delta_cols = [ 'NRS' , 'MPQ' , 'ODI' , 'PCS' , 'BDI' ] for i in range ( 0 , len ( delta_cols )): data = ( df [ f ' { delta_cols [ i ] } Post-Op' ] - df [ f ' { delta_cols [ i ] } Pre-Op' ]) . dropna () stat , p = stats . shapiro ( data ) print ( f 'Shapiro-Wilk Test: { delta_cols [ i ] } \\n Statistic: { np . round ( stat , 3 ) } \\n P-value: { np . round ( p , 3 ) } ' ) if p > 0.05 : print ( f 'Sample { delta_cols [ i ] } could be normally distributed (fail to reject null hypothesis)' ) else : print ( f 'Sample { delta_cols [ i ] } does not look normally distributed (reject null hypothesis)' ) print ( \"********************** \\n \" ) stats . probplot ( data , dist = \"norm\" , plot = axes [ i ]) axes [ i ] . set_title ( f \"Normal Q-Q Plot { delta_cols [ i ] } \" ) plt . tight_layout () axes [ 3 ] . set_position ([ 0.24 , 0.125 , 0.228 , 0.343 ]) axes [ 4 ] . set_position ([ 0.55 , 0.125 , 0.228 , 0.343 ]) axes [ 5 ] . set_visible ( False ) plt . close ( fig ) fig . savefig ( 'img/Non-Opioid_Treatment_Analysis/figure1.png' ) Image ( filename = \"img/Non-Opioid_Treatment_Analysis/figure1.png\" ) Shapiro-Wilk Test: NRS Statistic: 0.958 P-value: 0.513 Sample NRS could be normally distributed (fail to reject null hypothesis) ********************** Shapiro-Wilk Test: MPQ Statistic: 0.957 P-value: 0.55 Sample MPQ could be normally distributed (fail to reject null hypothesis) ********************** Shapiro-Wilk Test: ODI Statistic: 0.862 P-value: 0.016 Sample ODI does not look normally distributed (reject null hypothesis) ********************** Shapiro-Wilk Test: PCS Statistic: 0.881 P-value: 0.027 Sample PCS does not look normally distributed (reject null hypothesis) ********************** Shapiro-Wilk Test: BDI Statistic: 0.96 P-value: 0.607 Sample BDI could be normally distributed (fail to reject null hypothesis) ********************** For three of the subjects' measured treatment effects, Numerical Rating Scale (NRS), McGill Pain Questionnairre (MPQ), and Beck Depression Index (BDI), we fail to reject the null hypothesis and so the differences between effects pre and post operation could be normally distributed. For these three we will test if the underlying distributions of the treatment effects pre and post operation have the same underlying distribution using the Student's t-test. For the other two measured treatment effects, Oswestry Disability Index (ODI) and Pain Catastrophizing Scale (PCS), we reject the null hypthesis and assume the difference between treatment effects pre and post operation are not normally distributed. For these two treatment effects we cannot use the Student's t-test, and will instead use the non-parametric Mann Whitney U Test to test whether the the pre and post operation treatment effect samples hace the same underlying distribution. Because the Mann Whitney U Test is a non-parametric statistical test that does not assume normality, we will also use this test on the other three treatment effects. Student's T-Test \u00b6 The Two-Sample, Paired Student's T-Test is used to test whether two related, sample distributions have a statistically significant difference. (h2)= Our null hypothesis is that the averages (or expected) values of the two samples, pre and post treatment effects, are the same. If the null hypothesis is rejected, then the pre and post operation treatment effect samples do not have identical average (expected) values and the pre and post operation samples could be different, or in other words, the operation may have influenced a change in the measured treatment effect. If we fail to reject the null hypothesis, then the pre and post operation treatment effect samples could have identical average (expected) values and the operation may not have influenced a change in the measured treatment effect. delta_cols = [ 'NRS' , 'MPQ' , 'BDI' ] for col in delta_cols : resultTtest = stats . ttest_rel ( a = df [ f ' { col } Pre-Op' ], b = df [ f ' { col } Post-Op' ], nan_policy = 'omit' ) print ( f \"Student's t Test: { col } \\n Statistic: { np . round ( resultTtest . statistic , 3 ) } \\n P-value: { np . round ( resultTtest . pvalue , 3 ) } \" ) if resultTtest . pvalue > 0.05 : print ( f 'Pre and Post Op { col } samples could have identical average (expected) values. (fail to reject null hypothesis)' ) else : print ( f 'Pre and Post Op { col } samples do not have identical average (expected) values. (reject null hypothesis)' ) print ( \"********************** \\n \" ) Student's t Test: NRS Statistic: 6.139 P-value: 0.0 Pre and Post Op NRS samples do not have identical average (expected) values. (reject null hypothesis) ********************** Student's t Test: MPQ Statistic: 0.961 P-value: 0.35 Pre and Post Op MPQ samples could have identical average (expected) values. (fail to reject null hypothesis) ********************** Student's t Test: BDI Statistic: 1.916 P-value: 0.072 Pre and Post Op BDI samples could have identical average (expected) values. (fail to reject null hypothesis) ********************** We only reject the null hypothesis for the first treatment effect, Numerical Rating Scale (NRS), and fail to reject the null hypothesis for the other two treatment effects McGill Pain Questionnairre (MPQ) and Beck Depression Index (BDI). Wilcoxon Signed-Rank Test \u00b6 The Wilcoxon Signed-Rank Test is a non-parametric version of the Student's T-Test used to test if there is a difference between two paired distributions. (h3)= It tests the null hypothesis that differences between the paired samples are distributed symetrically around zero. If we reject the null hypothesis, then the paired pre and post operation treatment effects do not have the same underlying distribution, and the operation could have caused a significant difference to the measured treatment effect. And if we fail to reject the null hypothesis, then the paired treatment effect samples could have the same underlying distribution, and the treatment may not have caused a significant difference to the measured treatment effect. delta_cols = [ 'NRS' , 'MPQ' , 'ODI' , 'PCS' , 'BDI' ] for col in delta_cols : result_wilcoxon_test = stats . wilcoxon ( x = df [ f ' { col } Pre-Op' ], y = df [ f ' { col } Post-Op' ], nan_policy = 'omit' , zero_method = 'wilcox' ) print ( f \"Wilcoxon Signed-Rank Test: { col } \\n Statistic: { np . round ( result_wilcoxon_test . statistic , 3 ) } \\n P-value: { np . round ( result_wilcoxon_test . pvalue , 3 ) } \" ) if result_wilcoxon_test . pvalue > 0.05 : print ( f 'Pre and Post Op { col } samples could have the same underlying distribution. (fail to reject null hypothesis)' ) else : print ( f 'Pre and Post Op { col } samples do not have the same underlying distribution. (reject null hypothesis)' ) print ( \"********************** \\n \" ) Wilcoxon Signed-Rank Test: NRS Statistic: 1.0 P-value: 0.0 Pre and Post Op NRS samples do not have the same underlying distribution. (reject null hypothesis) ********************** Wilcoxon Signed-Rank Test: MPQ Statistic: 48.0 P-value: 0.3 Pre and Post Op MPQ samples could have the same underlying distribution. (fail to reject null hypothesis) ********************** Wilcoxon Signed-Rank Test: ODI Statistic: 10.0 P-value: 0.003 Pre and Post Op ODI samples do not have the same underlying distribution. (reject null hypothesis) ********************** Wilcoxon Signed-Rank Test: PCS Statistic: 44.0 P-value: 0.074 Pre and Post Op PCS samples could have the same underlying distribution. (fail to reject null hypothesis) ********************** Wilcoxon Signed-Rank Test: BDI Statistic: 45.5 P-value: 0.09 Pre and Post Op BDI samples could have the same underlying distribution. (fail to reject null hypothesis) ********************** Like with the Student's T-Test, we reject the null hypothesis for treatment effect Numerical Rating Scale (NRS), we also reject the null hypothesis for the treatment effect Oswestry Disability Index (ODI). This suggests that there is a statistically significant difference between these measured treatment effects from before and after the subjects' operations. For the other three treatment effects, we fail to reject the null hypothesis , and should conclude that there is no significant differences to the measured treatment effects before and after the subjects' operations. Conclusions \u00b6 We found large, average percent descreases between pre and post operation data across all five measured treatment effects for subject's reported pain, depression, and pain induced disability. Using both parametric and non-parametric statistical testing we found there was a statistically significant difference to the subject's pain and disability as reported with the Numerical Rating Scale for pain and the Oswestry Disability Index for lower-back pain induced disability.","title":"Non-Opioid Treatment Of Neuropathic Pain"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#analysis-of-a-non-opioid-treatment-for-neuropathic-pain-hdp00384","text":"","title":"Analysis Of A Non-Opioid Treatment For Neuropathic Pain (HDP00384)"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#by-j-m-maxwell-data-science-sr-analyst-ctds","text":"In this notebook, we'll be analyzing data from the study High-Resolution, Spinal Cord Stimulation for Non-Opioid Treatment of Neuropathic Pain by Bryan McLaughlin. The study was conducted in two phases, and this analysis utilizes the pre and post operation results from five indices for the subject's self reported pain, depression, or pain inducing disability. This work was strictly done to demonstrate the advantages of the HEAL Platform's Workspace feature and the ability to utilize data that is joined under the HEAL data mesh. All the following work was completed by J M. Maxwell and members of the HEAL Platform team, but was based on the data provided in High-Resolution, Spinal Cord Stimulation for Non-Opioid Treatment of Neuropathic Pain and influenced by the work of McLaughlin et al. in Correlating Evoked Electromyography and Anatomic Factors During Spinal Cord Stimulation Implantation With Short-Term Outcomes . The work here does not represent the official opinions, recommendations, or conclusions of Bryan McLaughlin and this work does not represent policy or medical recommendations on behalf of the NIH HEAL Initiative, The Center For Translational Data Science, or The University of Chicago. McLaughlin, Bryan (2024), \u201cHigh-Resolution, Spinal Cord Stimulation for Non-Opioid Treatment of Neuropathic Pain (U44NS115111)\u201d, Mendeley Data, V1, doi: 10.17632/rmj2kngzbp.1","title":"By J M Maxwell - Data Science, Sr. Analyst - CTDS"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#access-data","text":"To access the data from this study make sure you are logged in to the InCommon login option and then: 1) Go to the HEAL Discovery page to select the study 2) Select the 'Open In Workspace' option and choose the (Tutorials) Example Analysis Jupyter Lab Notebooks workspace option 3) Use the exported study manifest to download the study. Otherwise you may run the following gen3-sdk command to download the relevant CSV file from the study. ! gen3 drs - pull object dg . H34L / b8b871b8 - aadd - 4017 - 9 f67 - 184 b17ab3580 ! gen3 drs - pull object dg . H34L / ffde8647 - 1 ec2 - 4459 - 8409 - bd41c0736c86 {\"succeeded\": [\"dg.H34L/b8b871b8-aadd-4017-9f67-184b17ab3580\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/ffde8647-1ec2-4459-8409-bd41c0736c86\"], \"failed\": []}","title":"Access Data"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#about-the-study","text":"The study, High-Resolution, Spinal Cord Stimulation for Non-Opioid Treatment of Neuropathic Pain , investigated the outcomes of elliciting EMGs (electromyography) in subject's regions of pain during surgery. Data for evaluating the treatment effect were collected from 21 patients in two phases. Subject outcomes were measured using: the Numerical Rating Scale, McGill Pain Questionnaire, Beck Depression Inventory, Oswestry Disability Index, and Pain Catastrophizing Score, and were recorded preoperatively and at three months following the procedure.","title":"About the Study"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#load-packages-and-data","text":"! pip install matplotlib - q import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) import pandas as pd import numpy as np import matplotlib.pyplot as plt from scipy import stats as stats import os pd . set_option ( 'max_colwidth' , 800 ) from IPython.display import Markdown , Image , display os . makedirs ( 'img/Non-Opioid_Treatment_Analysis' )","title":"Load Packages and Data"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#read-in-data-and-clean-data","text":"After reading in the data, we perform standard data cleaning steps to improve the usability of the data, remove extraneous data features, and engineer new features measuring the percent change in treatment effects from before and after the each sample subject's operation. participants_df = pd . read_excel ( 'Microleads - Participant level data.xlsx' ) pain_scores_df = pd . read_excel ( 'Pain-MRI scores.xlsx' ) pain_scores_df = pain_scores_df . iloc [: 21 , :] df = pd . merge ( left = participants_df , right = pain_scores_df , how = 'left' , on = [ 'Phase' , 'Patient' ]) df [ list ( df . select_dtypes ( include = 'float64' ))] = df [ list ( df . select_dtypes ( include = 'float64' ))] . astype ( 'float32' ) df . replace ( '-' , np . nan , inplace = True ) df . rename ( columns = { 'NRS Pre-op' : 'NRS Pre-Op' , 'NRS Post-op' : 'NRS Post-Op' , 'MPQ pre-op' : 'MPQ Pre-Op' , 'MPQ post-op' : 'MPQ Post-Op' , 'Gender' : 'Sex' }, inplace = True ) df . drop ([ 'Patient' , 'Race' , 'Ethnicity' , 'Age Unit' ], axis = 1 , inplace = True ) delta_cols = [ 'NRS' , 'MPQ' , 'ODI' , 'PCS' , 'BDI' ] for col in delta_cols : df [ f ' { col } _pct_change' ] = np . round ( 100 * (( df [ f ' { col } Post-Op' ] - df [ f ' { col } Pre-Op' ]) / df [ f ' { col } Post-Op' ]), 2 ) df . replace ( np . float64 ( '-inf' ), np . nan , inplace = True ) Markdown ( df . to_markdown ()) Phase Sex Age NRS Pre-Op NRS Post-Op MPQ Pre-Op MPQ Post-Op ODI Pre-Op ODI Post-Op PCS Pre-Op PCS Post-Op BDI Pre-Op BDI Post-Op AP column Diameter (mm) Interpedicular distance (mm) Dorsal CSF Thickness (mm) NRS_pct_change MPQ_pct_change ODI_pct_change PCS_pct_change BDI_pct_change 0 1 F 54 9 4 6 6 68 44 14 7 10 5 12.8 16.5 3 -125 0 -54.55 -100 -100 1 1 M 60 9 5 8 7 62 36 34 16 15 11 15.8 20 4 -80 -14.29 -72.22 -112.5 -36.36 2 1 M 46 7 3 9 8 54 30 17 4 17 7 11.3 14.8 2.5 -133.33 -12.5 -80 -325 -142.86 3 1 M 29 8 5 9 5 52 54 20 7 5 8 15.2 19.5 5 -60 -80 3.7 -185.71 37.5 4 1 F 43 8 3 6 5 78 nan 42 38 46 23 14.8 19.6 5 -166.67 -20 nan -10.53 -100 5 1 F 40 2 0 5 nan 12 nan 2 nan 4 nan 17 21.5 4.8 nan nan nan nan nan 6 1 F 52 7 8 4 5 60 62 2 26 7 16 17.6 18.8 3.9 12.5 20 3.23 92.31 56.25 7 1 M 67 6 4 1 nan 62 nan 24 nan 19 nan 19 19.3 5.3 -50 nan nan nan nan 8 1 F 57 7 7 1 14 73 74 14 6 16 5 18.1 20 5.4 0 92.86 1.35 -133.33 -220 9 1 F 36 10 8 9 13 76 76 39 23 34 40 17 21.8 5.7 -25 30.77 0 -69.57 15 10 1 M 71 6 nan 5 nan 60 nan 39 nan 23 nan 13.9 21.3 3.9 nan nan nan nan nan 11 1 F 78 5 5 4 11 37.8 31 30 35 21 14 18 21.5 4.7 0 63.64 -21.94 14.29 -50 12 2 F 57 8 3 11 5 64 36 27 7 19 12 nan nan nan -166.67 -120 -77.78 -285.71 -58.33 13 2 F 60 8 3 4 2 56 38 42 22 27 15 15 17.6 4.3 -166.67 -100 -47.37 -90.91 -80 14 2 F 67 8 0 5 0 64 0 24 0 13 0 14.1 17.3 3.1 nan nan nan nan nan 15 2 F 51 8 6 4 15 60 50 8 42 0 7 14.4 17.5 4.8 -33.33 73.33 -20 80.95 100 16 2 F 78 8 8 8 8 38 42 26 29 5 7 15.2 19.3 4.9 0 0 9.52 10.34 28.57 17 2 M 75 8 2 11 4 49 40 11 8 5 2 12.2 18 4.7 -300 -175 -22.5 -37.5 -150 18 2 F 34 8 5 21 10 62 50 38 41 33 32 14.4 17.2 3.6 -60 -110 -24 7.32 -3.12 19 2 M 71 6.5 2 22 0 30 4 19 1 9 2 12.3 21.4 5.6 -225 nan -650 -1800 -350 20 2 F 49 7 3 13 4 42 21 29 24 7 14 14.8 18.7 6.2 -133.33 -225 -100 -20.83 50","title":"Read In Data and Clean Data"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#summary-statistics","text":"First, let us look at the summary statistics for our measured treatment effects and our engineer treatment effects. characteristics = [ 'Sex M/F' , 'Age' , 'Anterior-posterior diameter (mean \u00b1 SD in mm)' , 'Interpedicular distance (mean \u00b1 SD in mm)' , 'Dorsal CSF thickness (mean \u00b1 SD in mm)' , 'Numerical Rating Scale (mean \u00b1 SD)' , 'McGill Pain Questionnaire (mean \u00b1 SD)' , 'Oswestry Disability Index (mean \u00b1 SD)' , 'Pain Catastrophizing Scale (mean \u00b1 SD)' , 'Beck Depression Index (mean \u00b1 SD' ] cols = [ 'Age' , 'AP column Diameter (mm)' , 'Interpedicular distance (mm)' , 'Dorsal CSF Thickness (mm)' , 'NRS Pre-Op' , 'MPQ Pre-Op' , 'ODI Pre-Op' , 'PCS Pre-Op' , 'BDI Pre-Op' , ] x = df . Sex . value_counts () . values values = [ f ' { int ( x [ 1 ]) } / { int ( x [ 0 ]) } ' ] for col in cols : values . append ( f ' { np . round ( float ( df [ col ] . mean ()), decimals = 1 ) } ' + u \" \\u00B1 \" + f ' { np . round ( float ( df [ col ] . std ()), 1 ) } ' ) table_df1 = pd . DataFrame ({ 'Patient Information and Clinical Characteristics' : characteristics , 'Values' : values }) Markdown ( table_df1 . to_markdown ()) Patient Information and Clinical Characteristics Values 0 Sex M/F 7 / 14 1 Age 56.0 \u00b1 14.6 2 Anterior-posterior diameter (mean \u00b1 SD in mm) 15.1 \u00b1 2.1 3 Interpedicular distance (mean \u00b1 SD in mm) 19.1 \u00b1 1.9 4 Dorsal CSF thickness (mean \u00b1 SD in mm) 4.5 \u00b1 1.0 5 Numerical Rating Scale (mean \u00b1 SD) 7.3 \u00b1 1.7 6 McGill Pain Questionnaire (mean \u00b1 SD) 7.9 \u00b1 5.5 7 Oswestry Disability Index (mean \u00b1 SD) 55.2 \u00b1 16.0 8 Pain Catastrophizing Scale (mean \u00b1 SD) 23.9 \u00b1 12.6 9 Beck Depression Index (mean \u00b1 SD 16.0 \u00b1 11.7 characteristics = [ 'Numerical Rating Scale Percent Change (mean \u00b1 SD)' , 'McGill Pain Questionnaire Percent Change (mean \u00b1 SD)' , 'Oswestry Disability Index Percent Change (mean \u00b1 SD)' , 'Pain Catastrophizing Scale Percent Change (mean \u00b1 SD)' , 'Beck Depression Index Percent Change (mean \u00b1 SD' ] cols = [ 'NRS_pct_change' , 'MPQ_pct_change' , 'ODI_pct_change' , 'PCS_pct_change' , 'BDI_pct_change' ] values = [] for col in cols : values . append ( f ' { np . round ( float ( df [ col ] . mean ()), decimals = 1 ) } ' + u \" \\u00B1 \" + f ' { np . round ( float ( df [ col ] . std ()), 1 ) } ' ) table_df2 = pd . DataFrame ({ 'Patient Information and Clinical Characteristics' : characteristics , 'Values' : values }) Markdown ( table_df2 . to_markdown ()) Patient Information and Clinical Characteristics Values 0 Numerical Rating Scale Percent Change (mean \u00b1 SD) -95.1 \u00b1 87.5 1 McGill Pain Questionnaire Percent Change (mean \u00b1 SD) -36.0 \u00b1 90.8 2 Oswestry Disability Index Percent Change (mean \u00b1 SD) -72.0 \u00b1 158.0 3 Pain Catastrophizing Scale Percent Change (mean \u00b1 SD) -174.5 \u00b1 434.1 4 Beck Depression Index Percent Change (mean \u00b1 SD -59.0 \u00b1 113.6","title":"Summary Statistics"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#statistical-testing","text":"We're interested in comparing the treatment effects pre and post subject's operations. To begin with, we can use the Shapiro-Wilk Test to determine if the differences between each set of distributions are potentially normally distributed. (h1)= The null hypothesis is that the difference between the distributions of each treatment effect pre and post operation are not normally distributed. If we reject the null hypothesis, then we will proceed assuming the difference in distributions is not normally distributed. If we fail to reject the null hypothesis, then we will assume the distributions could be normally distributed. fig , axes = plt . subplots ( 2 , 3 , figsize = ( 12 , 6 )) # Adjust the figure size as needed axes = axes . flatten () delta_cols = [ 'NRS' , 'MPQ' , 'ODI' , 'PCS' , 'BDI' ] for i in range ( 0 , len ( delta_cols )): data = ( df [ f ' { delta_cols [ i ] } Post-Op' ] - df [ f ' { delta_cols [ i ] } Pre-Op' ]) . dropna () stat , p = stats . shapiro ( data ) print ( f 'Shapiro-Wilk Test: { delta_cols [ i ] } \\n Statistic: { np . round ( stat , 3 ) } \\n P-value: { np . round ( p , 3 ) } ' ) if p > 0.05 : print ( f 'Sample { delta_cols [ i ] } could be normally distributed (fail to reject null hypothesis)' ) else : print ( f 'Sample { delta_cols [ i ] } does not look normally distributed (reject null hypothesis)' ) print ( \"********************** \\n \" ) stats . probplot ( data , dist = \"norm\" , plot = axes [ i ]) axes [ i ] . set_title ( f \"Normal Q-Q Plot { delta_cols [ i ] } \" ) plt . tight_layout () axes [ 3 ] . set_position ([ 0.24 , 0.125 , 0.228 , 0.343 ]) axes [ 4 ] . set_position ([ 0.55 , 0.125 , 0.228 , 0.343 ]) axes [ 5 ] . set_visible ( False ) plt . close ( fig ) fig . savefig ( 'img/Non-Opioid_Treatment_Analysis/figure1.png' ) Image ( filename = \"img/Non-Opioid_Treatment_Analysis/figure1.png\" ) Shapiro-Wilk Test: NRS Statistic: 0.958 P-value: 0.513 Sample NRS could be normally distributed (fail to reject null hypothesis) ********************** Shapiro-Wilk Test: MPQ Statistic: 0.957 P-value: 0.55 Sample MPQ could be normally distributed (fail to reject null hypothesis) ********************** Shapiro-Wilk Test: ODI Statistic: 0.862 P-value: 0.016 Sample ODI does not look normally distributed (reject null hypothesis) ********************** Shapiro-Wilk Test: PCS Statistic: 0.881 P-value: 0.027 Sample PCS does not look normally distributed (reject null hypothesis) ********************** Shapiro-Wilk Test: BDI Statistic: 0.96 P-value: 0.607 Sample BDI could be normally distributed (fail to reject null hypothesis) ********************** For three of the subjects' measured treatment effects, Numerical Rating Scale (NRS), McGill Pain Questionnairre (MPQ), and Beck Depression Index (BDI), we fail to reject the null hypothesis and so the differences between effects pre and post operation could be normally distributed. For these three we will test if the underlying distributions of the treatment effects pre and post operation have the same underlying distribution using the Student's t-test. For the other two measured treatment effects, Oswestry Disability Index (ODI) and Pain Catastrophizing Scale (PCS), we reject the null hypthesis and assume the difference between treatment effects pre and post operation are not normally distributed. For these two treatment effects we cannot use the Student's t-test, and will instead use the non-parametric Mann Whitney U Test to test whether the the pre and post operation treatment effect samples hace the same underlying distribution. Because the Mann Whitney U Test is a non-parametric statistical test that does not assume normality, we will also use this test on the other three treatment effects.","title":"Statistical Testing"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#students-t-test","text":"The Two-Sample, Paired Student's T-Test is used to test whether two related, sample distributions have a statistically significant difference. (h2)= Our null hypothesis is that the averages (or expected) values of the two samples, pre and post treatment effects, are the same. If the null hypothesis is rejected, then the pre and post operation treatment effect samples do not have identical average (expected) values and the pre and post operation samples could be different, or in other words, the operation may have influenced a change in the measured treatment effect. If we fail to reject the null hypothesis, then the pre and post operation treatment effect samples could have identical average (expected) values and the operation may not have influenced a change in the measured treatment effect. delta_cols = [ 'NRS' , 'MPQ' , 'BDI' ] for col in delta_cols : resultTtest = stats . ttest_rel ( a = df [ f ' { col } Pre-Op' ], b = df [ f ' { col } Post-Op' ], nan_policy = 'omit' ) print ( f \"Student's t Test: { col } \\n Statistic: { np . round ( resultTtest . statistic , 3 ) } \\n P-value: { np . round ( resultTtest . pvalue , 3 ) } \" ) if resultTtest . pvalue > 0.05 : print ( f 'Pre and Post Op { col } samples could have identical average (expected) values. (fail to reject null hypothesis)' ) else : print ( f 'Pre and Post Op { col } samples do not have identical average (expected) values. (reject null hypothesis)' ) print ( \"********************** \\n \" ) Student's t Test: NRS Statistic: 6.139 P-value: 0.0 Pre and Post Op NRS samples do not have identical average (expected) values. (reject null hypothesis) ********************** Student's t Test: MPQ Statistic: 0.961 P-value: 0.35 Pre and Post Op MPQ samples could have identical average (expected) values. (fail to reject null hypothesis) ********************** Student's t Test: BDI Statistic: 1.916 P-value: 0.072 Pre and Post Op BDI samples could have identical average (expected) values. (fail to reject null hypothesis) ********************** We only reject the null hypothesis for the first treatment effect, Numerical Rating Scale (NRS), and fail to reject the null hypothesis for the other two treatment effects McGill Pain Questionnairre (MPQ) and Beck Depression Index (BDI).","title":"Student's T-Test"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#wilcoxon-signed-rank-test","text":"The Wilcoxon Signed-Rank Test is a non-parametric version of the Student's T-Test used to test if there is a difference between two paired distributions. (h3)= It tests the null hypothesis that differences between the paired samples are distributed symetrically around zero. If we reject the null hypothesis, then the paired pre and post operation treatment effects do not have the same underlying distribution, and the operation could have caused a significant difference to the measured treatment effect. And if we fail to reject the null hypothesis, then the paired treatment effect samples could have the same underlying distribution, and the treatment may not have caused a significant difference to the measured treatment effect. delta_cols = [ 'NRS' , 'MPQ' , 'ODI' , 'PCS' , 'BDI' ] for col in delta_cols : result_wilcoxon_test = stats . wilcoxon ( x = df [ f ' { col } Pre-Op' ], y = df [ f ' { col } Post-Op' ], nan_policy = 'omit' , zero_method = 'wilcox' ) print ( f \"Wilcoxon Signed-Rank Test: { col } \\n Statistic: { np . round ( result_wilcoxon_test . statistic , 3 ) } \\n P-value: { np . round ( result_wilcoxon_test . pvalue , 3 ) } \" ) if result_wilcoxon_test . pvalue > 0.05 : print ( f 'Pre and Post Op { col } samples could have the same underlying distribution. (fail to reject null hypothesis)' ) else : print ( f 'Pre and Post Op { col } samples do not have the same underlying distribution. (reject null hypothesis)' ) print ( \"********************** \\n \" ) Wilcoxon Signed-Rank Test: NRS Statistic: 1.0 P-value: 0.0 Pre and Post Op NRS samples do not have the same underlying distribution. (reject null hypothesis) ********************** Wilcoxon Signed-Rank Test: MPQ Statistic: 48.0 P-value: 0.3 Pre and Post Op MPQ samples could have the same underlying distribution. (fail to reject null hypothesis) ********************** Wilcoxon Signed-Rank Test: ODI Statistic: 10.0 P-value: 0.003 Pre and Post Op ODI samples do not have the same underlying distribution. (reject null hypothesis) ********************** Wilcoxon Signed-Rank Test: PCS Statistic: 44.0 P-value: 0.074 Pre and Post Op PCS samples could have the same underlying distribution. (fail to reject null hypothesis) ********************** Wilcoxon Signed-Rank Test: BDI Statistic: 45.5 P-value: 0.09 Pre and Post Op BDI samples could have the same underlying distribution. (fail to reject null hypothesis) ********************** Like with the Student's T-Test, we reject the null hypothesis for treatment effect Numerical Rating Scale (NRS), we also reject the null hypothesis for the treatment effect Oswestry Disability Index (ODI). This suggests that there is a statistically significant difference between these measured treatment effects from before and after the subjects' operations. For the other three treatment effects, we fail to reject the null hypothesis , and should conclude that there is no significant differences to the measured treatment effects before and after the subjects' operations.","title":"Wilcoxon Signed-Rank Test"},{"location":"notebooks/High-Resolution-Spinal-Cord-Stimulation-for-Non-Opioid-Treatment-of-Neuropathic-Pain/#conclusions","text":"We found large, average percent descreases between pre and post operation data across all five measured treatment effects for subject's reported pain, depression, and pain induced disability. Using both parametric and non-parametric statistical testing we found there was a statistically significant difference to the subject's pain and disability as reported with the Numerical Rating Scale for pain and the Oswestry Disability Index for lower-back pain induced disability.","title":"Conclusions"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/","text":"Monitoring The Future: 12th Grader Opiate Use From 2012 To 2021 - Part 2 \u00b6 By J Montgomery Maxwell - Data Science, Sr. Analyst - CTDS \u00b6 Analysis Introduction \u00b6 About The Data \u00b6 The Monitoring The Future surveys are a series of surveys that have emerged as a vital tool in measuring the values, behaviors, and lifestyle orientations of American youth. Through a comprehensive series of surveys, these studies offer a unique glimpse into the ever-changing landscape of 12th grade students. There are approximately 1,400 variables across all of the questionnaires; while recognizing the vastness of the available data, our exploration will be primarily focused on a subset of variables deemed particularly relevant to our research. One of the critical aspects examined in the surveys pertains to the frequency of drug use among students, encompassing a wide array of illicit and recreational substances. In the context of this analysis, specific attention has been limited to surveys which observe instances where students engaged in the use of heroin or other opioid narcotics. While the investigation of drug use patterns holds significance in understanding the landscape of contemporary American youth, the Monitoring The Future surveys provide a broader canvas for exploration. Our analysis incorporates other topics including, but not limited to, students' perspectives on religion, educational goals, family life dynamics, and work habits. By examining these multidimensional facets, we may gain a holistic understanding of the myriad factors influencing the lives, aspirations, and substance use risks of American students. ! pip install seaborn - q ! pip install matplotlib - q ! pip install scikit - learn - q ! pip install xgboost - q ! pip install imblearn - q import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt import os from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import cross_validate from sklearn.svm import SVC from xgboost import XGBClassifier from sklearn.metrics import recall_score , precision_score , accuracy_score , confusion_matrix , ConfusionMatrixDisplay from sklearn.utils import resample from sklearn.decomposition import PCA from imblearn.over_sampling import SMOTE from imblearn.pipeline import Pipeline from IPython.display import Markdown , Image , display pd . set_option ( 'future.no_silent_downcasting' , True ) os . makedirs ( 'img/MTF_Part2' ) import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) Data Preperation \u00b6 As in our previous work, we exclude a number of variables due to their strong correlations. For instance, we observed among the survey recipients an expected connection between the number of alcoholic drinks consumed this year and the number of alcoholic drinks consumed in the last 30 days. We believe that the latter variable will serve as a more robust indicator for opiate use, so to streamline our analysis and enhance the veracity of our work, we made the decision to remove the former variable. After removing a number of observations that were missing data, we were left with approximately 42,000 observations spanning the 10 years of survey data. Most of the data you see below is either recorded as a binary outcome (1/yes or 0/no), as an ordinal value(i.e., 0 = no drug use, 1 = some drug use, 2 = frequent drug use), or as a categorical feature. The categorical data is encoded and represented as binary data, and the ordinal values were scaled down so that all of the data was within the range of 0 and 1. random_seed = 2023 variable_dict = { 'V1' : 'Year' , 'RESPONDENT_AGE' : 'Over18' , 'V13' : 'SchoolRegion' , 'V49' : 'NumberOfSiblings' , 'V2102' : 'Cigarettes/30Days' , 'V2106' : 'AlcoholicDrinks/30Days' , 'V2117' : 'Marijuana/30Days' , 'V2118' : 'LSD/Lifetime' , 'V2121' : 'Psychedelics/Lifetime' , 'V2124' : 'Cocaine/Lifetime' , 'V2127' : 'Amphetamines/Lifetime' , 'V2133' : 'Sedatives/Lifetime' , 'V2136' : 'Tranquilizers/Lifetime' , 'V2139' : 'Heroine/Lifetime' , 'V2142' : 'OpioidNarcotics/Lifetime' , 'V2150' : 'Sex' , 'V2151' : 'Race' , 'V2152' : 'RaisedWhere' , 'V2153' : 'MaritalStatus' , 'V2155' : 'LivesWithFather' , 'V2156' : 'LivesWithMother' , 'V2157' : 'LivesWithSiblings' , 'V2163' : 'FatherEduLvl' , 'V2164' : 'MotherEduLvl' , 'V2165' : 'MotherHadPaidJobWhileGrowingUp' , 'V2166' : 'PoliticalPreference' , 'V2167' : 'PoliticalBeliefs' , 'V2169' : 'ReligiousServiceAttendenceWkly' , 'V2170' : 'ReligionImportance' , 'V2172' : 'HighSchoolProgram' , 'V2174' : 'SelfRateIntelligence' , 'V2175' : 'SchoolDaysMissedIllness/4Weeks' , 'V2176' : 'SchoolDaysMissedSkipped/4Weeks' , 'V2177' : 'SchoolDaysMissedOther/4Weeks' , 'V2178' : 'SkippedClass/4Weeks' , 'V2179' : 'AverageGradeHS' , 'V2180' : 'LikelyToAttendVocationalSchl' , 'V2181' : 'LikelyToServeInMilitary' , 'V2182' : 'LikelyToGraduate2YrCollege' , 'V2183' : 'LikelyToGraduate4YrCollege' , 'V2184' : 'LikelyToAttendGraduateSchl' , 'V2185' : 'WantToDoVocationalSchl' , 'V2186' : 'WantToServeInMilitary' , 'V2187' : 'WantToDo2YrCollege' , 'V2188' : 'WantToDo4YrCollege' , 'V2189' : 'WantToDoGradSchl' , 'V2190' : 'WantToDoNo2ndEd' , 'V2191' : 'HrsWorkedPerWeek' , 'V2193' : 'MoneyFromOtherSource' , 'V2194' : 'EveningsOutPerWeek' , 'V2195' : 'DatesHowOften' , 'V2196' : 'MilesDrivenPerWeek' , 'V2197' : 'DrivingTickets' , 'V2201' : 'CarAccidentsLast12Mo' , 'V2459' : 'Crack/Lifetime' , } df_2012 = pd . read_csv ( 'Grade12/ICPSR_34861/DS0001/34861-0001-Data.tsv' , sep = ' \\t ' ) df_2013 = pd . read_csv ( 'Grade12/ICPSR_35218/DS0001/35218-0001-Data.tsv' , sep = ' \\t ' ) df_2014 = pd . read_csv ( 'Grade12/ICPSR_36263/DS0001/36263-0001-Data.tsv' , sep = ' \\t ' ) df_2015 = pd . read_csv ( 'Grade12/ICPSR_36408/DS0001/36408-0001-Data.tsv' , sep = ' \\t ' ) df_2016 = pd . read_csv ( 'Grade12/ICPSR_36798/DS0001/36798-0001-Data.tsv' , sep = ' \\t ' ) df_2017 = pd . read_csv ( 'Grade12/ICPSR_37182/DS0001/37182-0001-Data.tsv' , sep = ' \\t ' ) df_2018 = pd . read_csv ( 'Grade12/ICPSR_37416/DS0001/37416-0001-Data.tsv' , sep = ' \\t ' ) df_2019 = pd . read_csv ( 'Grade12/ICPSR_37841/DS0001/37841-0001-Data.tsv' , sep = ' \\t ' ) df_2020 = pd . read_csv ( 'Grade12/ICPSR_38156/DS0001/38156-0001-Data.tsv' , sep = ' \\t ' ) df_2021 = pd . read_csv ( 'Grade12/ICPSR_38503/DS0001/38503-0001-Data.tsv' , sep = ' \\t ' ) df_list = [ df_2012 , df_2013 , df_2014 , df_2015 , df_2016 , df_2017 , df_2018 , df_2019 , df_2020 , df_2021 ] year_list = [ 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 , 2021 ] vars = set ( list ( df_2012 . columns )) for df in df_list : vars = set ( vars & set ( list ( df . columns ))) variables = list ( vars ) df = pd . concat ([ x [ variables ] for x in df_list ], ignore_index = True ) df = df [ variable_dict . keys ()] # Remove missing data missing_criteria = ( df == - 9 ) . sum () < 0.3 * len ( df . index ) df = df [ missing_criteria . index [ missing_criteria ]] minimal_missing = [] for i in df . index : cnt = sum ( df . iloc [ i , :] == - 9 ) if cnt < 1 : minimal_missing . append ( i ) df = df [ df . index . isin ( minimal_missing )] # Combine Opiate Use data df [ 'OpiateUse' ] = (( df [ 'V2142' ] != 1 ) + ( df [ 'V2139' ] != 1 )) . astype ( int ) df = df . drop ([ 'V2142' , 'V2139' ], axis = 1 ) # Rename columns using data dictionary df . rename ( columns = variable_dict , inplace = True ) # Factor categorical data dummy_cols = [ 'SchoolRegion' , 'Race' , 'RaisedWhere' , 'MaritalStatus' , 'PoliticalPreference' , 'PoliticalBeliefs' , 'HighSchoolProgram' ] dummies = pd . get_dummies ( df [ dummy_cols ], columns = dummy_cols , drop_first = True ) df = pd . concat ([ df , dummies ], axis = 1 ) df = df . drop ( dummy_cols , axis = 1 ) # Normalize data df = df . replace ({ False : 0 , True : 1 }) years_vec = df [ 'Year' ] df = ( df - df . min ()) / ( df . max () - df . min ()) df [ 'Year' ] = years_vec df = df . reset_index ( drop = True ) Analysis And Visualization \u00b6 Annual Oppiate Use Rate \u00b6 Here we find a steady decline in opiate use rates amongst the surveyed 12th graders. There is a significant drop in opiate abuse in 2021, however this abnormal decrease could be from a number of outlying conditions such as the COVID-19 pandemic and the subsequent stay at home orders and work from home school policies. series = ( df . groupby ( 'Year' )[ 'OpiateUse' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Opiate Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure1.png' ) Image ( filename = \"img/MTF_Part2/figure1.png\" ) Rate Of Illicit Substance Use Coinciding With Opiate Abuse \u00b6 Below we can see that more than half of all those surveyed who had ever used tranquilzers, cocaine, and pychedelics had also abused opiates or opioid narcotics at somepoint in their lives. Rates of coinciding sedative, amphetamine, and LSD use are not far behind. drug_use_df = df [[ 'Tranquilizers/Lifetime' , 'Amphetamines/Lifetime' , 'Sedatives/Lifetime' , 'Marijuana/30Days' , 'Cocaine/Lifetime' , 'Cigarettes/30Days' , 'Psychedelics/Lifetime' , 'AlcoholicDrinks/30Days' , 'LSD/Lifetime' , 'OpiateUse' ]] ratio_dict = {} for col in drug_use_df . columns : ratio = drug_use_df . loc [(( drug_use_df [ col ] > 0 ) & ( drug_use_df [ 'OpiateUse' ] > 0 ))] . shape [ 0 ] / drug_use_df . loc [( drug_use_df [ col ] > 0 )] . shape [ 0 ] ratio_dict [ col ] = ratio ratio_dict . pop ( 'OpiateUse' , None ) ratio_dict {'Tranquilizers/Lifetime': 0.5340777820562187, 'Amphetamines/Lifetime': 0.41908396946564885, 'Sedatives/Lifetime': 0.47626186906546725, 'Marijuana/30Days': 0.21841463414634146, 'Cocaine/Lifetime': 0.600326264274062, 'Cigarettes/30Days': 0.29249941217963793, 'Psychedelics/Lifetime': 0.5078625509609784, 'AlcoholicDrinks/30Days': 0.14727359585067903, 'LSD/Lifetime': 0.4786096256684492} If readers are familiar with the previous analysis on the HEAL platform: Monitoring The Future: 12th Grader Opiate Use - Part 1 , an undeniable connection was identified by the machine learning models used in that notebook between opioid abuse and other drug use for 12th graders in 2019. While that connection appears to exist again, let's examine if the same descrease in opioid use is present with other drug use amongst 12th graders. Annual Cocaine Use Rate \u00b6 series = ( df . groupby ( 'Year' )[ 'Cocaine/Lifetime' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Cocaine Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure2.png' ) Image ( filename = \"img/MTF_Part2/figure2.png\" ) Annual Tranquilzer Use Rate \u00b6 series = ( df . groupby ( 'Year' )[ 'Tranquilizers/Lifetime' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Tranquilizer Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure3.png' ) Image ( filename = \"img/MTF_Part2/figure3.png\" ) Annual Sedatives Use Rate \u00b6 series = ( df . groupby ( 'Year' )[ 'Sedatives/Lifetime' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Sedatives Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure4.png' ) Image ( filename = \"img/MTF_Part2/figure4.png\" ) Annual Amphetamines Use Rate \u00b6 series = ( df . groupby ( 'Year' )[ 'Amphetamines/Lifetime' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Amphetamines Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure5.png' ) Image ( filename = \"img/MTF_Part2/figure5.png\" ) While there is a substantial decrease in the use of amphetamines, sedatives, tranquilizers, and cocaine in 2021, we do not see the same slow decline in their usage from 2012 to 2020. It is, however, worth noting the significant degree to which opioids are abused compared to the other illicit substances. Opiate use peaked at over 11% in 2012, while all of the other substances have peaks between 1% and 6%. * Opiate use is a combined measurement of the heroin and opioid narcotic use survey results. Cross Validation, Hyperparameter Tuning, And Model Selection \u00b6 The work done in the first example analysis notebook in this series used SMOTE (Synthetic Minority Oversampling Technique) and multiple, simpler classification models, such as logistic regression and random forest classification. This notebook will use the XGB (Extreme Gradient Boosting) classification algorithm. Unlike with the simpler models used previously, the XGBClassifier does not require the use of SMOTE. Instead, we will use the XGBClassifier hyperparameter, 'scale_pos_weight'. When classes are imbalanced, 'scale_pos_weight' is typically set as the ratio of the number of overrepresented observations (no opiate use) to the number of underrepresented observations (opiate use). This hyperparameter scales the gradient of the positive, underrepresented class, thus scaling the errors of the positive class during the model training step. While 'scale_pos_weight' is taken at the suggested value, most of the other hyperparameters to the XGBClassifier model were tuned using the grid search and 10-fold cross validation methods. In other words, we exhaustively tested multiple combinations of hyperparameters from a subset of possible values and verified the optimal combination of hyperparameters using 10-fold cross validation. Below you will find the function used for cross validation and the final model used with the tuned hyperparameters. def pipeline_cross_validation ( data , k , pipeline_steps ): folds = np . array_split ( data , k ) accuracySum = 0 recallSum = 0 precisionSum = 0 for i in range ( k ): train = folds . copy () test = folds [ i ] del train [ i ] train = pd . concat ( train , sort = False ) y_train = train . OpiateUse . astype ( int ) X_train = train . drop ( 'OpiateUse' , axis = 1 ) y_test = test . OpiateUse . astype ( int ) X_test = test . drop ( 'OpiateUse' , axis = 1 ) pipeline = Pipeline ( pipeline_steps ) . fit ( X_train , y_train ) y_pred = pipeline . predict ( X_test ) accuracySum += accuracy_score ( y_test , y_pred ) recallSum += recall_score ( y_test , y_pred ) precisionSum += precision_score ( y_test , y_pred ) return [ accuracySum / k , recallSum / k , precisionSum / k ] df1 = df . drop ([ 'Year' ], axis = 1 ) df1 = df1 . astype ( float ) model = XGBClassifier ( learning_rate = 0.01 , n_estimators = 200 , max_depth = 5 , min_child_weight = 1 , gamma = 0.6 , subsample = 0.8 , colsample_bytree = 0.7 , objective = 'binary:logistic' , enable_categorical = 'True' , seed = random_seed , scale_pos_weight = len ( df1 ) / sum ( df1 [ 'OpiateUse' ])) steps = [( 'model' , model )] score = pipeline_cross_validation ( df1 , k = 10 , pipeline_steps = steps ) print ( f 'Accuracy: { score [ 0 ] } | Precision: { score [ 1 ] } | Recall: { score [ 2 ] } ' ) Accuracy: 0.8603258289775144 | Precision: 0.7657892432458844 | Recall: 0.31582818104175825 Opioid Use Classification \u00b6 This first iteration of model training, testing, and evaluation will use all 10 years of data spaning from 2012 to 2021. This model will be the same XGBClassifier that was tuned and validated above. After the model is trained, we will examine the model's performance by looking at the model's accuracy, precision, and recall metrics. Model accuracy will tell us the model's rate of correctly classifying both the students who have and have not ever abused opiates; model recall will tell us the model's rate of correctly identifying all of the students who have abused opiates, and model precision will tell us the model's rate of correctly identifying students who have abused opiates amongst all students the model identifies as having used opiates. After examining the model's performance and the corresponding confusion matrix, we will look at what the model considers to be the most and least relevant features to capturing students' opiate use behavior. X = df1 . drop ( 'OpiateUse' , axis = 1 ) y = df1 . OpiateUse X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = random_seed ) model = XGBClassifier ( learning_rate = 0.01 , n_estimators = 200 , max_depth = 5 , min_child_weight = 1 , gamma = 0.6 , subsample = 0.8 , colsample_bytree = 0.7 , objective = 'binary:logistic' , seed = random_seed , scale_pos_weight = len ( df1 ) / sum ( df1 [ 'OpiateUse' ])) steps = [( 'model' , model )] boosted_model = model . fit ( X_train , y_train ) y_pred = boosted_model . predict ( X_test ) Model Performance \u00b6 The following model scores are scaled between 0 and 1, with 1 being perfect performance. The scores and the corresponding confusion matrix tells us that the model performs relatively well at identifying students who have ever used opiates illicitly, identifying almost 78% of all students who have used opiates illicitly, and performs well at correctly classifying 85% of all students in either category. However, the model does a poor job at identifying only those who abused opioids amongst the student population. In fact, almost 70% of the students our model says have used opioids illicitly have not. Model Scores \u00b6 print ( f 'Accuracy: { accuracy_score ( y_test , y_pred ) } | Precision: { precision_score ( y_test , y_pred ) } | Recall: { recall_score ( y_test , y_pred ) } ' ) Accuracy: 0.8550380821575727 | Precision: 0.31851360318513605 | Recall: 0.7817589576547231 Confuion Matrix \u00b6 disp = ConfusionMatrixDisplay ( confusion_matrix ( y_test , y_pred )) disp . plot () disp . im_ . colorbar . remove () fig = disp . figure_ plt . close () fig . figure . savefig ( 'img/MTF_Part2/figure6.png' ) Image ( filename = \"img/MTF_Part2/figure6.png\" ) Most Important Features \u00b6 feature_importance = pd . DataFrame ( index = df1 . columns . drop ( 'OpiateUse' )) feature_importance [ f 'Feature Importance' ] = ( boosted_model . feature_importances_ - min ( boosted_model . feature_importances_ )) / ( max ( boosted_model . feature_importances_ ) - min ( boosted_model . feature_importances_ )) Markdown ( feature_importance . sort_values ( by = [ 'Feature Importance' ], ascending = False ) . head ( 15 ) . to_markdown ()) Feature Importance Amphetamines/Lifetime 1 Tranquilizers/Lifetime 0.449333 Marijuana/30Days 0.335475 Sedatives/Lifetime 0.152119 AlcoholicDrinks/30Days 0.129192 Cigarettes/30Days 0.105862 LivesWithSiblings 0.0666517 Psychedelics/Lifetime 0.0630031 Cocaine/Lifetime 0.0601336 MilesDrivenPerWeek 0.0462572 LSD/Lifetime 0.0363287 DrivingTickets 0.0314236 SkippedClass/4Weeks 0.02358 MoneyFromOtherSource 0.0222268 LivesWithMother 0.021669 Least Important Features \u00b6 Markdown ( feature_importance . sort_values ( by = [ 'Feature Importance' ], ascending = False ) . tail ( 15 ) . to_markdown ()) Feature Importance PoliticalPreference_2 0.00565269 MotherEduLvl 0.00560381 PoliticalBeliefs_2 0.00553094 MotherHadPaidJobWhileGrowingUp 0.00535169 RaisedWhere_9 0.00510992 Crack/Lifetime 0.00484198 HrsWorkedPerWeek 0.00477158 DatesHowOften 0.00447595 RaisedWhere_4 0.00430372 RaisedWhere_8 0.00428398 HighSchoolProgram_4 0.00370746 MaritalStatus_2 0.00318217 Over18 0.00306294 PoliticalPreference_3 0.00255435 PoliticalPreference_7 0 Above we see the 15 most and least important features ranked by their normalized feature importance scores. These feature scores are an indication of the relative amount each feature improves upon the performance of the model when making a decision along the given feature. As with our work in part one, we find that the students' use of other illicit substances are the most telling indicators as to whether a student will use opiates or opioid narcotics. We also find that the students race, political preference or beliefs, and where students are raised gives little to no indication towards whether they will abuse opioids. Annual Opioid Use Classification \u00b6 Next we will rerun this analysis but focus on only one year of data at a time. We will use the same hyperparameters as before for these newly trained models, since the computation for hyperparameter tuning takes a significant amount of time. After training the 10 models for the 10 years of data, we will again examine the models' performance and ranked feature importance. Training And Testing Model On Annual Data \u00b6 feature_importance = pd . DataFrame ( index = df1 . columns . drop ( 'OpiateUse' )) classification_scores = pd . DataFrame ({ 'Metric' : [ 'Accuracy' , 'Precision' , 'Recall' ]}) for year in year_list : df_annual = df [ df [ 'Year' ] == year ] df_annual = df_annual . drop ([ 'Year' ], axis = 1 ) df_annual = df_annual . astype ( float ) X = df_annual . drop ( 'OpiateUse' , axis = 1 ) y = df_annual . OpiateUse . astype ( int ) X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = random_seed ) model = XGBClassifier ( learning_rate = 0.01 , n_estimators = 200 , max_depth = 5 , min_child_weight = 1 , gamma = 0.6 , subsample = 0.8 , colsample_bytree = 0.7 , objective = 'binary:logistic' , enable_categorical = True , seed = random_seed , scale_pos_weight = len ( df_annual ) / sum ( df_annual [ 'OpiateUse' ])) boosted_model = model . fit ( X_train , y_train ) y_pred = boosted_model . predict ( X_test ) feature_importance [ f 'Feature Importance { year } ' ] = ( boosted_model . feature_importances_ - min ( boosted_model . feature_importances_ )) / ( max ( boosted_model . feature_importances_ ) - min ( boosted_model . feature_importances_ )) classification_scores [ f 'Model Performance { year } ' ] = [ accuracy_score ( y_test , y_pred ), precision_score ( y_test , y_pred ), recall_score ( y_test , y_pred )] Annual Accuracy And Precision Scores \u00b6 Below we can see that for the first few years our model's performance is only slightly below the previous performance of the model using all 10 years of data. In 2020 and 2021, the models do not perform nearly as well as the models trained on prior annual data or the model trained using all of the data. The underperformance of the models from earlier years compared to our first model is to be expected, as we are training those models on a much smaller subset of data. However, the poor performance of the later models cannot be completely explained by the difference in size of the training data. The lower performance of the models from 2020 and 2021 may be explained by the disruption to behavior caused by the COVID-19 pandemic, but may also be exlpained by the massive decrease in the opioid use rate of the 12th graders surveyed in 2021. Markdown ( classification_scores . to_markdown ()) Metric Model Performance 2012 Model Performance 2013 Model Performance 2014 Model Performance 2015 Model Performance 2016 Model Performance 2017 Model Performance 2018 Model Performance 2019 Model Performance 2020 Model Performance 2021 0 Accuracy 0.864261 0.871503 0.892216 0.89576 0.891626 0.917513 0.91247 0.911633 0.921875 0.9681 1 Precision 0.444444 0.42246 0.476923 0.351852 0.391667 0.488636 0.344086 0.358696 0.388889 0.4 2 Recall 0.75188 0.669492 0.738095 0.44186 0.758065 0.68254 0.727273 0.622642 0.4375 0.555556 Most important features each year \u00b6 Like before, we see the same relation between between general illicit substance use and illicit opiate use. It is worth noting that the use of tranqulizers and amphetamines typically took the top 1 and 2 positions for most influential features until 2021, when they fell to the 4th and 5th ranking. This is another indicator that something significant shifted in our model's classification of 12th grader opiate use. df12 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2012' ], ascending = False )[ 'Feature Importance 2012' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df12 [ 'Feature Importance 2012' ] = df12 [ 'Feature' ] + \" - \" + df12 [ \"Feature Importance 2012\" ] . astype ( str ) df12 = df12 . drop ([ 'Feature' ], axis = 1 ) df13 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2013' ], ascending = False )[ 'Feature Importance 2013' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df13 [ 'Feature Importance 2013' ] = df13 [ 'Feature' ] + \" - \" + df13 [ \"Feature Importance 2013\" ] . astype ( str ) df13 = df13 . drop ([ 'Feature' ], axis = 1 ) df14 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2014' ], ascending = False )[ 'Feature Importance 2014' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df14 [ 'Feature Importance 2014' ] = df14 [ 'Feature' ] + \" - \" + df14 [ \"Feature Importance 2014\" ] . astype ( str ) df14 = df14 . drop ([ 'Feature' ], axis = 1 ) df15 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2015' ], ascending = False )[ 'Feature Importance 2015' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df15 [ 'Feature Importance 2015' ] = df15 [ 'Feature' ] + \" - \" + df15 [ \"Feature Importance 2015\" ] . astype ( str ) df15 = df15 . drop ([ 'Feature' ], axis = 1 ) df16 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2016' ], ascending = False )[ 'Feature Importance 2016' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df16 [ 'Feature Importance 2016' ] = df16 [ 'Feature' ] + \" - \" + df16 [ \"Feature Importance 2016\" ] . astype ( str ) df16 = df16 . drop ([ 'Feature' ], axis = 1 ) df17 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2017' ], ascending = False )[ 'Feature Importance 2017' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df17 [ 'Feature Importance 2017' ] = df17 [ 'Feature' ] + \" - \" + df17 [ \"Feature Importance 2017\" ] . astype ( str ) df17 = df17 . drop ([ 'Feature' ], axis = 1 ) df18 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2018' ], ascending = False )[ 'Feature Importance 2018' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df18 [ 'Feature Importance 2018' ] = df18 [ 'Feature' ] + \" - \" + df18 [ \"Feature Importance 2018\" ] . astype ( str ) df18 = df18 . drop ([ 'Feature' ], axis = 1 ) df19 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2019' ], ascending = False )[ 'Feature Importance 2019' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df19 [ 'Feature Importance 2019' ] = df19 [ 'Feature' ] + \" - \" + df19 [ \"Feature Importance 2019\" ] . astype ( str ) df19 = df19 . drop ([ 'Feature' ], axis = 1 ) df20 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2020' ], ascending = False )[ 'Feature Importance 2020' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df20 [ 'Feature Importance 2020' ] = df20 [ 'Feature' ] + \" - \" + df20 [ \"Feature Importance 2020\" ] . astype ( str ) df20 = df20 . drop ([ 'Feature' ], axis = 1 ) df21 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2021' ], ascending = False )[ 'Feature Importance 2021' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df21 [ 'Feature Importance 2021' ] = df21 [ 'Feature' ] + \" - \" + df21 [ \"Feature Importance 2021\" ] . astype ( str ) df21 = df21 . drop ([ 'Feature' ], axis = 1 ) Markdown ( pd . concat ([ df12 , df13 , df14 , df15 , df16 , df17 , df18 , df19 , df20 , df21 ], axis = 1 ) . to_markdown ()) Feature Importance 2012 Feature Importance 2013 Feature Importance 2014 Feature Importance 2015 Feature Importance 2016 Feature Importance 2017 Feature Importance 2018 Feature Importance 2019 Feature Importance 2020 Feature Importance 2021 0 Amphetamines/Lifetime - 1.0 Amphetamines/Lifetime - 1.0 Amphetamines/Lifetime - 1.0 Amphetamines/Lifetime - 1.0 Amphetamines/Lifetime - 1.0 Tranquilizers/Lifetime - 1.0 Tranquilizers/Lifetime - 1.0 Tranquilizers/Lifetime - 1.0 Tranquilizers/Lifetime - 1.0 Psychedelics/Lifetime - 1.0 1 Marijuana/30Days - 0.75576615 Tranquilizers/Lifetime - 0.55172384 Tranquilizers/Lifetime - 0.5155145 Tranquilizers/Lifetime - 0.32245028 Tranquilizers/Lifetime - 0.49392527 Amphetamines/Lifetime - 0.87034947 Amphetamines/Lifetime - 0.34006974 Amphetamines/Lifetime - 0.46549627 Amphetamines/Lifetime - 0.82667917 Sedatives/Lifetime - 0.9135607 2 Tranquilizers/Lifetime - 0.65975815 Sedatives/Lifetime - 0.35604864 Marijuana/30Days - 0.3510031 Marijuana/30Days - 0.27957878 Marijuana/30Days - 0.30306983 Marijuana/30Days - 0.4922091 Marijuana/30Days - 0.20515968 AlcoholicDrinks/30Days - 0.26642838 Sedatives/Lifetime - 0.60782486 LSD/Lifetime - 0.70153475 3 Sedatives/Lifetime - 0.23304458 Cigarettes/30Days - 0.22533654 Sedatives/Lifetime - 0.24436365 Cigarettes/30Days - 0.26259112 Crack/Lifetime - 0.1769505 Cigarettes/30Days - 0.3307903 DrivingTickets - 0.12938854 LSD/Lifetime - 0.25456077 Marijuana/30Days - 0.36239895 Tranquilizers/Lifetime - 0.66015655 4 AlcoholicDrinks/30Days - 0.16919222 Marijuana/30Days - 0.22409648 AlcoholicDrinks/30Days - 0.19529353 Cocaine/Lifetime - 0.23002389 Sedatives/Lifetime - 0.17548333 Sedatives/Lifetime - 0.28806037 Sedatives/Lifetime - 0.121947214 Marijuana/30Days - 0.2489249 PoliticalBeliefs_6 - 0.33769482 Marijuana/30Days - 0.52852654 5 Cigarettes/30Days - 0.15726869 AlcoholicDrinks/30Days - 0.1261193 Psychedelics/Lifetime - 0.1708248 Psychedelics/Lifetime - 0.22408944 LSD/Lifetime - 0.14090925 DrivingTickets - 0.26170564 PoliticalPreference_6 - 0.11954165 Psychedelics/Lifetime - 0.19040935 WantToDo2YrCollege - 0.3267634 Amphetamines/Lifetime - 0.49161762 6 Crack/Lifetime - 0.15701917 PoliticalPreference_7 - 0.1104126 Cocaine/Lifetime - 0.17024292 RaisedWhere_1 - 0.17279556 PoliticalBeliefs_6 - 0.12900716 Crack/Lifetime - 0.21362005 LivesWithSiblings - 0.117574446 Cocaine/Lifetime - 0.15222396 LSD/Lifetime - 0.31751463 RaisedWhere_7 - 0.4318025 7 WantToServeInMilitary - 0.14331344 MaritalStatus_2 - 0.10724328 PoliticalPreference_7 - 0.16727918 Sedatives/Lifetime - 0.1554664 AlcoholicDrinks/30Days - 0.12395912 Cocaine/Lifetime - 0.19935064 Cocaine/Lifetime - 0.10532992 WantToServeInMilitary - 0.15194388 SchoolDaysMissedIllness/4Weeks - 0.29573283 PoliticalPreference_7 - 0.42327297 8 Psychedelics/Lifetime - 0.14275527 Psychedelics/Lifetime - 0.10488076 MaritalStatus_3 - 0.15278761 PoliticalBeliefs_6 - 0.14911336 PoliticalBeliefs_8 - 0.11484937 SkippedClass/4Weeks - 0.18681203 RaisedWhere_7 - 0.10298768 Cigarettes/30Days - 0.1502413 SkippedClass/4Weeks - 0.29407594 WantToDoVocationalSchl - 0.39966732 9 LivesWithSiblings - 0.13939653 RaisedWhere_8 - 0.083930984 DrivingTickets - 0.15190427 SchoolRegion_3 - 0.1441104 Over18 - 0.11348703 SchoolRegion_3 - 0.16396773 MoneyFromOtherSource - 0.102316245 SkippedClass/4Weeks - 0.14667954 DatesHowOften - 0.28880978 SchoolRegion_2 - 0.38491154 Conclusion \u00b6 Using the XGBoost (extreme gradient boosting) classifier algorithm and cross-validation techniques, we successfully tuned, trained, and tested an XGBClassifier model on survey data from 2012 to 2021 for classifying whether a student surveyed had ever opioids illicitly. The model trained using all 10 years of data had a fairly high model accuracy score of 0.86 and a model recall score of 0.77 during cross-validation. In other words, the model correctly identified whether a student had or had not ever illicitly used opioids 86% of the time and correctly identified 77% of the students who had used opioids illicitly. Following our model fitting, testing, and feature analysis on all 10 years of data, we refit our model on each year of data seperately, keeping the same hyperparameter tunings. While many of these annual models did not perform as well as the initial model with all 10 years worth of data, this can easily be explained by differences in the size of the training datasets. However, the models for 2020 and 2021 performed poorly even when compared to the models trained on the previous years data; this suggests some additioanl influence is taking place upon the survey data for 2020 and 2021. The two most obvious influences would be the significant decrease in the reported rate of opioid use in 2021 and the possible effects of the COVID-19 pandemic on the survey methodology and/or the changes in the actual behavior of the surveyed 12th graders. Like with our previous work in part one of this series, many of the identified important variables aligned with expectations, both when modeling the annual datasets and the entire dataset spanning from 2012 to 2021. It was not surprising to find that students who engaged in various illicit drug use and underage drinking were at higher risk of using opiates and heroin. It is worth noting: from 2012 to 2016, use of amphetamine, followed by the use of tranquilizers, was considered by the models to be the best indicator of opioid use. From 2017 to 2020, those positions switched. In 2021, the use of amphetamine and tranquilizers became a significantly less influential indicator. Future Work \u00b6 Future work is planned to further analyze the lifestyle, behaviors, and opiate use of the survey subjects from 2021. Particular emphasis will be placed on examining what other behavioral and lifestyle changes occured amongst 12th graders that might coincide with the decreased rate of illicit opiate use as found amongst the MTF survey participants.","title":"MTF 12th Grader Opiate Use In 2012-2021"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#monitoring-the-future-12th-grader-opiate-use-from-2012-to-2021-part-2","text":"","title":"Monitoring The Future: 12th Grader Opiate Use From 2012 To 2021 - Part 2"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#by-j-montgomery-maxwell-data-science-sr-analyst-ctds","text":"","title":"By J Montgomery Maxwell - Data Science, Sr. Analyst - CTDS"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#analysis-introduction","text":"","title":"Analysis Introduction"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#about-the-data","text":"The Monitoring The Future surveys are a series of surveys that have emerged as a vital tool in measuring the values, behaviors, and lifestyle orientations of American youth. Through a comprehensive series of surveys, these studies offer a unique glimpse into the ever-changing landscape of 12th grade students. There are approximately 1,400 variables across all of the questionnaires; while recognizing the vastness of the available data, our exploration will be primarily focused on a subset of variables deemed particularly relevant to our research. One of the critical aspects examined in the surveys pertains to the frequency of drug use among students, encompassing a wide array of illicit and recreational substances. In the context of this analysis, specific attention has been limited to surveys which observe instances where students engaged in the use of heroin or other opioid narcotics. While the investigation of drug use patterns holds significance in understanding the landscape of contemporary American youth, the Monitoring The Future surveys provide a broader canvas for exploration. Our analysis incorporates other topics including, but not limited to, students' perspectives on religion, educational goals, family life dynamics, and work habits. By examining these multidimensional facets, we may gain a holistic understanding of the myriad factors influencing the lives, aspirations, and substance use risks of American students. ! pip install seaborn - q ! pip install matplotlib - q ! pip install scikit - learn - q ! pip install xgboost - q ! pip install imblearn - q import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt import os from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import cross_validate from sklearn.svm import SVC from xgboost import XGBClassifier from sklearn.metrics import recall_score , precision_score , accuracy_score , confusion_matrix , ConfusionMatrixDisplay from sklearn.utils import resample from sklearn.decomposition import PCA from imblearn.over_sampling import SMOTE from imblearn.pipeline import Pipeline from IPython.display import Markdown , Image , display pd . set_option ( 'future.no_silent_downcasting' , True ) os . makedirs ( 'img/MTF_Part2' ) import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning )","title":"About The Data"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#data-preperation","text":"As in our previous work, we exclude a number of variables due to their strong correlations. For instance, we observed among the survey recipients an expected connection between the number of alcoholic drinks consumed this year and the number of alcoholic drinks consumed in the last 30 days. We believe that the latter variable will serve as a more robust indicator for opiate use, so to streamline our analysis and enhance the veracity of our work, we made the decision to remove the former variable. After removing a number of observations that were missing data, we were left with approximately 42,000 observations spanning the 10 years of survey data. Most of the data you see below is either recorded as a binary outcome (1/yes or 0/no), as an ordinal value(i.e., 0 = no drug use, 1 = some drug use, 2 = frequent drug use), or as a categorical feature. The categorical data is encoded and represented as binary data, and the ordinal values were scaled down so that all of the data was within the range of 0 and 1. random_seed = 2023 variable_dict = { 'V1' : 'Year' , 'RESPONDENT_AGE' : 'Over18' , 'V13' : 'SchoolRegion' , 'V49' : 'NumberOfSiblings' , 'V2102' : 'Cigarettes/30Days' , 'V2106' : 'AlcoholicDrinks/30Days' , 'V2117' : 'Marijuana/30Days' , 'V2118' : 'LSD/Lifetime' , 'V2121' : 'Psychedelics/Lifetime' , 'V2124' : 'Cocaine/Lifetime' , 'V2127' : 'Amphetamines/Lifetime' , 'V2133' : 'Sedatives/Lifetime' , 'V2136' : 'Tranquilizers/Lifetime' , 'V2139' : 'Heroine/Lifetime' , 'V2142' : 'OpioidNarcotics/Lifetime' , 'V2150' : 'Sex' , 'V2151' : 'Race' , 'V2152' : 'RaisedWhere' , 'V2153' : 'MaritalStatus' , 'V2155' : 'LivesWithFather' , 'V2156' : 'LivesWithMother' , 'V2157' : 'LivesWithSiblings' , 'V2163' : 'FatherEduLvl' , 'V2164' : 'MotherEduLvl' , 'V2165' : 'MotherHadPaidJobWhileGrowingUp' , 'V2166' : 'PoliticalPreference' , 'V2167' : 'PoliticalBeliefs' , 'V2169' : 'ReligiousServiceAttendenceWkly' , 'V2170' : 'ReligionImportance' , 'V2172' : 'HighSchoolProgram' , 'V2174' : 'SelfRateIntelligence' , 'V2175' : 'SchoolDaysMissedIllness/4Weeks' , 'V2176' : 'SchoolDaysMissedSkipped/4Weeks' , 'V2177' : 'SchoolDaysMissedOther/4Weeks' , 'V2178' : 'SkippedClass/4Weeks' , 'V2179' : 'AverageGradeHS' , 'V2180' : 'LikelyToAttendVocationalSchl' , 'V2181' : 'LikelyToServeInMilitary' , 'V2182' : 'LikelyToGraduate2YrCollege' , 'V2183' : 'LikelyToGraduate4YrCollege' , 'V2184' : 'LikelyToAttendGraduateSchl' , 'V2185' : 'WantToDoVocationalSchl' , 'V2186' : 'WantToServeInMilitary' , 'V2187' : 'WantToDo2YrCollege' , 'V2188' : 'WantToDo4YrCollege' , 'V2189' : 'WantToDoGradSchl' , 'V2190' : 'WantToDoNo2ndEd' , 'V2191' : 'HrsWorkedPerWeek' , 'V2193' : 'MoneyFromOtherSource' , 'V2194' : 'EveningsOutPerWeek' , 'V2195' : 'DatesHowOften' , 'V2196' : 'MilesDrivenPerWeek' , 'V2197' : 'DrivingTickets' , 'V2201' : 'CarAccidentsLast12Mo' , 'V2459' : 'Crack/Lifetime' , } df_2012 = pd . read_csv ( 'Grade12/ICPSR_34861/DS0001/34861-0001-Data.tsv' , sep = ' \\t ' ) df_2013 = pd . read_csv ( 'Grade12/ICPSR_35218/DS0001/35218-0001-Data.tsv' , sep = ' \\t ' ) df_2014 = pd . read_csv ( 'Grade12/ICPSR_36263/DS0001/36263-0001-Data.tsv' , sep = ' \\t ' ) df_2015 = pd . read_csv ( 'Grade12/ICPSR_36408/DS0001/36408-0001-Data.tsv' , sep = ' \\t ' ) df_2016 = pd . read_csv ( 'Grade12/ICPSR_36798/DS0001/36798-0001-Data.tsv' , sep = ' \\t ' ) df_2017 = pd . read_csv ( 'Grade12/ICPSR_37182/DS0001/37182-0001-Data.tsv' , sep = ' \\t ' ) df_2018 = pd . read_csv ( 'Grade12/ICPSR_37416/DS0001/37416-0001-Data.tsv' , sep = ' \\t ' ) df_2019 = pd . read_csv ( 'Grade12/ICPSR_37841/DS0001/37841-0001-Data.tsv' , sep = ' \\t ' ) df_2020 = pd . read_csv ( 'Grade12/ICPSR_38156/DS0001/38156-0001-Data.tsv' , sep = ' \\t ' ) df_2021 = pd . read_csv ( 'Grade12/ICPSR_38503/DS0001/38503-0001-Data.tsv' , sep = ' \\t ' ) df_list = [ df_2012 , df_2013 , df_2014 , df_2015 , df_2016 , df_2017 , df_2018 , df_2019 , df_2020 , df_2021 ] year_list = [ 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 , 2021 ] vars = set ( list ( df_2012 . columns )) for df in df_list : vars = set ( vars & set ( list ( df . columns ))) variables = list ( vars ) df = pd . concat ([ x [ variables ] for x in df_list ], ignore_index = True ) df = df [ variable_dict . keys ()] # Remove missing data missing_criteria = ( df == - 9 ) . sum () < 0.3 * len ( df . index ) df = df [ missing_criteria . index [ missing_criteria ]] minimal_missing = [] for i in df . index : cnt = sum ( df . iloc [ i , :] == - 9 ) if cnt < 1 : minimal_missing . append ( i ) df = df [ df . index . isin ( minimal_missing )] # Combine Opiate Use data df [ 'OpiateUse' ] = (( df [ 'V2142' ] != 1 ) + ( df [ 'V2139' ] != 1 )) . astype ( int ) df = df . drop ([ 'V2142' , 'V2139' ], axis = 1 ) # Rename columns using data dictionary df . rename ( columns = variable_dict , inplace = True ) # Factor categorical data dummy_cols = [ 'SchoolRegion' , 'Race' , 'RaisedWhere' , 'MaritalStatus' , 'PoliticalPreference' , 'PoliticalBeliefs' , 'HighSchoolProgram' ] dummies = pd . get_dummies ( df [ dummy_cols ], columns = dummy_cols , drop_first = True ) df = pd . concat ([ df , dummies ], axis = 1 ) df = df . drop ( dummy_cols , axis = 1 ) # Normalize data df = df . replace ({ False : 0 , True : 1 }) years_vec = df [ 'Year' ] df = ( df - df . min ()) / ( df . max () - df . min ()) df [ 'Year' ] = years_vec df = df . reset_index ( drop = True )","title":"Data Preperation"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#analysis-and-visualization","text":"","title":"Analysis And Visualization"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#annual-oppiate-use-rate","text":"Here we find a steady decline in opiate use rates amongst the surveyed 12th graders. There is a significant drop in opiate abuse in 2021, however this abnormal decrease could be from a number of outlying conditions such as the COVID-19 pandemic and the subsequent stay at home orders and work from home school policies. series = ( df . groupby ( 'Year' )[ 'OpiateUse' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Opiate Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure1.png' ) Image ( filename = \"img/MTF_Part2/figure1.png\" )","title":"Annual Oppiate Use Rate"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#rate-of-illicit-substance-use-coinciding-with-opiate-abuse","text":"Below we can see that more than half of all those surveyed who had ever used tranquilzers, cocaine, and pychedelics had also abused opiates or opioid narcotics at somepoint in their lives. Rates of coinciding sedative, amphetamine, and LSD use are not far behind. drug_use_df = df [[ 'Tranquilizers/Lifetime' , 'Amphetamines/Lifetime' , 'Sedatives/Lifetime' , 'Marijuana/30Days' , 'Cocaine/Lifetime' , 'Cigarettes/30Days' , 'Psychedelics/Lifetime' , 'AlcoholicDrinks/30Days' , 'LSD/Lifetime' , 'OpiateUse' ]] ratio_dict = {} for col in drug_use_df . columns : ratio = drug_use_df . loc [(( drug_use_df [ col ] > 0 ) & ( drug_use_df [ 'OpiateUse' ] > 0 ))] . shape [ 0 ] / drug_use_df . loc [( drug_use_df [ col ] > 0 )] . shape [ 0 ] ratio_dict [ col ] = ratio ratio_dict . pop ( 'OpiateUse' , None ) ratio_dict {'Tranquilizers/Lifetime': 0.5340777820562187, 'Amphetamines/Lifetime': 0.41908396946564885, 'Sedatives/Lifetime': 0.47626186906546725, 'Marijuana/30Days': 0.21841463414634146, 'Cocaine/Lifetime': 0.600326264274062, 'Cigarettes/30Days': 0.29249941217963793, 'Psychedelics/Lifetime': 0.5078625509609784, 'AlcoholicDrinks/30Days': 0.14727359585067903, 'LSD/Lifetime': 0.4786096256684492} If readers are familiar with the previous analysis on the HEAL platform: Monitoring The Future: 12th Grader Opiate Use - Part 1 , an undeniable connection was identified by the machine learning models used in that notebook between opioid abuse and other drug use for 12th graders in 2019. While that connection appears to exist again, let's examine if the same descrease in opioid use is present with other drug use amongst 12th graders.","title":"Rate Of Illicit Substance Use Coinciding With Opiate Abuse"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#annual-cocaine-use-rate","text":"series = ( df . groupby ( 'Year' )[ 'Cocaine/Lifetime' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Cocaine Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure2.png' ) Image ( filename = \"img/MTF_Part2/figure2.png\" )","title":"Annual Cocaine Use Rate"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#annual-tranquilzer-use-rate","text":"series = ( df . groupby ( 'Year' )[ 'Tranquilizers/Lifetime' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Tranquilizer Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure3.png' ) Image ( filename = \"img/MTF_Part2/figure3.png\" )","title":"Annual Tranquilzer Use Rate"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#annual-sedatives-use-rate","text":"series = ( df . groupby ( 'Year' )[ 'Sedatives/Lifetime' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Sedatives Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure4.png' ) Image ( filename = \"img/MTF_Part2/figure4.png\" )","title":"Annual Sedatives Use Rate"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#annual-amphetamines-use-rate","text":"series = ( df . groupby ( 'Year' )[ 'Amphetamines/Lifetime' ] . sum () / df . groupby ( 'Year' )[ 'Year' ] . count ()) ax = sns . barplot ( x = list ( series . index ), y = list ( series . array ), color = 'purple' ) ax . set ( xlabel = 'Year' , ylabel = 'Amphetamines Use Rate' ) plt . close () ax . figure . savefig ( 'img/MTF_Part2/figure5.png' ) Image ( filename = \"img/MTF_Part2/figure5.png\" ) While there is a substantial decrease in the use of amphetamines, sedatives, tranquilizers, and cocaine in 2021, we do not see the same slow decline in their usage from 2012 to 2020. It is, however, worth noting the significant degree to which opioids are abused compared to the other illicit substances. Opiate use peaked at over 11% in 2012, while all of the other substances have peaks between 1% and 6%. * Opiate use is a combined measurement of the heroin and opioid narcotic use survey results.","title":"Annual Amphetamines Use Rate"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#cross-validation-hyperparameter-tuning-and-model-selection","text":"The work done in the first example analysis notebook in this series used SMOTE (Synthetic Minority Oversampling Technique) and multiple, simpler classification models, such as logistic regression and random forest classification. This notebook will use the XGB (Extreme Gradient Boosting) classification algorithm. Unlike with the simpler models used previously, the XGBClassifier does not require the use of SMOTE. Instead, we will use the XGBClassifier hyperparameter, 'scale_pos_weight'. When classes are imbalanced, 'scale_pos_weight' is typically set as the ratio of the number of overrepresented observations (no opiate use) to the number of underrepresented observations (opiate use). This hyperparameter scales the gradient of the positive, underrepresented class, thus scaling the errors of the positive class during the model training step. While 'scale_pos_weight' is taken at the suggested value, most of the other hyperparameters to the XGBClassifier model were tuned using the grid search and 10-fold cross validation methods. In other words, we exhaustively tested multiple combinations of hyperparameters from a subset of possible values and verified the optimal combination of hyperparameters using 10-fold cross validation. Below you will find the function used for cross validation and the final model used with the tuned hyperparameters. def pipeline_cross_validation ( data , k , pipeline_steps ): folds = np . array_split ( data , k ) accuracySum = 0 recallSum = 0 precisionSum = 0 for i in range ( k ): train = folds . copy () test = folds [ i ] del train [ i ] train = pd . concat ( train , sort = False ) y_train = train . OpiateUse . astype ( int ) X_train = train . drop ( 'OpiateUse' , axis = 1 ) y_test = test . OpiateUse . astype ( int ) X_test = test . drop ( 'OpiateUse' , axis = 1 ) pipeline = Pipeline ( pipeline_steps ) . fit ( X_train , y_train ) y_pred = pipeline . predict ( X_test ) accuracySum += accuracy_score ( y_test , y_pred ) recallSum += recall_score ( y_test , y_pred ) precisionSum += precision_score ( y_test , y_pred ) return [ accuracySum / k , recallSum / k , precisionSum / k ] df1 = df . drop ([ 'Year' ], axis = 1 ) df1 = df1 . astype ( float ) model = XGBClassifier ( learning_rate = 0.01 , n_estimators = 200 , max_depth = 5 , min_child_weight = 1 , gamma = 0.6 , subsample = 0.8 , colsample_bytree = 0.7 , objective = 'binary:logistic' , enable_categorical = 'True' , seed = random_seed , scale_pos_weight = len ( df1 ) / sum ( df1 [ 'OpiateUse' ])) steps = [( 'model' , model )] score = pipeline_cross_validation ( df1 , k = 10 , pipeline_steps = steps ) print ( f 'Accuracy: { score [ 0 ] } | Precision: { score [ 1 ] } | Recall: { score [ 2 ] } ' ) Accuracy: 0.8603258289775144 | Precision: 0.7657892432458844 | Recall: 0.31582818104175825","title":"Cross Validation, Hyperparameter Tuning, And Model Selection"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#opioid-use-classification","text":"This first iteration of model training, testing, and evaluation will use all 10 years of data spaning from 2012 to 2021. This model will be the same XGBClassifier that was tuned and validated above. After the model is trained, we will examine the model's performance by looking at the model's accuracy, precision, and recall metrics. Model accuracy will tell us the model's rate of correctly classifying both the students who have and have not ever abused opiates; model recall will tell us the model's rate of correctly identifying all of the students who have abused opiates, and model precision will tell us the model's rate of correctly identifying students who have abused opiates amongst all students the model identifies as having used opiates. After examining the model's performance and the corresponding confusion matrix, we will look at what the model considers to be the most and least relevant features to capturing students' opiate use behavior. X = df1 . drop ( 'OpiateUse' , axis = 1 ) y = df1 . OpiateUse X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = random_seed ) model = XGBClassifier ( learning_rate = 0.01 , n_estimators = 200 , max_depth = 5 , min_child_weight = 1 , gamma = 0.6 , subsample = 0.8 , colsample_bytree = 0.7 , objective = 'binary:logistic' , seed = random_seed , scale_pos_weight = len ( df1 ) / sum ( df1 [ 'OpiateUse' ])) steps = [( 'model' , model )] boosted_model = model . fit ( X_train , y_train ) y_pred = boosted_model . predict ( X_test )","title":"Opioid Use Classification"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#model-performance","text":"The following model scores are scaled between 0 and 1, with 1 being perfect performance. The scores and the corresponding confusion matrix tells us that the model performs relatively well at identifying students who have ever used opiates illicitly, identifying almost 78% of all students who have used opiates illicitly, and performs well at correctly classifying 85% of all students in either category. However, the model does a poor job at identifying only those who abused opioids amongst the student population. In fact, almost 70% of the students our model says have used opioids illicitly have not.","title":"Model Performance"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#model-scores","text":"print ( f 'Accuracy: { accuracy_score ( y_test , y_pred ) } | Precision: { precision_score ( y_test , y_pred ) } | Recall: { recall_score ( y_test , y_pred ) } ' ) Accuracy: 0.8550380821575727 | Precision: 0.31851360318513605 | Recall: 0.7817589576547231","title":"Model Scores"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#confuion-matrix","text":"disp = ConfusionMatrixDisplay ( confusion_matrix ( y_test , y_pred )) disp . plot () disp . im_ . colorbar . remove () fig = disp . figure_ plt . close () fig . figure . savefig ( 'img/MTF_Part2/figure6.png' ) Image ( filename = \"img/MTF_Part2/figure6.png\" )","title":"Confuion Matrix"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#most-important-features","text":"feature_importance = pd . DataFrame ( index = df1 . columns . drop ( 'OpiateUse' )) feature_importance [ f 'Feature Importance' ] = ( boosted_model . feature_importances_ - min ( boosted_model . feature_importances_ )) / ( max ( boosted_model . feature_importances_ ) - min ( boosted_model . feature_importances_ )) Markdown ( feature_importance . sort_values ( by = [ 'Feature Importance' ], ascending = False ) . head ( 15 ) . to_markdown ()) Feature Importance Amphetamines/Lifetime 1 Tranquilizers/Lifetime 0.449333 Marijuana/30Days 0.335475 Sedatives/Lifetime 0.152119 AlcoholicDrinks/30Days 0.129192 Cigarettes/30Days 0.105862 LivesWithSiblings 0.0666517 Psychedelics/Lifetime 0.0630031 Cocaine/Lifetime 0.0601336 MilesDrivenPerWeek 0.0462572 LSD/Lifetime 0.0363287 DrivingTickets 0.0314236 SkippedClass/4Weeks 0.02358 MoneyFromOtherSource 0.0222268 LivesWithMother 0.021669","title":"Most Important Features"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#least-important-features","text":"Markdown ( feature_importance . sort_values ( by = [ 'Feature Importance' ], ascending = False ) . tail ( 15 ) . to_markdown ()) Feature Importance PoliticalPreference_2 0.00565269 MotherEduLvl 0.00560381 PoliticalBeliefs_2 0.00553094 MotherHadPaidJobWhileGrowingUp 0.00535169 RaisedWhere_9 0.00510992 Crack/Lifetime 0.00484198 HrsWorkedPerWeek 0.00477158 DatesHowOften 0.00447595 RaisedWhere_4 0.00430372 RaisedWhere_8 0.00428398 HighSchoolProgram_4 0.00370746 MaritalStatus_2 0.00318217 Over18 0.00306294 PoliticalPreference_3 0.00255435 PoliticalPreference_7 0 Above we see the 15 most and least important features ranked by their normalized feature importance scores. These feature scores are an indication of the relative amount each feature improves upon the performance of the model when making a decision along the given feature. As with our work in part one, we find that the students' use of other illicit substances are the most telling indicators as to whether a student will use opiates or opioid narcotics. We also find that the students race, political preference or beliefs, and where students are raised gives little to no indication towards whether they will abuse opioids.","title":"Least Important Features"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#annual-opioid-use-classification","text":"Next we will rerun this analysis but focus on only one year of data at a time. We will use the same hyperparameters as before for these newly trained models, since the computation for hyperparameter tuning takes a significant amount of time. After training the 10 models for the 10 years of data, we will again examine the models' performance and ranked feature importance.","title":"Annual Opioid Use Classification"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#training-and-testing-model-on-annual-data","text":"feature_importance = pd . DataFrame ( index = df1 . columns . drop ( 'OpiateUse' )) classification_scores = pd . DataFrame ({ 'Metric' : [ 'Accuracy' , 'Precision' , 'Recall' ]}) for year in year_list : df_annual = df [ df [ 'Year' ] == year ] df_annual = df_annual . drop ([ 'Year' ], axis = 1 ) df_annual = df_annual . astype ( float ) X = df_annual . drop ( 'OpiateUse' , axis = 1 ) y = df_annual . OpiateUse . astype ( int ) X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = random_seed ) model = XGBClassifier ( learning_rate = 0.01 , n_estimators = 200 , max_depth = 5 , min_child_weight = 1 , gamma = 0.6 , subsample = 0.8 , colsample_bytree = 0.7 , objective = 'binary:logistic' , enable_categorical = True , seed = random_seed , scale_pos_weight = len ( df_annual ) / sum ( df_annual [ 'OpiateUse' ])) boosted_model = model . fit ( X_train , y_train ) y_pred = boosted_model . predict ( X_test ) feature_importance [ f 'Feature Importance { year } ' ] = ( boosted_model . feature_importances_ - min ( boosted_model . feature_importances_ )) / ( max ( boosted_model . feature_importances_ ) - min ( boosted_model . feature_importances_ )) classification_scores [ f 'Model Performance { year } ' ] = [ accuracy_score ( y_test , y_pred ), precision_score ( y_test , y_pred ), recall_score ( y_test , y_pred )]","title":"Training And Testing Model On Annual Data"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#annual-accuracy-and-precision-scores","text":"Below we can see that for the first few years our model's performance is only slightly below the previous performance of the model using all 10 years of data. In 2020 and 2021, the models do not perform nearly as well as the models trained on prior annual data or the model trained using all of the data. The underperformance of the models from earlier years compared to our first model is to be expected, as we are training those models on a much smaller subset of data. However, the poor performance of the later models cannot be completely explained by the difference in size of the training data. The lower performance of the models from 2020 and 2021 may be explained by the disruption to behavior caused by the COVID-19 pandemic, but may also be exlpained by the massive decrease in the opioid use rate of the 12th graders surveyed in 2021. Markdown ( classification_scores . to_markdown ()) Metric Model Performance 2012 Model Performance 2013 Model Performance 2014 Model Performance 2015 Model Performance 2016 Model Performance 2017 Model Performance 2018 Model Performance 2019 Model Performance 2020 Model Performance 2021 0 Accuracy 0.864261 0.871503 0.892216 0.89576 0.891626 0.917513 0.91247 0.911633 0.921875 0.9681 1 Precision 0.444444 0.42246 0.476923 0.351852 0.391667 0.488636 0.344086 0.358696 0.388889 0.4 2 Recall 0.75188 0.669492 0.738095 0.44186 0.758065 0.68254 0.727273 0.622642 0.4375 0.555556","title":"Annual Accuracy And Precision Scores"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#most-important-features-each-year","text":"Like before, we see the same relation between between general illicit substance use and illicit opiate use. It is worth noting that the use of tranqulizers and amphetamines typically took the top 1 and 2 positions for most influential features until 2021, when they fell to the 4th and 5th ranking. This is another indicator that something significant shifted in our model's classification of 12th grader opiate use. df12 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2012' ], ascending = False )[ 'Feature Importance 2012' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df12 [ 'Feature Importance 2012' ] = df12 [ 'Feature' ] + \" - \" + df12 [ \"Feature Importance 2012\" ] . astype ( str ) df12 = df12 . drop ([ 'Feature' ], axis = 1 ) df13 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2013' ], ascending = False )[ 'Feature Importance 2013' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df13 [ 'Feature Importance 2013' ] = df13 [ 'Feature' ] + \" - \" + df13 [ \"Feature Importance 2013\" ] . astype ( str ) df13 = df13 . drop ([ 'Feature' ], axis = 1 ) df14 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2014' ], ascending = False )[ 'Feature Importance 2014' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df14 [ 'Feature Importance 2014' ] = df14 [ 'Feature' ] + \" - \" + df14 [ \"Feature Importance 2014\" ] . astype ( str ) df14 = df14 . drop ([ 'Feature' ], axis = 1 ) df15 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2015' ], ascending = False )[ 'Feature Importance 2015' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df15 [ 'Feature Importance 2015' ] = df15 [ 'Feature' ] + \" - \" + df15 [ \"Feature Importance 2015\" ] . astype ( str ) df15 = df15 . drop ([ 'Feature' ], axis = 1 ) df16 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2016' ], ascending = False )[ 'Feature Importance 2016' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df16 [ 'Feature Importance 2016' ] = df16 [ 'Feature' ] + \" - \" + df16 [ \"Feature Importance 2016\" ] . astype ( str ) df16 = df16 . drop ([ 'Feature' ], axis = 1 ) df17 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2017' ], ascending = False )[ 'Feature Importance 2017' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df17 [ 'Feature Importance 2017' ] = df17 [ 'Feature' ] + \" - \" + df17 [ \"Feature Importance 2017\" ] . astype ( str ) df17 = df17 . drop ([ 'Feature' ], axis = 1 ) df18 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2018' ], ascending = False )[ 'Feature Importance 2018' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df18 [ 'Feature Importance 2018' ] = df18 [ 'Feature' ] + \" - \" + df18 [ \"Feature Importance 2018\" ] . astype ( str ) df18 = df18 . drop ([ 'Feature' ], axis = 1 ) df19 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2019' ], ascending = False )[ 'Feature Importance 2019' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df19 [ 'Feature Importance 2019' ] = df19 [ 'Feature' ] + \" - \" + df19 [ \"Feature Importance 2019\" ] . astype ( str ) df19 = df19 . drop ([ 'Feature' ], axis = 1 ) df20 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2020' ], ascending = False )[ 'Feature Importance 2020' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df20 [ 'Feature Importance 2020' ] = df20 [ 'Feature' ] + \" - \" + df20 [ \"Feature Importance 2020\" ] . astype ( str ) df20 = df20 . drop ([ 'Feature' ], axis = 1 ) df21 = pd . DataFrame ( feature_importance . sort_values ( by = [ 'Feature Importance 2021' ], ascending = False )[ 'Feature Importance 2021' ]) . head ( 10 ) . reset_index ( names = [ 'Feature' ]) df21 [ 'Feature Importance 2021' ] = df21 [ 'Feature' ] + \" - \" + df21 [ \"Feature Importance 2021\" ] . astype ( str ) df21 = df21 . drop ([ 'Feature' ], axis = 1 ) Markdown ( pd . concat ([ df12 , df13 , df14 , df15 , df16 , df17 , df18 , df19 , df20 , df21 ], axis = 1 ) . to_markdown ()) Feature Importance 2012 Feature Importance 2013 Feature Importance 2014 Feature Importance 2015 Feature Importance 2016 Feature Importance 2017 Feature Importance 2018 Feature Importance 2019 Feature Importance 2020 Feature Importance 2021 0 Amphetamines/Lifetime - 1.0 Amphetamines/Lifetime - 1.0 Amphetamines/Lifetime - 1.0 Amphetamines/Lifetime - 1.0 Amphetamines/Lifetime - 1.0 Tranquilizers/Lifetime - 1.0 Tranquilizers/Lifetime - 1.0 Tranquilizers/Lifetime - 1.0 Tranquilizers/Lifetime - 1.0 Psychedelics/Lifetime - 1.0 1 Marijuana/30Days - 0.75576615 Tranquilizers/Lifetime - 0.55172384 Tranquilizers/Lifetime - 0.5155145 Tranquilizers/Lifetime - 0.32245028 Tranquilizers/Lifetime - 0.49392527 Amphetamines/Lifetime - 0.87034947 Amphetamines/Lifetime - 0.34006974 Amphetamines/Lifetime - 0.46549627 Amphetamines/Lifetime - 0.82667917 Sedatives/Lifetime - 0.9135607 2 Tranquilizers/Lifetime - 0.65975815 Sedatives/Lifetime - 0.35604864 Marijuana/30Days - 0.3510031 Marijuana/30Days - 0.27957878 Marijuana/30Days - 0.30306983 Marijuana/30Days - 0.4922091 Marijuana/30Days - 0.20515968 AlcoholicDrinks/30Days - 0.26642838 Sedatives/Lifetime - 0.60782486 LSD/Lifetime - 0.70153475 3 Sedatives/Lifetime - 0.23304458 Cigarettes/30Days - 0.22533654 Sedatives/Lifetime - 0.24436365 Cigarettes/30Days - 0.26259112 Crack/Lifetime - 0.1769505 Cigarettes/30Days - 0.3307903 DrivingTickets - 0.12938854 LSD/Lifetime - 0.25456077 Marijuana/30Days - 0.36239895 Tranquilizers/Lifetime - 0.66015655 4 AlcoholicDrinks/30Days - 0.16919222 Marijuana/30Days - 0.22409648 AlcoholicDrinks/30Days - 0.19529353 Cocaine/Lifetime - 0.23002389 Sedatives/Lifetime - 0.17548333 Sedatives/Lifetime - 0.28806037 Sedatives/Lifetime - 0.121947214 Marijuana/30Days - 0.2489249 PoliticalBeliefs_6 - 0.33769482 Marijuana/30Days - 0.52852654 5 Cigarettes/30Days - 0.15726869 AlcoholicDrinks/30Days - 0.1261193 Psychedelics/Lifetime - 0.1708248 Psychedelics/Lifetime - 0.22408944 LSD/Lifetime - 0.14090925 DrivingTickets - 0.26170564 PoliticalPreference_6 - 0.11954165 Psychedelics/Lifetime - 0.19040935 WantToDo2YrCollege - 0.3267634 Amphetamines/Lifetime - 0.49161762 6 Crack/Lifetime - 0.15701917 PoliticalPreference_7 - 0.1104126 Cocaine/Lifetime - 0.17024292 RaisedWhere_1 - 0.17279556 PoliticalBeliefs_6 - 0.12900716 Crack/Lifetime - 0.21362005 LivesWithSiblings - 0.117574446 Cocaine/Lifetime - 0.15222396 LSD/Lifetime - 0.31751463 RaisedWhere_7 - 0.4318025 7 WantToServeInMilitary - 0.14331344 MaritalStatus_2 - 0.10724328 PoliticalPreference_7 - 0.16727918 Sedatives/Lifetime - 0.1554664 AlcoholicDrinks/30Days - 0.12395912 Cocaine/Lifetime - 0.19935064 Cocaine/Lifetime - 0.10532992 WantToServeInMilitary - 0.15194388 SchoolDaysMissedIllness/4Weeks - 0.29573283 PoliticalPreference_7 - 0.42327297 8 Psychedelics/Lifetime - 0.14275527 Psychedelics/Lifetime - 0.10488076 MaritalStatus_3 - 0.15278761 PoliticalBeliefs_6 - 0.14911336 PoliticalBeliefs_8 - 0.11484937 SkippedClass/4Weeks - 0.18681203 RaisedWhere_7 - 0.10298768 Cigarettes/30Days - 0.1502413 SkippedClass/4Weeks - 0.29407594 WantToDoVocationalSchl - 0.39966732 9 LivesWithSiblings - 0.13939653 RaisedWhere_8 - 0.083930984 DrivingTickets - 0.15190427 SchoolRegion_3 - 0.1441104 Over18 - 0.11348703 SchoolRegion_3 - 0.16396773 MoneyFromOtherSource - 0.102316245 SkippedClass/4Weeks - 0.14667954 DatesHowOften - 0.28880978 SchoolRegion_2 - 0.38491154","title":"Most important features each year"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#conclusion","text":"Using the XGBoost (extreme gradient boosting) classifier algorithm and cross-validation techniques, we successfully tuned, trained, and tested an XGBClassifier model on survey data from 2012 to 2021 for classifying whether a student surveyed had ever opioids illicitly. The model trained using all 10 years of data had a fairly high model accuracy score of 0.86 and a model recall score of 0.77 during cross-validation. In other words, the model correctly identified whether a student had or had not ever illicitly used opioids 86% of the time and correctly identified 77% of the students who had used opioids illicitly. Following our model fitting, testing, and feature analysis on all 10 years of data, we refit our model on each year of data seperately, keeping the same hyperparameter tunings. While many of these annual models did not perform as well as the initial model with all 10 years worth of data, this can easily be explained by differences in the size of the training datasets. However, the models for 2020 and 2021 performed poorly even when compared to the models trained on the previous years data; this suggests some additioanl influence is taking place upon the survey data for 2020 and 2021. The two most obvious influences would be the significant decrease in the reported rate of opioid use in 2021 and the possible effects of the COVID-19 pandemic on the survey methodology and/or the changes in the actual behavior of the surveyed 12th graders. Like with our previous work in part one of this series, many of the identified important variables aligned with expectations, both when modeling the annual datasets and the entire dataset spanning from 2012 to 2021. It was not surprising to find that students who engaged in various illicit drug use and underage drinking were at higher risk of using opiates and heroin. It is worth noting: from 2012 to 2016, use of amphetamine, followed by the use of tranquilizers, was considered by the models to be the best indicator of opioid use. From 2017 to 2020, those positions switched. In 2021, the use of amphetamine and tranquilizers became a significantly less influential indicator.","title":"Conclusion"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_2012-2021/#future-work","text":"Future work is planned to further analyze the lifestyle, behaviors, and opiate use of the survey subjects from 2021. Particular emphasis will be placed on examining what other behavioral and lifestyle changes occured amongst 12th graders that might coincide with the decreased rate of illicit opiate use as found amongst the MTF survey participants.","title":"Future Work"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/","text":"Monitoring The Future: 12th Grader Opiate Use - Part 1 \u00b6 J M Maxwell - Data Science, Sr. Analyst - CTDS \u00b6 Analysis Introduction \u00b6 About The Data \u00b6 The Monitoring The Future surveys are a series of surveys that have emerged as a vital tool in measuring the values, behaviors, and lifestyle orientations among American youth. Through a comprehensive series of surveys, these studies offer a unique window into the ever-changing landscape of 12th grade students. Students are randomly assigned one of six questionnaires; each questionnaire comprises both a core set of questions common to all surveys and a set of questions tailored to the specific survey, collectively providing a rich dataset for exploration. There are approximately 1,400 variables across all of the questionnaires; while recognizing the vastness of the available data, our exploration will be primarily focused on a subset of variables deemed particularly relevant to our research objectives. One of the critical aspects examined in the surveys pertains to the frequency of drug use among students, encompassing a wide array of illicit and recreational substances. In the context of this analysis, specific attention has been limited to surveys which observe instances where students engaged in the use of heroin or other opioid narcotics. While the investigation of drug use patterns holds significance in understanding the landscape of contemporary American youth, the Monitoring The Future surveys provide a broader canvas for exploration. Our analysis encompasses an assortment of other captivating topics including, but not limited to, students' perspectives on religion, educational goals, family life dynamics, and work habits. By examining these multidimensional facets, we may gain a holistic understanding of the myriad factors influencing the lives, aspirations, and substance use risks of American youth. Import Python Packages And Data \u00b6 ! pip install matplotlib - q ! pip install scikit - learn - q ! pip install imblearn - q import pandas as pd pd . set_option ( 'future.no_silent_downcasting' , True ) import numpy as np import random import matplotlib.pyplot as plt from collections import Counter from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import cross_validate from sklearn.svm import SVC from sklearn.metrics import recall_score , precision_score , accuracy_score from sklearn.utils import resample from sklearn.decomposition import PCA from imblearn.over_sampling import SMOTE from imblearn.pipeline import Pipeline from IPython.display import Markdown import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) random_seed = 2023 df_12_2019_1 = pd . read_csv ( 'Grade12/ICPSR_37841/DS0001/37841-0001-Data.tsv' , sep = ' \\t ' ) df_12_2019_3 = pd . read_csv ( 'Grade12/ICPSR_37841/DS0003/37841-0003-Data.tsv' , sep = ' \\t ' ) Data Cleaning And Feature Selection \u00b6 Below is a key for mapping the surveys' coded variable names to a more interpretable set of variable labels. We identified a number variables from the original dataset that needed to be removed because they were highly correlated. For instance, we observed among the survey recipients an unsurprising association between the number of alcoholic drinks consumed this year and the number of alcoholic drinks consumed in the last 30 days. We believe that the latter variable will serve as a more robust indicator for opiate use, so to streamline our analysis and enhance the veracity of our work, we made the decision to remove the former variable. The initial dataset comprises an impressive collection of 16,000+ survey results, each representing an observation from a survey participant. However, it is important to note that a substantial portion of these observations were removed during the data cleaning process, as those observations were missing portions of their data. Most of the data you see below is either recorded as a binary outcome (1/yes or 0/no), as an ordinal value(i.e., 0 = no drug use, 1 = some drug use, 2 = frequent drug use), or as a categorical feature. The categorical data is encoded and represented as binary data. variable_dict = { 'RESPONDENT_AGE' : 'Over18' , 'V13' : 'SchoolRegion' , 'V49' : 'NumberOfSiblings' , 'V2102' : 'CigsSmoked/30Days' , 'V2106' : 'AlcoholicDrinksHowManyTimes/30Days' , 'V2117' : 'MarijuanaHowManyTimes/30Days' , 'V2118' : 'LSDHowManyTimes/Life' , 'V2121' : 'PsychedelicsHowManyTimes/Life' , 'V2124' : 'CocaineHowManyTimes/Life' , 'V2127' : 'AmphetaminesHowManyTimes/Life' , 'V2133' : 'SedativesHowManyTimes/Life' , 'V2136' : 'TranquilizersHowManyTimes/Life' , 'V2139' : 'HerHowManyTimes/Life' , 'V2142' : 'NarcHowManyTimes/Life' , 'V2150' : 'Sex' , 'V2151' : 'Race' , 'V2152' : 'RaisedWhere' , 'V2153' : 'MaritalStatus' , 'V2155' : 'LivesWithFather' , 'V2156' : 'LivesWithMother' , 'V2157' : 'LivesWithSiblings' , 'V2163' : 'FatherEduLvl' , 'V2164' : 'MotherEduLvl' , 'V2165' : 'MotherHadPaidJobWhileGrowingUp' , 'V2166' : 'PoliticalPreference' , 'V2167' : 'PoliticalBeliefs' , 'V2169' : 'ReligiousServiceAttendenceWkly' , 'V2170' : 'ReligionImportance' , 'V2172' : 'HighSchoolProgram' , 'V2174' : 'SelfRateIntelligence' , 'V2175' : 'SchoolDaysMissedIllness/4Weeks' , 'V2176' : 'SchoolDaysMissedSkipped/4Weeks' , 'V2177' : 'SchoolDaysMissedOther/4Weeks' , 'V2178' : 'SkippedClass/4Weeks' , 'V2179' : 'AverageGradeHS' , 'V2180' : 'LikelyToAttendVocationalSchl' , 'V2181' : 'LikelyToServeInMilitary' , 'V2182' : 'LikelyToGraduate2YrCollege' , 'V2183' : 'LikelyToGraduate4YrCollege' , 'V2184' : 'LikelyToAttendGraduateSchl' , 'V2185' : 'WantToDoVocationalSchl' , 'V2186' : 'WantToServeInMilitary' , 'V2187' : 'WantToDo2YrCollege' , 'V2188' : 'WantToDo4YrCollege' , 'V2189' : 'WantToDoGradSchl' , 'V2190' : 'WantToDoNo2ndEd' , 'V2191' : 'HrsWorkedPerWeek' , 'V2193' : 'MoneyFromOtherSource' , 'V2194' : 'EveningsOutPerWeek' , 'V2195' : 'DatesHowOften' , 'V2196' : 'MilesDrivenPerWeek' , 'V2197' : 'DrivingTickets' , 'V2201' : 'CarAccidentsLast12Mo' , 'V2459' : 'CrackHowManyTimes/Life' , } The folowing steps were taken to clean the data: 1) We filtered the existing data by removing all variables missing more than 30% of their resepective values. We then remove all observations missing any survey responses. 2) We combined the survey questions asking students how many times they have used heroin and how many times they used opioid narcotics in their life into a single variable marking whether they have ever used heroin or an opiate. 3) We renamed all of our variables using the coded data dictionary above. 4) We factored the categorical data so it can be represented numerically. 5) We normalized the data so the ordinal and numerical outcomes do not have an oversized effect on our models. After these steps are complete we are left with only 5377 survey observations, approximately a third of our initial data. # Filter data down to just the variable dictionary, removing correlated features in the process variables = list ( variable_dict . keys ()) df = pd . concat ([ df_12_2019_1 [ variables ], df_12_2019_3 [ variables ]], ignore_index = True ) # Remove missing data missing_criteria = ( df == - 9 ) . sum () < 0.3 * len ( df . index ) df = df [ missing_criteria . index [ missing_criteria ]] df_counts = df . apply ( pd . Series . value_counts , axis = 1 ) missing_data = df_counts . iloc [:, 0 ] missing_data = missing_data . fillna ( 0 ) minimal_missing = missing_data . index [ missing_data < 1 ] df = df [ df . index . isin ( minimal_missing )] # Combine Opiate Use data df [ 'OpiateUse' ] = (( df [ 'V2142' ] != 1 ) + ( df [ 'V2139' ] != 1 )) . astype ( int ) df = df . drop ([ 'V2142' , 'V2139' ], axis = 1 ) # Rename columns using data dictionary df . rename ( columns = variable_dict , inplace = True ) # Factor categorical data dummy_cols = [ 'SchoolRegion' , 'Race' , 'RaisedWhere' , 'MaritalStatus' , 'PoliticalPreference' , 'PoliticalBeliefs' , 'HighSchoolProgram' ] dummies = pd . get_dummies ( df [ dummy_cols ], columns = dummy_cols , drop_first = True ) df = pd . concat ([ df , dummies ], axis = 1 ) df = df . drop ( dummy_cols , axis = 1 ) # Normalize data df . replace ({ False : 0 , True : 1 }, inplace = True ) df = ( df - df . min ()) / ( df . max () - df . min ()) df = df . reset_index ( drop = True ) Model Selection \u00b6 We began our model selection stage by training five different machine learning models and comparing their performance. We then selected the two best performing models. The five initial models we trained were a simple logistic regression model, a lasso logistic regression model, a ridge logistic regression model, a support vector machine (SVM) classifier, and a random forest classifier. Model Overview \u00b6 Logistic Regression Model : A widely used technique for exploring relationships between predictor variables and the probability of a set of binary outcomes occuring. Lasso Logistic Regression Model : A variation of the logistic regression model that incorporates a component encouraging the model to minimize the number of predictor variables, helping us identify which predictor variables are most (and least) influential. Ridge Logistic Regression Model : Another variation of the logistic regression model that promotes a balanced selection of predictor variables, allowing us to more clearly compare the influence of different predictor variables on opiate use. Support Vector Machine (SVM) Classifier : a classification model specificly suited to uncover complex boundaries to distinguish between classes of opiate users and non-users. Random Forest Classifier : Utilizes the collective descision making power of an ensemble of smaller, simpler models (decison trees) to produce more robust insights on the factors associated with opiate use in students. Cross Validation \u00b6 In order to make a precise comparison between these five models, we need to utilize cross-validation. Cross-validation involves executing multiple iterations of training and testing a model on various random, resampled selections of the data. This method is primarily used to estimate how a predictive model will perform in practice. In our use case, we compared the performance of our five models during cross-validation to determine which models perform best. Resolving Class Imbalances \u00b6 As expected, a limited number of the students surveyed had ever used opiates. Only 295 of the 5377 (approx. 5.5%) students had ever used opiates or heroin recreationally. This imbalance in classes made it very difficult to train a model to predict occurances of the minority class (opiate use) accurately. To resolve this problem, we used a technique called Synthetic Minority Oversampling Technique (SMOTE) . SMOTE synthesizes new examples from the minority class by creating synthetic data points which only slightly differ from the original data points of the minority class. SMOTE Cross Validation Pipeline \u00b6 Below you will find the function for a pipeline for performing model training and testing using 10-fold cross validation and SMOTE and for recording each model's cross validated performace. def pipeline_cross_validation ( data , k , pipeline_steps ): folds = np . array_split ( data , k ) accuracySum = 0 recallSum = 0 precisionSum = 0 for i in range ( k ): train = folds . copy () test = folds [ i ] del train [ i ] train = pd . concat ( train , sort = False ) y_train = train . OpiateUse . astype ( int ) X_train = train . drop ( 'OpiateUse' , axis = 1 ) y_test = test . OpiateUse . astype ( int ) X_test = test . drop ( 'OpiateUse' , axis = 1 ) pipeline = Pipeline ( pipeline_steps ) . fit ( X_train , y_train ) y_pred = pipeline . predict ( X_test ) accuracySum += accuracy_score ( y_test , y_pred ) recallSum += recall_score ( y_test , y_pred ) precisionSum += precision_score ( y_test , y_pred ) return [ accuracySum / k , recallSum / k , precisionSum / k ] Model Cross Validation \u00b6 k = 10 df2 = df . iloc [ np . random . permutation ( len ( df ))] classification_scores = pd . DataFrame ({ 'Metric' : [ 'Accuracy' , 'Recall' , 'Precision' ]}) smt = SMOTE ( random_state = random_seed ) model = LogisticRegression ( solver = 'liblinear' ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Logistic Regression' ] = pipeline_cross_validation ( df2 , k , steps ) model = LogisticRegression ( solver = 'liblinear' , penalty = 'l1' ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Lasso Logistic Regression' ] = pipeline_cross_validation ( df2 , k , steps ) model = LogisticRegression ( solver = 'liblinear' , penalty = 'l2' ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Ridge Logistic Regression' ] = pipeline_cross_validation ( df2 , k , steps ) model = SVC ( C = 1.5 , kernel = 'rbf' ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Support Vector Machine' ] = pipeline_cross_validation ( df2 , k , steps ) model = RandomForestClassifier ( n_estimators = 100 , criterion = 'entropy' , bootstrap = True ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Random Forest Classifier' ] = pipeline_cross_validation ( df2 , k , steps ) Model Classification Scores \u00b6 Below we find the model accuracy, recall, and precision scores for all five models. All three metrics are scored between 0.0 and 1.0, with 1.0 being a perfect score. In our current application, model accuracy is a measurement of how well the model correctly labels whether a student is likely to either have used opiates/heroin or to not have used opiates/heroin. Recall measures how well the model performs at detecting all of the subjects who have used opiates/heroin. Precision measures how well the model performs at accurately specifying which subjects have used opiates/heroin from those subjects who have not used opiates/heroin. While we resolved the class imbalance when training our models, the class imbalance can still effect our scores, particularly model accuracy during testing. With that in mind, we primarily relied on the recall and precision scores when comparing the performance of the models and selecting our final two models. Markdown ( classification_scores . head () . to_markdown ()) Metric Logistic Regression Lasso Logistic Regression Ridge Logistic Regression Support Vector Machine Random Forest Classifier 0 Accuracy 0.863121 0.866843 0.863121 0.961129 0.967452 1 Recall 0.704792 0.703083 0.704792 0.524306 0.515776 2 Precision 0.244013 0.250618 0.244013 0.699461 0.80553 Model Selection \u00b6 We chose one model with the highest recall score and one with the highest precision score. The random forest classifier clearly had the best precison score. The three logistic regression models all had very similar recall scores, however, we chose the lasso logistic regression model from those three models. The lasso logistic regression model will typically be more interpretable and simpler by reducing the number of variables. We proceeded with retraining the random forest classifier and lasso logistic regression models so we could examine what each model believes to be the most influential variables on whether a 12th grader has ever used opiates/heroin. Model Analysis \u00b6 X = df . drop ( 'OpiateUse' , axis = 1 ) y = df . OpiateUse . astype ( int ) X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = random_seed ) classification_scores = pd . DataFrame ({ 'Metric' : [ 'Accuracy' , 'Recall' , 'Precision' ]}) model = RandomForestClassifier ( n_estimators = 100 , criterion = 'entropy' , bootstrap = True ) steps = [( 'smt' , smt ), ( 'model' , model )] pipeline = Pipeline ( steps ) . fit ( X_train , y_train ) y_pred = pipeline . predict ( X_test ) feature_importance = pd . DataFrame ({ 'RF Feature Importance' : pipeline [ 'model' ] . feature_importances_ }, index = df . columns . drop ( 'OpiateUse' )) feature_importance [ 'Normalized RF Feature Importance' ] = ( pipeline [ 'model' ] . feature_importances_ - min ( pipeline [ 'model' ] . feature_importances_ )) / ( max ( pipeline [ 'model' ] . feature_importances_ ) - min ( pipeline [ 'model' ] . feature_importances_ )) classification_scores [ 'Random Forest Classifier' ] = [ accuracy_score ( y_test , y_pred ), recall_score ( y_test , y_pred ), precision_score ( y_test , y_pred )] model = LogisticRegression ( solver = 'liblinear' , penalty = 'l1' ) steps = [( 'smt' , smt ), ( 'model' , model )] pipeline = Pipeline ( steps ) . fit ( X_train , y_train ) y_pred = pipeline . predict ( X_test ) feature_importance [ 'Lasso Model Coefficients' ] = pipeline [ 'model' ] . coef_ [ 0 ] feature_importance [ 'Lasso Model Coefficients AbsVal' ] = abs ( pipeline [ 'model' ] . coef_ [ 0 ]) classification_scores [ 'Lasso Logistic Regression' ] = [ accuracy_score ( y_test , y_pred ), recall_score ( y_test , y_pred ), precision_score ( y_test , y_pred )] Again we see similar recall and precision scores as before. Markdown ( classification_scores . to_markdown ()) Metric Random Forest Classifier Lasso Logistic Regression 0 Accuracy 0.958178 0.859665 1 Recall 0.476923 0.753846 2 Precision 0.738095 0.266304 Lasso Logistic Regression Influential Variables \u00b6 We first looked at the most influential variables in the lasso logistic regression model. Below are a rank ordered list of the 15 most influential variables. Because the lasso logistic regression model's coefficients are related to a high recall score, they let us know which of the variables are the most influential on the model's ability to identify all of the students who have used opiates/heroin. This particular model was able to identify between 70% and 75% of all the surveyed students who had used opiates/heroin. In the data frame below, 'Lasso Model Coefficients' is the coefficient in the model and tells us the relative influence of each of the 10 variables with the greatest positive influence towards identifying students who used opiates. For instance, the frequency of with which students use tranquilizers or LSD (the two highest ranked variables) are highly influential in identifying students who have ever used opiates. Furthermore, 8 of top 10 variables that are highly related to student's opiate use involve the student's illicit use of other drugs or alcohol. When comparing the influence of each variable in our model, it is important to note the relative scale of the model coefficients. For instance, each use of amphetamines or cocaine in a students lifetime is approximately 3 times more influential to our model's prediction of opiate use than each use of marijuana or sedatives/barbituates. Markdown ( feature_importance . sort_values ( by = [ 'Lasso Model Coefficients' ], axis = 0 , ascending = False )[[ 'Lasso Model Coefficients' ]] . head ( 15 ) . to_markdown ()) Lasso Model Coefficients TranquilizersHowManyTimes/Life 7.3497 LSDHowManyTimes/Life 6.9445 CocaineHowManyTimes/Life 4.26338 AmphetaminesHowManyTimes/Life 4.14465 CigsSmoked/30Days 2.13381 AlcoholicDrinksHowManyTimes/30Days 1.69848 MarijuanaHowManyTimes/30Days 1.54761 SedativesHowManyTimes/Life 1.22001 LivesWithFather 0.978733 MotherHadPaidJobWhileGrowingUp 0.821343 WantToServeInMilitary 0.697732 AverageGradeHS 0.606838 LikelyToAttendVocationalSchl 0.595602 LikelyToAttendGraduateSchl 0.466966 MotherEduLvl 0.348325 Lasso Logistic Regression Least Influential Variables \u00b6 According to our lasso logistic regression model, these are the 10 least influential variables on whether a survey subject was likely or unlikely to use opiates/heroin. These attributes give little to no indication into whether a student will have illicitly used opiates or heroin. These variables are listed in order of least influence. The relevant encodings on this list are: 'PoliticalBeliefs_6' - Radical (ranked 1-6 from very conservative to radically liberal, with option for no belief) 'PoliticalBeliefs_3' - Moderate (ranked 1-6 from very conservative to radically liberal, with option for no belief) 'Race_3' - Hispanic (subjects self reported race as Black, White, or Hispanic) From our model, it appears that some student's political beliefs, the number of times the student has skipped class in the last four weeks, a lack of desire to pursure secondary education, and the number of psychedelics they have consumed in their lifetime all provide little to no information as to whether a student would or would not use opiates/heroin. Markdown ( feature_importance . sort_values ( by = [ 'Lasso Model Coefficients AbsVal' ], axis = 0 , ascending = True )[[ 'Lasso Model Coefficients AbsVal' ]] . head ( 10 ) . to_markdown ()) Lasso Model Coefficients AbsVal PsychedelicsHowManyTimes/Life 0 SkippedClass/4Weeks 0 WantToDoNo2ndEd 0 PoliticalBeliefs_3 0 PoliticalBeliefs_6 0 Race_3 0.0410165 DatesHowOften 0.0453305 LikelyToServeInMilitary 0.0460795 NumberOfSiblings 0.0713443 ReligiousServiceAttendenceWkly 0.0808742 Random Forest Influential Variables \u00b6 Now, let's analyze the key attributes of the random forest classification model. Presented below is a ranked list of the top 15 most important variables to our random forest model. These variables play a crucial role in achieving a high precision score and provide insights into the most influential factors affecting the model's capability to accurately distinguish and identify students who have used opiates/heroin (it is highly unlikely that the model will indicate that student who has never used opiates/heroin as having used opiates/heroin at least once in their life). In the data frame below, 'RF Feature Importance' is the Gini Feature Importance of the random forest model and 'Normalized RF Feature Importance' is the the same set of values normalized to a range between 0 and 1. As with our lasso logistic regression model, a variety of other drug and alcohol use is highly influential on whether a subject is likely to have or have not used opiates/heroin. Other important features include how often the subject goes out on dates, the self reported importance of religion and attendence to religious services, the number school days they have missed in the last four weeks, how many hours they work each week, and whether the subject's mother had a paid job growing up. Unlike the coefficients of our ridge logistic regression model above, these scores do not tell us whether a particular variable has a strong postive or negative influence on predicting whether a student has or has not used opiates/heroin. Markdown ( feature_importance . sort_values ( by = [ 'RF Feature Importance' ], axis = 0 , ascending = False )[[ 'RF Feature Importance' , 'Normalized RF Feature Importance' ]] . head ( 15 ) . to_markdown ()) RF Feature Importance Normalized RF Feature Importance TranquilizersHowManyTimes/Life 0.104334 1 AmphetaminesHowManyTimes/Life 0.0943735 0.90435 AlcoholicDrinksHowManyTimes/30Days 0.0748839 0.717192 MarijuanaHowManyTimes/30Days 0.0633785 0.606706 LSDHowManyTimes/Life 0.0550314 0.526549 SedativesHowManyTimes/Life 0.0350997 0.335146 CocaineHowManyTimes/Life 0.0254969 0.242931 CigsSmoked/30Days 0.0233875 0.222674 ReligionImportance 0.0198766 0.188959 SchoolDaysMissedSkipped/4Weeks 0.0195713 0.186027 PsychedelicsHowManyTimes/Life 0.0194071 0.18445 HrsWorkedPerWeek 0.0192343 0.182791 FatherEduLvl 0.0183928 0.174711 MotherHadPaidJobWhileGrowingUp 0.0183627 0.174421 LikelyToAttendVocationalSchl 0.018341 0.174213 Conclusions \u00b6 By employing SMOTE and cross-validation techniques, we successfully identified the random forest classifier and lasso logistic regression model as two effective models for accurately predicting the likelihood of survey subjects having used opiates or heroin during their 12th grade year. Using these models, we evaluated the influential variables that impacted our predictions. Many of the identified important variables aligned with expectations. It was not surprising to find that students who engaged in various illicit drug use and underage drinking were at higher risk of using opiates and heroin. Additionally, we discovered that a number of factors such as the student's desire to pursue secondary education or the freuency of skipping class had a minimal impact on the lasso logistic regression model's outcomes. This suggests that these variables may not be significant predictors of opiate/heroin usage according to the model. Future Work \u00b6 Future work is planned in order to incorporate the ICPSR Monitoring the Future data for years outside of 2019. We would like to analyze the survey results from years prior to the COVID-19 pandemic in comparison to survey results during the pandemic in order to examine how 12th grader opiate use and the factors influencing their opiate use have changed over time.","title":"MTF 12th Grader Opiate Use In 2019"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#monitoring-the-future-12th-grader-opiate-use-part-1","text":"","title":"Monitoring The Future: 12th Grader Opiate Use - Part 1"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#j-m-maxwell-data-science-sr-analyst-ctds","text":"","title":"J M Maxwell - Data Science, Sr. Analyst - CTDS"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#analysis-introduction","text":"","title":"Analysis Introduction"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#about-the-data","text":"The Monitoring The Future surveys are a series of surveys that have emerged as a vital tool in measuring the values, behaviors, and lifestyle orientations among American youth. Through a comprehensive series of surveys, these studies offer a unique window into the ever-changing landscape of 12th grade students. Students are randomly assigned one of six questionnaires; each questionnaire comprises both a core set of questions common to all surveys and a set of questions tailored to the specific survey, collectively providing a rich dataset for exploration. There are approximately 1,400 variables across all of the questionnaires; while recognizing the vastness of the available data, our exploration will be primarily focused on a subset of variables deemed particularly relevant to our research objectives. One of the critical aspects examined in the surveys pertains to the frequency of drug use among students, encompassing a wide array of illicit and recreational substances. In the context of this analysis, specific attention has been limited to surveys which observe instances where students engaged in the use of heroin or other opioid narcotics. While the investigation of drug use patterns holds significance in understanding the landscape of contemporary American youth, the Monitoring The Future surveys provide a broader canvas for exploration. Our analysis encompasses an assortment of other captivating topics including, but not limited to, students' perspectives on religion, educational goals, family life dynamics, and work habits. By examining these multidimensional facets, we may gain a holistic understanding of the myriad factors influencing the lives, aspirations, and substance use risks of American youth.","title":"About The Data"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#import-python-packages-and-data","text":"! pip install matplotlib - q ! pip install scikit - learn - q ! pip install imblearn - q import pandas as pd pd . set_option ( 'future.no_silent_downcasting' , True ) import numpy as np import random import matplotlib.pyplot as plt from collections import Counter from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import cross_validate from sklearn.svm import SVC from sklearn.metrics import recall_score , precision_score , accuracy_score from sklearn.utils import resample from sklearn.decomposition import PCA from imblearn.over_sampling import SMOTE from imblearn.pipeline import Pipeline from IPython.display import Markdown import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) random_seed = 2023 df_12_2019_1 = pd . read_csv ( 'Grade12/ICPSR_37841/DS0001/37841-0001-Data.tsv' , sep = ' \\t ' ) df_12_2019_3 = pd . read_csv ( 'Grade12/ICPSR_37841/DS0003/37841-0003-Data.tsv' , sep = ' \\t ' )","title":"Import Python Packages And Data"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#data-cleaning-and-feature-selection","text":"Below is a key for mapping the surveys' coded variable names to a more interpretable set of variable labels. We identified a number variables from the original dataset that needed to be removed because they were highly correlated. For instance, we observed among the survey recipients an unsurprising association between the number of alcoholic drinks consumed this year and the number of alcoholic drinks consumed in the last 30 days. We believe that the latter variable will serve as a more robust indicator for opiate use, so to streamline our analysis and enhance the veracity of our work, we made the decision to remove the former variable. The initial dataset comprises an impressive collection of 16,000+ survey results, each representing an observation from a survey participant. However, it is important to note that a substantial portion of these observations were removed during the data cleaning process, as those observations were missing portions of their data. Most of the data you see below is either recorded as a binary outcome (1/yes or 0/no), as an ordinal value(i.e., 0 = no drug use, 1 = some drug use, 2 = frequent drug use), or as a categorical feature. The categorical data is encoded and represented as binary data. variable_dict = { 'RESPONDENT_AGE' : 'Over18' , 'V13' : 'SchoolRegion' , 'V49' : 'NumberOfSiblings' , 'V2102' : 'CigsSmoked/30Days' , 'V2106' : 'AlcoholicDrinksHowManyTimes/30Days' , 'V2117' : 'MarijuanaHowManyTimes/30Days' , 'V2118' : 'LSDHowManyTimes/Life' , 'V2121' : 'PsychedelicsHowManyTimes/Life' , 'V2124' : 'CocaineHowManyTimes/Life' , 'V2127' : 'AmphetaminesHowManyTimes/Life' , 'V2133' : 'SedativesHowManyTimes/Life' , 'V2136' : 'TranquilizersHowManyTimes/Life' , 'V2139' : 'HerHowManyTimes/Life' , 'V2142' : 'NarcHowManyTimes/Life' , 'V2150' : 'Sex' , 'V2151' : 'Race' , 'V2152' : 'RaisedWhere' , 'V2153' : 'MaritalStatus' , 'V2155' : 'LivesWithFather' , 'V2156' : 'LivesWithMother' , 'V2157' : 'LivesWithSiblings' , 'V2163' : 'FatherEduLvl' , 'V2164' : 'MotherEduLvl' , 'V2165' : 'MotherHadPaidJobWhileGrowingUp' , 'V2166' : 'PoliticalPreference' , 'V2167' : 'PoliticalBeliefs' , 'V2169' : 'ReligiousServiceAttendenceWkly' , 'V2170' : 'ReligionImportance' , 'V2172' : 'HighSchoolProgram' , 'V2174' : 'SelfRateIntelligence' , 'V2175' : 'SchoolDaysMissedIllness/4Weeks' , 'V2176' : 'SchoolDaysMissedSkipped/4Weeks' , 'V2177' : 'SchoolDaysMissedOther/4Weeks' , 'V2178' : 'SkippedClass/4Weeks' , 'V2179' : 'AverageGradeHS' , 'V2180' : 'LikelyToAttendVocationalSchl' , 'V2181' : 'LikelyToServeInMilitary' , 'V2182' : 'LikelyToGraduate2YrCollege' , 'V2183' : 'LikelyToGraduate4YrCollege' , 'V2184' : 'LikelyToAttendGraduateSchl' , 'V2185' : 'WantToDoVocationalSchl' , 'V2186' : 'WantToServeInMilitary' , 'V2187' : 'WantToDo2YrCollege' , 'V2188' : 'WantToDo4YrCollege' , 'V2189' : 'WantToDoGradSchl' , 'V2190' : 'WantToDoNo2ndEd' , 'V2191' : 'HrsWorkedPerWeek' , 'V2193' : 'MoneyFromOtherSource' , 'V2194' : 'EveningsOutPerWeek' , 'V2195' : 'DatesHowOften' , 'V2196' : 'MilesDrivenPerWeek' , 'V2197' : 'DrivingTickets' , 'V2201' : 'CarAccidentsLast12Mo' , 'V2459' : 'CrackHowManyTimes/Life' , } The folowing steps were taken to clean the data: 1) We filtered the existing data by removing all variables missing more than 30% of their resepective values. We then remove all observations missing any survey responses. 2) We combined the survey questions asking students how many times they have used heroin and how many times they used opioid narcotics in their life into a single variable marking whether they have ever used heroin or an opiate. 3) We renamed all of our variables using the coded data dictionary above. 4) We factored the categorical data so it can be represented numerically. 5) We normalized the data so the ordinal and numerical outcomes do not have an oversized effect on our models. After these steps are complete we are left with only 5377 survey observations, approximately a third of our initial data. # Filter data down to just the variable dictionary, removing correlated features in the process variables = list ( variable_dict . keys ()) df = pd . concat ([ df_12_2019_1 [ variables ], df_12_2019_3 [ variables ]], ignore_index = True ) # Remove missing data missing_criteria = ( df == - 9 ) . sum () < 0.3 * len ( df . index ) df = df [ missing_criteria . index [ missing_criteria ]] df_counts = df . apply ( pd . Series . value_counts , axis = 1 ) missing_data = df_counts . iloc [:, 0 ] missing_data = missing_data . fillna ( 0 ) minimal_missing = missing_data . index [ missing_data < 1 ] df = df [ df . index . isin ( minimal_missing )] # Combine Opiate Use data df [ 'OpiateUse' ] = (( df [ 'V2142' ] != 1 ) + ( df [ 'V2139' ] != 1 )) . astype ( int ) df = df . drop ([ 'V2142' , 'V2139' ], axis = 1 ) # Rename columns using data dictionary df . rename ( columns = variable_dict , inplace = True ) # Factor categorical data dummy_cols = [ 'SchoolRegion' , 'Race' , 'RaisedWhere' , 'MaritalStatus' , 'PoliticalPreference' , 'PoliticalBeliefs' , 'HighSchoolProgram' ] dummies = pd . get_dummies ( df [ dummy_cols ], columns = dummy_cols , drop_first = True ) df = pd . concat ([ df , dummies ], axis = 1 ) df = df . drop ( dummy_cols , axis = 1 ) # Normalize data df . replace ({ False : 0 , True : 1 }, inplace = True ) df = ( df - df . min ()) / ( df . max () - df . min ()) df = df . reset_index ( drop = True )","title":"Data Cleaning And Feature Selection"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#model-selection","text":"We began our model selection stage by training five different machine learning models and comparing their performance. We then selected the two best performing models. The five initial models we trained were a simple logistic regression model, a lasso logistic regression model, a ridge logistic regression model, a support vector machine (SVM) classifier, and a random forest classifier.","title":"Model Selection"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#model-overview","text":"Logistic Regression Model : A widely used technique for exploring relationships between predictor variables and the probability of a set of binary outcomes occuring. Lasso Logistic Regression Model : A variation of the logistic regression model that incorporates a component encouraging the model to minimize the number of predictor variables, helping us identify which predictor variables are most (and least) influential. Ridge Logistic Regression Model : Another variation of the logistic regression model that promotes a balanced selection of predictor variables, allowing us to more clearly compare the influence of different predictor variables on opiate use. Support Vector Machine (SVM) Classifier : a classification model specificly suited to uncover complex boundaries to distinguish between classes of opiate users and non-users. Random Forest Classifier : Utilizes the collective descision making power of an ensemble of smaller, simpler models (decison trees) to produce more robust insights on the factors associated with opiate use in students.","title":"Model Overview"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#cross-validation","text":"In order to make a precise comparison between these five models, we need to utilize cross-validation. Cross-validation involves executing multiple iterations of training and testing a model on various random, resampled selections of the data. This method is primarily used to estimate how a predictive model will perform in practice. In our use case, we compared the performance of our five models during cross-validation to determine which models perform best.","title":"Cross Validation"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#resolving-class-imbalances","text":"As expected, a limited number of the students surveyed had ever used opiates. Only 295 of the 5377 (approx. 5.5%) students had ever used opiates or heroin recreationally. This imbalance in classes made it very difficult to train a model to predict occurances of the minority class (opiate use) accurately. To resolve this problem, we used a technique called Synthetic Minority Oversampling Technique (SMOTE) . SMOTE synthesizes new examples from the minority class by creating synthetic data points which only slightly differ from the original data points of the minority class.","title":"Resolving Class Imbalances"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#smote-cross-validation-pipeline","text":"Below you will find the function for a pipeline for performing model training and testing using 10-fold cross validation and SMOTE and for recording each model's cross validated performace. def pipeline_cross_validation ( data , k , pipeline_steps ): folds = np . array_split ( data , k ) accuracySum = 0 recallSum = 0 precisionSum = 0 for i in range ( k ): train = folds . copy () test = folds [ i ] del train [ i ] train = pd . concat ( train , sort = False ) y_train = train . OpiateUse . astype ( int ) X_train = train . drop ( 'OpiateUse' , axis = 1 ) y_test = test . OpiateUse . astype ( int ) X_test = test . drop ( 'OpiateUse' , axis = 1 ) pipeline = Pipeline ( pipeline_steps ) . fit ( X_train , y_train ) y_pred = pipeline . predict ( X_test ) accuracySum += accuracy_score ( y_test , y_pred ) recallSum += recall_score ( y_test , y_pred ) precisionSum += precision_score ( y_test , y_pred ) return [ accuracySum / k , recallSum / k , precisionSum / k ]","title":"SMOTE Cross Validation Pipeline"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#model-cross-validation","text":"k = 10 df2 = df . iloc [ np . random . permutation ( len ( df ))] classification_scores = pd . DataFrame ({ 'Metric' : [ 'Accuracy' , 'Recall' , 'Precision' ]}) smt = SMOTE ( random_state = random_seed ) model = LogisticRegression ( solver = 'liblinear' ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Logistic Regression' ] = pipeline_cross_validation ( df2 , k , steps ) model = LogisticRegression ( solver = 'liblinear' , penalty = 'l1' ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Lasso Logistic Regression' ] = pipeline_cross_validation ( df2 , k , steps ) model = LogisticRegression ( solver = 'liblinear' , penalty = 'l2' ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Ridge Logistic Regression' ] = pipeline_cross_validation ( df2 , k , steps ) model = SVC ( C = 1.5 , kernel = 'rbf' ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Support Vector Machine' ] = pipeline_cross_validation ( df2 , k , steps ) model = RandomForestClassifier ( n_estimators = 100 , criterion = 'entropy' , bootstrap = True ) steps = [( 'smt' , smt ), ( 'model' , model )] classification_scores [ 'Random Forest Classifier' ] = pipeline_cross_validation ( df2 , k , steps )","title":"Model Cross Validation"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#model-classification-scores","text":"Below we find the model accuracy, recall, and precision scores for all five models. All three metrics are scored between 0.0 and 1.0, with 1.0 being a perfect score. In our current application, model accuracy is a measurement of how well the model correctly labels whether a student is likely to either have used opiates/heroin or to not have used opiates/heroin. Recall measures how well the model performs at detecting all of the subjects who have used opiates/heroin. Precision measures how well the model performs at accurately specifying which subjects have used opiates/heroin from those subjects who have not used opiates/heroin. While we resolved the class imbalance when training our models, the class imbalance can still effect our scores, particularly model accuracy during testing. With that in mind, we primarily relied on the recall and precision scores when comparing the performance of the models and selecting our final two models. Markdown ( classification_scores . head () . to_markdown ()) Metric Logistic Regression Lasso Logistic Regression Ridge Logistic Regression Support Vector Machine Random Forest Classifier 0 Accuracy 0.863121 0.866843 0.863121 0.961129 0.967452 1 Recall 0.704792 0.703083 0.704792 0.524306 0.515776 2 Precision 0.244013 0.250618 0.244013 0.699461 0.80553","title":"Model Classification Scores"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#model-selection_1","text":"We chose one model with the highest recall score and one with the highest precision score. The random forest classifier clearly had the best precison score. The three logistic regression models all had very similar recall scores, however, we chose the lasso logistic regression model from those three models. The lasso logistic regression model will typically be more interpretable and simpler by reducing the number of variables. We proceeded with retraining the random forest classifier and lasso logistic regression models so we could examine what each model believes to be the most influential variables on whether a 12th grader has ever used opiates/heroin.","title":"Model Selection"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#model-analysis","text":"X = df . drop ( 'OpiateUse' , axis = 1 ) y = df . OpiateUse . astype ( int ) X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = random_seed ) classification_scores = pd . DataFrame ({ 'Metric' : [ 'Accuracy' , 'Recall' , 'Precision' ]}) model = RandomForestClassifier ( n_estimators = 100 , criterion = 'entropy' , bootstrap = True ) steps = [( 'smt' , smt ), ( 'model' , model )] pipeline = Pipeline ( steps ) . fit ( X_train , y_train ) y_pred = pipeline . predict ( X_test ) feature_importance = pd . DataFrame ({ 'RF Feature Importance' : pipeline [ 'model' ] . feature_importances_ }, index = df . columns . drop ( 'OpiateUse' )) feature_importance [ 'Normalized RF Feature Importance' ] = ( pipeline [ 'model' ] . feature_importances_ - min ( pipeline [ 'model' ] . feature_importances_ )) / ( max ( pipeline [ 'model' ] . feature_importances_ ) - min ( pipeline [ 'model' ] . feature_importances_ )) classification_scores [ 'Random Forest Classifier' ] = [ accuracy_score ( y_test , y_pred ), recall_score ( y_test , y_pred ), precision_score ( y_test , y_pred )] model = LogisticRegression ( solver = 'liblinear' , penalty = 'l1' ) steps = [( 'smt' , smt ), ( 'model' , model )] pipeline = Pipeline ( steps ) . fit ( X_train , y_train ) y_pred = pipeline . predict ( X_test ) feature_importance [ 'Lasso Model Coefficients' ] = pipeline [ 'model' ] . coef_ [ 0 ] feature_importance [ 'Lasso Model Coefficients AbsVal' ] = abs ( pipeline [ 'model' ] . coef_ [ 0 ]) classification_scores [ 'Lasso Logistic Regression' ] = [ accuracy_score ( y_test , y_pred ), recall_score ( y_test , y_pred ), precision_score ( y_test , y_pred )] Again we see similar recall and precision scores as before. Markdown ( classification_scores . to_markdown ()) Metric Random Forest Classifier Lasso Logistic Regression 0 Accuracy 0.958178 0.859665 1 Recall 0.476923 0.753846 2 Precision 0.738095 0.266304","title":"Model Analysis"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#lasso-logistic-regression-influential-variables","text":"We first looked at the most influential variables in the lasso logistic regression model. Below are a rank ordered list of the 15 most influential variables. Because the lasso logistic regression model's coefficients are related to a high recall score, they let us know which of the variables are the most influential on the model's ability to identify all of the students who have used opiates/heroin. This particular model was able to identify between 70% and 75% of all the surveyed students who had used opiates/heroin. In the data frame below, 'Lasso Model Coefficients' is the coefficient in the model and tells us the relative influence of each of the 10 variables with the greatest positive influence towards identifying students who used opiates. For instance, the frequency of with which students use tranquilizers or LSD (the two highest ranked variables) are highly influential in identifying students who have ever used opiates. Furthermore, 8 of top 10 variables that are highly related to student's opiate use involve the student's illicit use of other drugs or alcohol. When comparing the influence of each variable in our model, it is important to note the relative scale of the model coefficients. For instance, each use of amphetamines or cocaine in a students lifetime is approximately 3 times more influential to our model's prediction of opiate use than each use of marijuana or sedatives/barbituates. Markdown ( feature_importance . sort_values ( by = [ 'Lasso Model Coefficients' ], axis = 0 , ascending = False )[[ 'Lasso Model Coefficients' ]] . head ( 15 ) . to_markdown ()) Lasso Model Coefficients TranquilizersHowManyTimes/Life 7.3497 LSDHowManyTimes/Life 6.9445 CocaineHowManyTimes/Life 4.26338 AmphetaminesHowManyTimes/Life 4.14465 CigsSmoked/30Days 2.13381 AlcoholicDrinksHowManyTimes/30Days 1.69848 MarijuanaHowManyTimes/30Days 1.54761 SedativesHowManyTimes/Life 1.22001 LivesWithFather 0.978733 MotherHadPaidJobWhileGrowingUp 0.821343 WantToServeInMilitary 0.697732 AverageGradeHS 0.606838 LikelyToAttendVocationalSchl 0.595602 LikelyToAttendGraduateSchl 0.466966 MotherEduLvl 0.348325","title":"Lasso Logistic Regression Influential Variables"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#lasso-logistic-regression-least-influential-variables","text":"According to our lasso logistic regression model, these are the 10 least influential variables on whether a survey subject was likely or unlikely to use opiates/heroin. These attributes give little to no indication into whether a student will have illicitly used opiates or heroin. These variables are listed in order of least influence. The relevant encodings on this list are: 'PoliticalBeliefs_6' - Radical (ranked 1-6 from very conservative to radically liberal, with option for no belief) 'PoliticalBeliefs_3' - Moderate (ranked 1-6 from very conservative to radically liberal, with option for no belief) 'Race_3' - Hispanic (subjects self reported race as Black, White, or Hispanic) From our model, it appears that some student's political beliefs, the number of times the student has skipped class in the last four weeks, a lack of desire to pursure secondary education, and the number of psychedelics they have consumed in their lifetime all provide little to no information as to whether a student would or would not use opiates/heroin. Markdown ( feature_importance . sort_values ( by = [ 'Lasso Model Coefficients AbsVal' ], axis = 0 , ascending = True )[[ 'Lasso Model Coefficients AbsVal' ]] . head ( 10 ) . to_markdown ()) Lasso Model Coefficients AbsVal PsychedelicsHowManyTimes/Life 0 SkippedClass/4Weeks 0 WantToDoNo2ndEd 0 PoliticalBeliefs_3 0 PoliticalBeliefs_6 0 Race_3 0.0410165 DatesHowOften 0.0453305 LikelyToServeInMilitary 0.0460795 NumberOfSiblings 0.0713443 ReligiousServiceAttendenceWkly 0.0808742","title":"Lasso Logistic Regression Least Influential Variables"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#random-forest-influential-variables","text":"Now, let's analyze the key attributes of the random forest classification model. Presented below is a ranked list of the top 15 most important variables to our random forest model. These variables play a crucial role in achieving a high precision score and provide insights into the most influential factors affecting the model's capability to accurately distinguish and identify students who have used opiates/heroin (it is highly unlikely that the model will indicate that student who has never used opiates/heroin as having used opiates/heroin at least once in their life). In the data frame below, 'RF Feature Importance' is the Gini Feature Importance of the random forest model and 'Normalized RF Feature Importance' is the the same set of values normalized to a range between 0 and 1. As with our lasso logistic regression model, a variety of other drug and alcohol use is highly influential on whether a subject is likely to have or have not used opiates/heroin. Other important features include how often the subject goes out on dates, the self reported importance of religion and attendence to religious services, the number school days they have missed in the last four weeks, how many hours they work each week, and whether the subject's mother had a paid job growing up. Unlike the coefficients of our ridge logistic regression model above, these scores do not tell us whether a particular variable has a strong postive or negative influence on predicting whether a student has or has not used opiates/heroin. Markdown ( feature_importance . sort_values ( by = [ 'RF Feature Importance' ], axis = 0 , ascending = False )[[ 'RF Feature Importance' , 'Normalized RF Feature Importance' ]] . head ( 15 ) . to_markdown ()) RF Feature Importance Normalized RF Feature Importance TranquilizersHowManyTimes/Life 0.104334 1 AmphetaminesHowManyTimes/Life 0.0943735 0.90435 AlcoholicDrinksHowManyTimes/30Days 0.0748839 0.717192 MarijuanaHowManyTimes/30Days 0.0633785 0.606706 LSDHowManyTimes/Life 0.0550314 0.526549 SedativesHowManyTimes/Life 0.0350997 0.335146 CocaineHowManyTimes/Life 0.0254969 0.242931 CigsSmoked/30Days 0.0233875 0.222674 ReligionImportance 0.0198766 0.188959 SchoolDaysMissedSkipped/4Weeks 0.0195713 0.186027 PsychedelicsHowManyTimes/Life 0.0194071 0.18445 HrsWorkedPerWeek 0.0192343 0.182791 FatherEduLvl 0.0183928 0.174711 MotherHadPaidJobWhileGrowingUp 0.0183627 0.174421 LikelyToAttendVocationalSchl 0.018341 0.174213","title":"Random Forest Influential Variables"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#conclusions","text":"By employing SMOTE and cross-validation techniques, we successfully identified the random forest classifier and lasso logistic regression model as two effective models for accurately predicting the likelihood of survey subjects having used opiates or heroin during their 12th grade year. Using these models, we evaluated the influential variables that impacted our predictions. Many of the identified important variables aligned with expectations. It was not surprising to find that students who engaged in various illicit drug use and underage drinking were at higher risk of using opiates and heroin. Additionally, we discovered that a number of factors such as the student's desire to pursue secondary education or the freuency of skipping class had a minimal impact on the lasso logistic regression model's outcomes. This suggests that these variables may not be significant predictors of opiate/heroin usage according to the model.","title":"Conclusions"},{"location":"notebooks/Monitoring_The_Future_12th_Grader_Opiate_Use_In_2019/#future-work","text":"Future work is planned in order to incorporate the ICPSR Monitoring the Future data for years outside of 2019. We would like to analyze the survey results from years prior to the COVID-19 pandemic in comparison to survey results during the pandemic in order to examine how 12th grader opiate use and the factors influencing their opiate use have changed over time.","title":"Future Work"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/","text":"Opioid Related Deaths and Opioid Prevalence \u00b6 J Montgomery Maxwell \u00b6 06/28/2021 \u00b6 This notebook is a snapshot of publicly available data from HEAL and includes the DEA-ARCOS and CDC WONDER datasets. Data visualizations illustrate the national rise in opioid related overdoses and suicides, the rise in prevalence of opioid pills, and the current stage of the opioid epidemic in select states. The graphics presented here should not be considered as part of a rigorous study of the opioid epidemic or of public health policy. The purpose of this notebook is merely to demonstrate the advantages and capabilities of using the University of Chicago's Center for Translational Data Science's HEAL Data Commons. Table of Contents \u00b6 1) Setup Notebook 2) Import Datasets 3) National Opioid Deaths and Opioid Prevalence 4) Data Cleaning 5) West Virginia's Opioid Overdoses And Suicides 6) Conclusions 1) Setup Notebook \u00b6 ! pip install matplotlib - q import numpy as np import pandas as pd import requests import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) import matplotlib.pyplot as plt from matplotlib.ticker import FuncFormatter import matplotlib.patches as mpatches from pathlib import Path import os from IPython.display import Markdown , Image , display os . makedirs ( 'img/Opioid_Prevalence_And_Overdoses' ) ! gen3 drs - pull object dg . H34L / 4 b26774b - 4629 - 4363 - 8443 - e335d0de40c2 ! gen3 drs - pull object dg . H34L / 173 bf921 - 776 f - 4 c86 - 8 ea0 - 619 afdba0f1e ! gen3 drs - pull object dg . H34L / 4 f2764bd - 8847 - 4037 - ad1b - 0 c16d15f38d9 ! gen3 drs - pull object dg . H34L / 8128 a7c0 - 1791 - 4380 - b7b1 - a9af8a104304 ! gen3 drs - pull object dg . H34L / e091ebec - f111 - 4917 - 8317 - 204 c6b969011 ! gen3 drs - pull object dg . H34L / b1aa1e7c - 7869 - 475 a - 841 c - e2a94ac79481 ! gen3 drs - pull object dg . H34L / f726fbdb - c7c1 - 423 d - 99 d7 - 842 da441b509 {\"succeeded\": [\"dg.H34L/4b26774b-4629-4363-8443-e335d0de40c2\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/173bf921-776f-4c86-8ea0-619afdba0f1e\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/4f2764bd-8847-4037-ad1b-0c16d15f38d9\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/8128a7c0-1791-4380-b7b1-a9af8a104304\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/e091ebec-f111-4917-8317-204c6b969011\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/b1aa1e7c-7869-475a-841c-e2a94ac79481\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/f726fbdb-c7c1-423d-99d7-842da441b509\"], \"failed\": []} Common Code for Graphics \u00b6 def thousands ( x , pos ): return \" %1.0f K\" % ( x * 1e-3 ) def millions ( x , pos ): return \" %1.0f M\" % round (( x * 1e-6 ), 4 ) def percents ( x , pos ): return f \" { round ( x , 4 ) } %\" 2) Import Datasets \u00b6 Import DEA ARCOS \u00b6 arcos_drug_list = pd . read_csv ( \"./dea_arcos_drug_list.tsv\" , sep = \" \\t \" ) arcos_df = pd . read_csv ( \"./dea_arcos_county_population.tsv\" , sep = \" \\t \" ) arcos_df1 = pd . read_csv ( \"./dea_arcos_combined_county_annual.tsv\" , sep = \" \\t \" ) arcos_state_pop = pd . read_csv ( \"./dea_arcos_state_population.tsv\" , sep = \" \\t \" ) arcos_drug_list = arcos_drug_list . drop ([ 'Unnamed: 0' ], axis = 1 ) arcos_df [ \"KEY\" ] = arcos_df [ \"BUYER_COUNTY\" ] + ', ' + arcos_df [ \"BUYER_STATE\" ] + \", \" + arcos_df [ \"year\" ] . astype ( str ) arcos_df = arcos_df [[ \"KEY\" , \"BUYER_COUNTY\" , \"BUYER_STATE\" , \"year\" , \"population\" ]] arcos_df1 [ \"KEY\" ] = arcos_df1 [ \"BUYER_COUNTY\" ] + ', ' + arcos_df1 [ \"BUYER_STATE\" ] + \", \" + arcos_df1 [ \"year\" ] . astype ( str ) arcos_df1 = arcos_df1 [[ \"KEY\" , \"BUYER_STATE\" , \"count\" , \"DOSAGE_UNIT\" ]] arcos_df1 = arcos_df1 [ arcos_df1 [ \"KEY\" ] . notna ()] counts = arcos_df1 . set_index ( \"KEY\" )[ \"count\" ] . to_dict () doses = arcos_df1 . set_index ( \"KEY\" )[ \"DOSAGE_UNIT\" ] . to_dict () arcos_df [ \"count\" ] = arcos_df [ \"KEY\" ] . map ( counts ) arcos_df [ \"dosages\" ] = arcos_df [ \"KEY\" ] . map ( doses ) arcos_df [ \"pills per capita\" ] = arcos_df [ \"count\" ] / arcos_df [ \"population\" ] display ( Markdown ( arcos_drug_list . to_markdown ())) display ( Markdown ( arcos_df . head ( 5 ) . to_markdown ())) DRUG_NAME 0 FENTANYL 1 MORPHINE 2 MEPERIDINE 3 HYDROCODONE 4 OXYCODONE 5 CODEINE 6 HYDROMORPHONE 7 METHADONE 8 BUPRENORPHINE 9 OXYMORPHONE 10 OPIUM, POWDERED 11 TAPENTADOL 12 LEVORPHANOL 13 DIHYDROCODEINE KEY BUYER_COUNTY BUYER_STATE year population count dosages pills per capita 0 AUTAUGA, AL, 2006 AUTAUGA AL 2006 51328 5470 2.27714e+06 0.10657 1 BALDWIN, AL, 2006 BALDWIN AL 2006 168121 17381 6.3538e+06 0.103384 2 BARBOUR, AL, 2006 BARBOUR AL 2006 27861 2920 827060 0.104806 3 BIBB, AL, 2006 BIBB AL 2006 22099 1899 754210 0.0859315 4 BLOUNT, AL, 2006 BLOUNT AL 2006 55485 2757 1.2903e+06 0.0496891 Import the DEA ARCOS datasets for county and state populations from 2006 to 2014, and for the total pharmacy and practitioner pill counts by county and year. The county population and pill counts datasets are combined using a common key (county name, state name, year). An additional feature is added, 'pills per capita' which is the number of opioid pills per person in each county. Some counties have an abnormally large ratio of opioid pills per person; however these are from low county population sizes. DEA ARCOS: https://www.deadiversion.usdoj.gov/arcos/index.html Import CDC WONDER \u00b6 annual_overdoses = pd . read_csv ( \"./CDC_WONDER_unintentional_overdoses.tsv\" , sep = \" \\t \" ) annual_suicides = pd . read_csv ( \"./CDC_WONDER_suicide_overdoses.tsv\" , sep = \" \\t \" ) monthly_overdoses = pd . read_csv ( \"./monthly_unintentional_overdoses.tsv\" , sep = \" \\t \" ) annual_overdoses = annual_overdoses . drop ([ \"Unnamed: 0\" , \"Notes\" , \"Year Code\" , \"State Code\" ], axis = 1 ) annual_overdoses = annual_overdoses [ annual_overdoses [ \"Deaths\" ] . notna ()] annual_overdoses [ \"Year\" ] = annual_overdoses [ \"Year\" ] . map ( lambda x : str ( x )[: - 2 ]) annual_overdoses [ ' % o f Population' ] = ( annual_overdoses [ 'Deaths' ] / annual_overdoses [ 'Population' ]) * 100 annual_suicides = annual_suicides . drop ([ 'Unnamed: 0' , 'Notes' , 'State Code' , 'Year Code' ], axis = 1 ) annual_suicides = annual_suicides [ annual_suicides [ 'Deaths' ] . notna ()] annual_suicides [ \"Year\" ] = annual_suicides [ \"Year\" ] . map ( lambda x : str ( x )[: - 2 ]) annual_suicides [ ' % o f Population' ] = ( annual_suicides [ 'Deaths' ] / annual_suicides [ 'Population' ]) * 100 monthly_overdoses = monthly_overdoses . drop ([ 'Notes' , 'State Code' , 'Year Code' , 'Population' , 'Crude Rate' ], axis = 1 ) monthly_overdoses = monthly_overdoses [ monthly_overdoses [ 'Deaths' ] . notna ()] monthly_overdoses [ \"Year\" ] = monthly_overdoses [ \"Year\" ] . map ( lambda x : str ( x )[: - 2 ]) display ( Markdown ( annual_overdoses . head ( 5 ) . to_markdown ())) display ( Markdown ( annual_suicides . head ( 5 ) . to_markdown ())) Year State Deaths Population Crude Rate Crude Rate Lower 95% Confidence Interval Crude Rate Upper 95% Confidence Interval Crude Rate Standard Error % of Total Deaths % of Population 0 2000 Alabama 31 4.4471e+06 0.7 0.47 0.99 0.13 0.01% 0.000697083 1 2000 Alaska 22 626932 3.51 2.2 5.31 0.75 0.01% 0.00350915 2 2000 Arizona 195 5.13063e+06 3.8 3.27 4.33 0.27 0.05% 0.0038007 3 2000 California 891 3.38716e+07 2.63 2.46 2.8 0.09 0.21% 0.00263052 4 2000 Colorado 115 4.30126e+06 2.67 2.18 3.16 0.25 0.03% 0.00267363 Year State Deaths Population Crude Rate Crude Rate Lower 95% Confidence Interval Crude Rate Upper 95% Confidence Interval Crude Rate Standard Error % of Total Deaths % of Population 0 2000 Arizona 21 5.13063e+06 0.41 0.25 0.63 0.09 0.07% 0.000409306 1 2000 California 81 3.38716e+07 0.24 0.19 0.3 0.03 0.27% 0.000239138 2 2000 Colorado 19 4.30126e+06 Unreliable 0.27 0.69 0.1 0.06% 0.000441731 3 2000 Florida 78 1.59824e+07 0.49 0.39 0.61 0.06 0.26% 0.000488038 4 2000 Georgia 14 8.18645e+06 Unreliable 0.09 0.29 0.05 0.05% 0.000171014 Import the CDC WONDER datasets for annual, recorded opioid related unintentional overdoses and suicides, and monthly unintentional opioid overdoses. HEAL hosts the entire CDC WONDER dataset as well as these filtered datasets. Below are links to the CDC WONDER codebook explaining the ICD (International Classifications of Diseases) codes used in filtering for opioid related deaths and to the CDC WONDER website. CDC WONDER: https://wonder.cdc.gov ICD Opioid Codebook: https://mnprc.org/wp-content/uploads/2019/01/using-icd-10-codes-to-assess-opioid-related-overdose-deaths.pdf 3) National Opioid Deaths And Opioid Prevalence \u00b6 National Unintentional Opioid Overdoses And Suicides \u00b6 national_overdoses = annual_overdoses . groupby ( \"Year\" )[ \"Deaths\" ] . sum () + annual_suicides . groupby ( \"Year\" )[ \"Deaths\" ] . sum () fig , ax = plt . subplots ( figsize = ( 8 , 5 ), dpi = 100 ) ax . vlines ( x = national_overdoses . index , ymin = 0 , ymax = national_overdoses , color = \"grey\" , alpha = 1.0 , linewidth = 4 , ) ax . set_title ( f \"Annual National Opioid Overdoses And Suicides\" , size = 14 ) plt . grid ( axis = \"y\" , alpha = 0.3 ) ax . set_xlabel ( \"Year\" , size = 12 ) ax . set_ylabel ( \"Deaths\" , size = 11 ) formatter = FuncFormatter ( thousands ) ax . yaxis . set_major_formatter ( formatter ) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure1.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure1.png\" ) We see above that since 2000 the annual number of unintentional opioid overdoses and suicides has increased by more than a factor five and that since 2010 the annual number of deaths has more than doubled. National Opioid Prevalence \u00b6 opioids_yearly = arcos_df . groupby ( 'year' )[ 'count' ] . sum () fig , ax = plt . subplots ( figsize = ( 8 , 5 ), dpi = 100 ) ax . plot ( opioids_yearly , color = 'grey' ) ax . set_title ( f \"Annual National Pharmacy and Practitioner Pill Count\" , size = 14 ) plt . grid ( axis = \"y\" , alpha = 0.3 ) ax . set_xlabel ( \"Year\" , size = 12 ) ax . set_ylabel ( \"Pill Count\" , size = 11 ) formatter = FuncFormatter ( millions ) ax . yaxis . set_major_formatter ( formatter ) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure2.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure2.png\" ) We see above that the number of opioid pills in the United States has increased steadily from 2006 until 2013 when a significant decline occurred in the annual opioid pill count. It should be noted that the count only records pharmacy and practitioner's pill counts and does not include any illicit opioids. The types of opioids included in the count are listed in the arcos_drug_list dataframe shown previously. States With The Highest Annual Overdose Rate \u00b6 top_states = ( annual_overdoses . groupby ( \"Year\" )[[ \"State\" , \" % o f Population\" ]] . apply ( lambda grp : grp . nlargest ( 1 , \" % o f Population\" )) . reset_index () ) top_states [ 'State_and_Year' ] = top_states [ 'State' ] + ', ' + top_states [ 'Year' ] top_states = top_states . drop ([ 'Year' , 'level_1' , 'State' ], axis = 1 ) fig , ax = plt . subplots ( figsize = ( 8 , 5 ), dpi = 100 ) ax . vlines ( x = top_states [ 'State_and_Year' ], ymin = 0 , ymax = top_states [ ' % o f Population' ], color = \"grey\" , alpha = 1.0 , linewidth = 2.5 , ) ax . set_title ( f \"Unintentional Opioid Overdoses\" , size = 14 ) plt . grid ( axis = \"y\" , alpha = 0.3 ) ax . set_xlabel ( \"State and Year\" , size = 12 ) ax . set_ylabel ( \"Overdoses As Percent \\n Of Population\" , size = 11 ) formatter = FuncFormatter ( percents ) ax . yaxis . set_major_formatter ( formatter ) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure3.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure3.png\" ) In the last twenty years West Virginia has consistently had the highest percentage of unintentional opioid overdose deaths. West Virginia is the leading state in thirteen of the last twenty years including during the time period where there was a significant increase in annual opioid related overdoses and suicides (see figure 1). Going forward we will take a closer look at West Virginia's statewide opioid overdose and suicide mortality rate and respective changes in anti-epidemic policy. 4) Data Cleaning \u00b6 overdoses_wv = annual_overdoses [ annual_overdoses [ \"State\" ] == \"West Virginia\" ] . reset_index ( drop = True ) overdoses_wv = overdoses_wv . reset_index () suicides_wv = annual_suicides [ annual_suicides [ \"State\" ] == \"West Virginia\" ] . reset_index ( drop = True ) suicides_wv = suicides_wv . reset_index () monthly_overdoses_wv = monthly_overdoses [ monthly_overdoses [ \"State\" ] == \"West Virginia\" ] . reset_index ( drop = True ) monthly_overdoses_wv = monthly_overdoses_wv . reset_index () years = [ '2006' , '2007' , '2008' , '2009' , '2010' , '2011' , '2012' , '2013' , '2014' , '2015' , '2016' , '2017' , '2018' , '2019' ] ticks = [] for year in years : index = monthly_overdoses_wv . index [ monthly_overdoses_wv [ 'Year' ] == year ][ 0 ] ticks . append ( index ) 5) West Virginia's Opioid Overdoses and Suicides \u00b6 fig , ax = plt . subplots ( figsize = ( 10 , 6 ), dpi = 100 ) lns1 = ax . bar ( overdoses_wv [ 'Year' ], overdoses_wv [ 'Deaths' ], label = 'Overdoses' , width = 0.5 , color = 'grey' ) lns2 = ax . bar ( suicides_wv [ 'Year' ], suicides_wv [ 'Deaths' ], label = 'Overdoses' , width = 0.5 , color = 'red' ) ax . set_title ( f \" West Virginia's Annual Opioid Overdoses and Suicides\" , size = 14 ) ax . set_xlabel ( \"Year\" , size = 12 ) ax . set_ylabel ( \"Deaths\" , size = 11 ) red_patch = mpatches . Patch ( color = 'red' , label = 'Suicides' ) grey_patch = mpatches . Patch ( color = 'grey' , label = 'Overdoses' ) plt . legend ( handles = [ grey_patch , red_patch ]) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure4.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure4.png\" ) fig , ax = plt . subplots ( figsize = ( 10 , 6 ), dpi = 100 ) plt . xticks ( ticks ) start = monthly_overdoses_wv . index [ monthly_overdoses_wv [ 'Year' ] == '2006' ][ 0 ] end = monthly_overdoses_wv . index [ monthly_overdoses_wv [ 'Year' ] == '2019' ][ 1 ] monthly_overdoses_wv [ 'RollingYrAvg' ] = monthly_overdoses_wv [ 'Deaths' ] . rolling ( 6 ) . mean () lns1 = ax . vlines ( x = monthly_overdoses_wv . iloc [ start : end ] . index , ymin = 0 , ymax = monthly_overdoses_wv [ 'Deaths' ] . iloc [ start : end ], color = \"grey\" , alpha = 1.0 , linewidth = 1.0 , label = 'Deaths' ) lns2 = ax . plot ( monthly_overdoses_wv [ 'RollingYrAvg' ] . iloc [ start : end ], color = 'green' , label = 'Deaths Rolling Avg.' ) ax . set_title ( f \"West Virginia's Monthly Unintentional Overdose Deaths\" , size = 14 ) ax . set_xlabel ( \"Year\" , size = 12 ) ax . set_xticklabels ( years ) ax . set_ylabel ( \"Unintentional Overdose Deaths\" , size = 11 ) ax . legend ( loc = 2 ) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure5.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure5.png\" ) Since 2000 the annual number of reported unintentional opioid overdoses has grown from 24 in 2000 to over 600 in 2019 and since 2010 the annual number of unintentional overdoses has nearly doubled. The number of opioid related suicides has remained relatively steady since 2000. The second image looks at West Virginia's monthly unintentional overdoses with a 6 month rolling average. Here we can see there is not a large level of variation to the number of deaths on a monthly basis but the 6 month rolling average has a clear upward trend. The bar graphs for overdoses and suicides are superimposed, not stacked. Some data is missing at a monthly level, particularly prior to 2010. 6) Conclusions \u00b6 In this notebook we first looked at (figure 1) the annual national opioid suicides and unintentional overdoses and in (figure 2) the annual national pharmacy and practitioner opioid pill counts. Next, we found (figure 3) the states each year who have the highest rate of unintentional opioid overdose deaths as a percentage of each state's respective population. Finally, we examined opioid related suicides and unintentional overdoses at the state level in West Virgina (figure 4 and 5).","title":"Opioid Prevalence And Overdoses"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#opioid-related-deaths-and-opioid-prevalence","text":"","title":"Opioid Related Deaths and Opioid Prevalence"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#j-montgomery-maxwell","text":"","title":"J Montgomery Maxwell"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#06282021","text":"This notebook is a snapshot of publicly available data from HEAL and includes the DEA-ARCOS and CDC WONDER datasets. Data visualizations illustrate the national rise in opioid related overdoses and suicides, the rise in prevalence of opioid pills, and the current stage of the opioid epidemic in select states. The graphics presented here should not be considered as part of a rigorous study of the opioid epidemic or of public health policy. The purpose of this notebook is merely to demonstrate the advantages and capabilities of using the University of Chicago's Center for Translational Data Science's HEAL Data Commons.","title":"06/28/2021"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#table-of-contents","text":"1) Setup Notebook 2) Import Datasets 3) National Opioid Deaths and Opioid Prevalence 4) Data Cleaning 5) West Virginia's Opioid Overdoses And Suicides 6) Conclusions","title":"Table of Contents"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#1-setup-notebook","text":"! pip install matplotlib - q import numpy as np import pandas as pd import requests import warnings warnings . simplefilter ( action = 'ignore' , category = FutureWarning ) import matplotlib.pyplot as plt from matplotlib.ticker import FuncFormatter import matplotlib.patches as mpatches from pathlib import Path import os from IPython.display import Markdown , Image , display os . makedirs ( 'img/Opioid_Prevalence_And_Overdoses' ) ! gen3 drs - pull object dg . H34L / 4 b26774b - 4629 - 4363 - 8443 - e335d0de40c2 ! gen3 drs - pull object dg . H34L / 173 bf921 - 776 f - 4 c86 - 8 ea0 - 619 afdba0f1e ! gen3 drs - pull object dg . H34L / 4 f2764bd - 8847 - 4037 - ad1b - 0 c16d15f38d9 ! gen3 drs - pull object dg . H34L / 8128 a7c0 - 1791 - 4380 - b7b1 - a9af8a104304 ! gen3 drs - pull object dg . H34L / e091ebec - f111 - 4917 - 8317 - 204 c6b969011 ! gen3 drs - pull object dg . H34L / b1aa1e7c - 7869 - 475 a - 841 c - e2a94ac79481 ! gen3 drs - pull object dg . H34L / f726fbdb - c7c1 - 423 d - 99 d7 - 842 da441b509 {\"succeeded\": [\"dg.H34L/4b26774b-4629-4363-8443-e335d0de40c2\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/173bf921-776f-4c86-8ea0-619afdba0f1e\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/4f2764bd-8847-4037-ad1b-0c16d15f38d9\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/8128a7c0-1791-4380-b7b1-a9af8a104304\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/e091ebec-f111-4917-8317-204c6b969011\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/b1aa1e7c-7869-475a-841c-e2a94ac79481\"], \"failed\": []} {\"succeeded\": [\"dg.H34L/f726fbdb-c7c1-423d-99d7-842da441b509\"], \"failed\": []}","title":"1) Setup Notebook"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#common-code-for-graphics","text":"def thousands ( x , pos ): return \" %1.0f K\" % ( x * 1e-3 ) def millions ( x , pos ): return \" %1.0f M\" % round (( x * 1e-6 ), 4 ) def percents ( x , pos ): return f \" { round ( x , 4 ) } %\"","title":"Common Code for Graphics"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#2-import-datasets","text":"","title":"2) Import Datasets"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#import-dea-arcos","text":"arcos_drug_list = pd . read_csv ( \"./dea_arcos_drug_list.tsv\" , sep = \" \\t \" ) arcos_df = pd . read_csv ( \"./dea_arcos_county_population.tsv\" , sep = \" \\t \" ) arcos_df1 = pd . read_csv ( \"./dea_arcos_combined_county_annual.tsv\" , sep = \" \\t \" ) arcos_state_pop = pd . read_csv ( \"./dea_arcos_state_population.tsv\" , sep = \" \\t \" ) arcos_drug_list = arcos_drug_list . drop ([ 'Unnamed: 0' ], axis = 1 ) arcos_df [ \"KEY\" ] = arcos_df [ \"BUYER_COUNTY\" ] + ', ' + arcos_df [ \"BUYER_STATE\" ] + \", \" + arcos_df [ \"year\" ] . astype ( str ) arcos_df = arcos_df [[ \"KEY\" , \"BUYER_COUNTY\" , \"BUYER_STATE\" , \"year\" , \"population\" ]] arcos_df1 [ \"KEY\" ] = arcos_df1 [ \"BUYER_COUNTY\" ] + ', ' + arcos_df1 [ \"BUYER_STATE\" ] + \", \" + arcos_df1 [ \"year\" ] . astype ( str ) arcos_df1 = arcos_df1 [[ \"KEY\" , \"BUYER_STATE\" , \"count\" , \"DOSAGE_UNIT\" ]] arcos_df1 = arcos_df1 [ arcos_df1 [ \"KEY\" ] . notna ()] counts = arcos_df1 . set_index ( \"KEY\" )[ \"count\" ] . to_dict () doses = arcos_df1 . set_index ( \"KEY\" )[ \"DOSAGE_UNIT\" ] . to_dict () arcos_df [ \"count\" ] = arcos_df [ \"KEY\" ] . map ( counts ) arcos_df [ \"dosages\" ] = arcos_df [ \"KEY\" ] . map ( doses ) arcos_df [ \"pills per capita\" ] = arcos_df [ \"count\" ] / arcos_df [ \"population\" ] display ( Markdown ( arcos_drug_list . to_markdown ())) display ( Markdown ( arcos_df . head ( 5 ) . to_markdown ())) DRUG_NAME 0 FENTANYL 1 MORPHINE 2 MEPERIDINE 3 HYDROCODONE 4 OXYCODONE 5 CODEINE 6 HYDROMORPHONE 7 METHADONE 8 BUPRENORPHINE 9 OXYMORPHONE 10 OPIUM, POWDERED 11 TAPENTADOL 12 LEVORPHANOL 13 DIHYDROCODEINE KEY BUYER_COUNTY BUYER_STATE year population count dosages pills per capita 0 AUTAUGA, AL, 2006 AUTAUGA AL 2006 51328 5470 2.27714e+06 0.10657 1 BALDWIN, AL, 2006 BALDWIN AL 2006 168121 17381 6.3538e+06 0.103384 2 BARBOUR, AL, 2006 BARBOUR AL 2006 27861 2920 827060 0.104806 3 BIBB, AL, 2006 BIBB AL 2006 22099 1899 754210 0.0859315 4 BLOUNT, AL, 2006 BLOUNT AL 2006 55485 2757 1.2903e+06 0.0496891 Import the DEA ARCOS datasets for county and state populations from 2006 to 2014, and for the total pharmacy and practitioner pill counts by county and year. The county population and pill counts datasets are combined using a common key (county name, state name, year). An additional feature is added, 'pills per capita' which is the number of opioid pills per person in each county. Some counties have an abnormally large ratio of opioid pills per person; however these are from low county population sizes. DEA ARCOS: https://www.deadiversion.usdoj.gov/arcos/index.html","title":"Import DEA ARCOS"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#import-cdc-wonder","text":"annual_overdoses = pd . read_csv ( \"./CDC_WONDER_unintentional_overdoses.tsv\" , sep = \" \\t \" ) annual_suicides = pd . read_csv ( \"./CDC_WONDER_suicide_overdoses.tsv\" , sep = \" \\t \" ) monthly_overdoses = pd . read_csv ( \"./monthly_unintentional_overdoses.tsv\" , sep = \" \\t \" ) annual_overdoses = annual_overdoses . drop ([ \"Unnamed: 0\" , \"Notes\" , \"Year Code\" , \"State Code\" ], axis = 1 ) annual_overdoses = annual_overdoses [ annual_overdoses [ \"Deaths\" ] . notna ()] annual_overdoses [ \"Year\" ] = annual_overdoses [ \"Year\" ] . map ( lambda x : str ( x )[: - 2 ]) annual_overdoses [ ' % o f Population' ] = ( annual_overdoses [ 'Deaths' ] / annual_overdoses [ 'Population' ]) * 100 annual_suicides = annual_suicides . drop ([ 'Unnamed: 0' , 'Notes' , 'State Code' , 'Year Code' ], axis = 1 ) annual_suicides = annual_suicides [ annual_suicides [ 'Deaths' ] . notna ()] annual_suicides [ \"Year\" ] = annual_suicides [ \"Year\" ] . map ( lambda x : str ( x )[: - 2 ]) annual_suicides [ ' % o f Population' ] = ( annual_suicides [ 'Deaths' ] / annual_suicides [ 'Population' ]) * 100 monthly_overdoses = monthly_overdoses . drop ([ 'Notes' , 'State Code' , 'Year Code' , 'Population' , 'Crude Rate' ], axis = 1 ) monthly_overdoses = monthly_overdoses [ monthly_overdoses [ 'Deaths' ] . notna ()] monthly_overdoses [ \"Year\" ] = monthly_overdoses [ \"Year\" ] . map ( lambda x : str ( x )[: - 2 ]) display ( Markdown ( annual_overdoses . head ( 5 ) . to_markdown ())) display ( Markdown ( annual_suicides . head ( 5 ) . to_markdown ())) Year State Deaths Population Crude Rate Crude Rate Lower 95% Confidence Interval Crude Rate Upper 95% Confidence Interval Crude Rate Standard Error % of Total Deaths % of Population 0 2000 Alabama 31 4.4471e+06 0.7 0.47 0.99 0.13 0.01% 0.000697083 1 2000 Alaska 22 626932 3.51 2.2 5.31 0.75 0.01% 0.00350915 2 2000 Arizona 195 5.13063e+06 3.8 3.27 4.33 0.27 0.05% 0.0038007 3 2000 California 891 3.38716e+07 2.63 2.46 2.8 0.09 0.21% 0.00263052 4 2000 Colorado 115 4.30126e+06 2.67 2.18 3.16 0.25 0.03% 0.00267363 Year State Deaths Population Crude Rate Crude Rate Lower 95% Confidence Interval Crude Rate Upper 95% Confidence Interval Crude Rate Standard Error % of Total Deaths % of Population 0 2000 Arizona 21 5.13063e+06 0.41 0.25 0.63 0.09 0.07% 0.000409306 1 2000 California 81 3.38716e+07 0.24 0.19 0.3 0.03 0.27% 0.000239138 2 2000 Colorado 19 4.30126e+06 Unreliable 0.27 0.69 0.1 0.06% 0.000441731 3 2000 Florida 78 1.59824e+07 0.49 0.39 0.61 0.06 0.26% 0.000488038 4 2000 Georgia 14 8.18645e+06 Unreliable 0.09 0.29 0.05 0.05% 0.000171014 Import the CDC WONDER datasets for annual, recorded opioid related unintentional overdoses and suicides, and monthly unintentional opioid overdoses. HEAL hosts the entire CDC WONDER dataset as well as these filtered datasets. Below are links to the CDC WONDER codebook explaining the ICD (International Classifications of Diseases) codes used in filtering for opioid related deaths and to the CDC WONDER website. CDC WONDER: https://wonder.cdc.gov ICD Opioid Codebook: https://mnprc.org/wp-content/uploads/2019/01/using-icd-10-codes-to-assess-opioid-related-overdose-deaths.pdf","title":"Import CDC WONDER"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#3-national-opioid-deaths-and-opioid-prevalence","text":"","title":"3) National Opioid Deaths And Opioid Prevalence"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#national-unintentional-opioid-overdoses-and-suicides","text":"national_overdoses = annual_overdoses . groupby ( \"Year\" )[ \"Deaths\" ] . sum () + annual_suicides . groupby ( \"Year\" )[ \"Deaths\" ] . sum () fig , ax = plt . subplots ( figsize = ( 8 , 5 ), dpi = 100 ) ax . vlines ( x = national_overdoses . index , ymin = 0 , ymax = national_overdoses , color = \"grey\" , alpha = 1.0 , linewidth = 4 , ) ax . set_title ( f \"Annual National Opioid Overdoses And Suicides\" , size = 14 ) plt . grid ( axis = \"y\" , alpha = 0.3 ) ax . set_xlabel ( \"Year\" , size = 12 ) ax . set_ylabel ( \"Deaths\" , size = 11 ) formatter = FuncFormatter ( thousands ) ax . yaxis . set_major_formatter ( formatter ) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure1.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure1.png\" ) We see above that since 2000 the annual number of unintentional opioid overdoses and suicides has increased by more than a factor five and that since 2010 the annual number of deaths has more than doubled.","title":"National Unintentional Opioid Overdoses And Suicides"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#national-opioid-prevalence","text":"opioids_yearly = arcos_df . groupby ( 'year' )[ 'count' ] . sum () fig , ax = plt . subplots ( figsize = ( 8 , 5 ), dpi = 100 ) ax . plot ( opioids_yearly , color = 'grey' ) ax . set_title ( f \"Annual National Pharmacy and Practitioner Pill Count\" , size = 14 ) plt . grid ( axis = \"y\" , alpha = 0.3 ) ax . set_xlabel ( \"Year\" , size = 12 ) ax . set_ylabel ( \"Pill Count\" , size = 11 ) formatter = FuncFormatter ( millions ) ax . yaxis . set_major_formatter ( formatter ) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure2.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure2.png\" ) We see above that the number of opioid pills in the United States has increased steadily from 2006 until 2013 when a significant decline occurred in the annual opioid pill count. It should be noted that the count only records pharmacy and practitioner's pill counts and does not include any illicit opioids. The types of opioids included in the count are listed in the arcos_drug_list dataframe shown previously.","title":"National Opioid Prevalence"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#states-with-the-highest-annual-overdose-rate","text":"top_states = ( annual_overdoses . groupby ( \"Year\" )[[ \"State\" , \" % o f Population\" ]] . apply ( lambda grp : grp . nlargest ( 1 , \" % o f Population\" )) . reset_index () ) top_states [ 'State_and_Year' ] = top_states [ 'State' ] + ', ' + top_states [ 'Year' ] top_states = top_states . drop ([ 'Year' , 'level_1' , 'State' ], axis = 1 ) fig , ax = plt . subplots ( figsize = ( 8 , 5 ), dpi = 100 ) ax . vlines ( x = top_states [ 'State_and_Year' ], ymin = 0 , ymax = top_states [ ' % o f Population' ], color = \"grey\" , alpha = 1.0 , linewidth = 2.5 , ) ax . set_title ( f \"Unintentional Opioid Overdoses\" , size = 14 ) plt . grid ( axis = \"y\" , alpha = 0.3 ) ax . set_xlabel ( \"State and Year\" , size = 12 ) ax . set_ylabel ( \"Overdoses As Percent \\n Of Population\" , size = 11 ) formatter = FuncFormatter ( percents ) ax . yaxis . set_major_formatter ( formatter ) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure3.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure3.png\" ) In the last twenty years West Virginia has consistently had the highest percentage of unintentional opioid overdose deaths. West Virginia is the leading state in thirteen of the last twenty years including during the time period where there was a significant increase in annual opioid related overdoses and suicides (see figure 1). Going forward we will take a closer look at West Virginia's statewide opioid overdose and suicide mortality rate and respective changes in anti-epidemic policy.","title":"States With The Highest Annual Overdose Rate"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#4-data-cleaning","text":"overdoses_wv = annual_overdoses [ annual_overdoses [ \"State\" ] == \"West Virginia\" ] . reset_index ( drop = True ) overdoses_wv = overdoses_wv . reset_index () suicides_wv = annual_suicides [ annual_suicides [ \"State\" ] == \"West Virginia\" ] . reset_index ( drop = True ) suicides_wv = suicides_wv . reset_index () monthly_overdoses_wv = monthly_overdoses [ monthly_overdoses [ \"State\" ] == \"West Virginia\" ] . reset_index ( drop = True ) monthly_overdoses_wv = monthly_overdoses_wv . reset_index () years = [ '2006' , '2007' , '2008' , '2009' , '2010' , '2011' , '2012' , '2013' , '2014' , '2015' , '2016' , '2017' , '2018' , '2019' ] ticks = [] for year in years : index = monthly_overdoses_wv . index [ monthly_overdoses_wv [ 'Year' ] == year ][ 0 ] ticks . append ( index )","title":"4) Data Cleaning"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#5-west-virginias-opioid-overdoses-and-suicides","text":"fig , ax = plt . subplots ( figsize = ( 10 , 6 ), dpi = 100 ) lns1 = ax . bar ( overdoses_wv [ 'Year' ], overdoses_wv [ 'Deaths' ], label = 'Overdoses' , width = 0.5 , color = 'grey' ) lns2 = ax . bar ( suicides_wv [ 'Year' ], suicides_wv [ 'Deaths' ], label = 'Overdoses' , width = 0.5 , color = 'red' ) ax . set_title ( f \" West Virginia's Annual Opioid Overdoses and Suicides\" , size = 14 ) ax . set_xlabel ( \"Year\" , size = 12 ) ax . set_ylabel ( \"Deaths\" , size = 11 ) red_patch = mpatches . Patch ( color = 'red' , label = 'Suicides' ) grey_patch = mpatches . Patch ( color = 'grey' , label = 'Overdoses' ) plt . legend ( handles = [ grey_patch , red_patch ]) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure4.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure4.png\" ) fig , ax = plt . subplots ( figsize = ( 10 , 6 ), dpi = 100 ) plt . xticks ( ticks ) start = monthly_overdoses_wv . index [ monthly_overdoses_wv [ 'Year' ] == '2006' ][ 0 ] end = monthly_overdoses_wv . index [ monthly_overdoses_wv [ 'Year' ] == '2019' ][ 1 ] monthly_overdoses_wv [ 'RollingYrAvg' ] = monthly_overdoses_wv [ 'Deaths' ] . rolling ( 6 ) . mean () lns1 = ax . vlines ( x = monthly_overdoses_wv . iloc [ start : end ] . index , ymin = 0 , ymax = monthly_overdoses_wv [ 'Deaths' ] . iloc [ start : end ], color = \"grey\" , alpha = 1.0 , linewidth = 1.0 , label = 'Deaths' ) lns2 = ax . plot ( monthly_overdoses_wv [ 'RollingYrAvg' ] . iloc [ start : end ], color = 'green' , label = 'Deaths Rolling Avg.' ) ax . set_title ( f \"West Virginia's Monthly Unintentional Overdose Deaths\" , size = 14 ) ax . set_xlabel ( \"Year\" , size = 12 ) ax . set_xticklabels ( years ) ax . set_ylabel ( \"Unintentional Overdose Deaths\" , size = 11 ) ax . legend ( loc = 2 ) fig . autofmt_xdate ( rotation = 45 ) plt . close ( fig ) fig . savefig ( 'img/Opioid_Prevalence_And_Overdoses/figure5.png' ) Image ( filename = \"img/Opioid_Prevalence_And_Overdoses/figure5.png\" ) Since 2000 the annual number of reported unintentional opioid overdoses has grown from 24 in 2000 to over 600 in 2019 and since 2010 the annual number of unintentional overdoses has nearly doubled. The number of opioid related suicides has remained relatively steady since 2000. The second image looks at West Virginia's monthly unintentional overdoses with a 6 month rolling average. Here we can see there is not a large level of variation to the number of deaths on a monthly basis but the 6 month rolling average has a clear upward trend. The bar graphs for overdoses and suicides are superimposed, not stacked. Some data is missing at a monthly level, particularly prior to 2010.","title":"5) West Virginia's Opioid Overdoses and Suicides"},{"location":"notebooks/Opioid_Prevalence_And_Overdoses/#6-conclusions","text":"In this notebook we first looked at (figure 1) the annual national opioid suicides and unintentional overdoses and in (figure 2) the annual national pharmacy and practitioner opioid pill counts. Next, we found (figure 3) the states each year who have the highest rate of unintentional opioid overdose deaths as a percentage of each state's respective population. Finally, we examined opioid related suicides and unintentional overdoses at the state level in West Virgina (figure 4 and 5).","title":"6) Conclusions"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/","text":"Opioid Risk Metric Threshold Identification - Study Recreation \u00b6 - J M. Maxwell \u00b6 In this notebook we will be recreating the work by Cochran et al. from the paper Validation and Threshold Identification of a Prescription Drug Monitoring Program Clinical Opioid Risk Metric with the WHO Alcohol, Smoking, and Substance Involvement Screening Test . We will be utilizing data from the study Validation of a Community Pharmacy-Based Prescription Drug Monitoring Program Risk Screening Tool to recreate a number of the images and graphs as seen in the paper. This work was strictly done to demonstrate the advantages of the HEAL Platform's Workspace feature and the ability to utilize data that is joined under the HEAL data mesh. While all the work here was completed by J M. Maxwell and members of the HEAL Platform team, this is not original work, and it is exclusively based off of the work completed by Cochran et al. Due to compounding factors relating to variations in data cleaning methodologies, the work presented here will slightly vary from the results published in Validation and Threshold Identification... by Cochran et al. The work here does not represent the official opinions, recommendations, or conclusions of Cochran et al. and this work does not represent policy or medical recommendations on behalf of the NIH HEAL Initiative, The Center For Translational Data Science, or The University of Chicago. Access Data \u00b6 To access the data from this study make sure you are logged in to the InCommon login option and then: 1) Go to the HEAL discovery page to select the study 2) Select the 'Open In Workspace' option and choose the (Tutorials) Example Analysis Jupyter Lab Notebooks workspace option 3) Use the exported study manifest to download the study. Otherwise you may run the follwowing gen3-sdk command to download the relevant CSV file from the study. ! gen3 drs - pull object dg . H34L / f3de0abd - 5338 - 4 b42 - 8689 - 04 dfc46a6dbb {\"succeeded\": [\"dg.H34L/f3de0abd-5338-4b42-8689-04dfc46a6dbb\"], \"failed\": []} Introduction \u00b6 The Prescription Drug Monitoring Program (PDMP) is a highly available tool pharmacists may use to identify patients who are potentially misusing or abusing opioids. However, in practice, mixed results have been achieved in the application of PDMP to improve opioid safety. The output of PDMP information that pharmacists have access to is often un-summarized and of limited clinical value. Appriss Health has developed the Narcotic Score (NS) metric, a novel opioid risk identification metric, with the hope of offering to community pharmacists a clinical metric for identifying subjects with a high risk of opioid misuse and guidelines for promoting response and resources to those high risk individuals. Methods \u00b6 In their paper, Cochran et al. describe how the NS metric, composed of a collection of survey responses, is a continuous scale from 000-999; the first two numbers are a composite risk score derived from a collection of well known risk indicators and the third number is the total number of active opioid prescriptions (coded 0-9+). They compared and scaled the NS metric to the WHO Alcohol, Smoking, and Substance Involvement Screening Test (ASSIST), which is considered a gold-standard for assessing drug use risk. They then calculated the risk threshold identifications using the ASSIST prescription opioid subscale and all participants were sorted into one of three risk categories - low, moderate, and high. Data Preprocessing \u00b6 ! pip install matplotlib - q ! pip install scikit_learn - q import pandas as pd import numpy as np import os import matplotlib.pyplot as plt import matplotlib.image as mpimg from sklearn import metrics from zipfile import ZipFile from IPython.display import Markdown , Image , display os . makedirs ( 'img/Opioid_Risk_Metric_Threshold_Identification' ) Read Data \u00b6 Read in the data and filter by the relevant data fields: Unique Identifier, Narcotic Score, and ASSIST prescription opioid subscale responses. with ZipFile ( 'CTN0093_csv.zip' , 'r' ) as zip_object : zip_object . extractall () df = pd . read_csv ( 'CTN0093_FINAL_DATASET.csv' ) cols = [ x for x in df . columns if 'RX_OPIOID' in x ] df = df [[ 'ID' , 'NARCOTICSCORE' ] + cols ] . copy () Markdown ( df . head () . to_markdown ()) ID NARCOTICSCORE ASSIST_EVER_RX_OPIOID ASSIST_3MONTH_RX_OPIOID ASSIST_DESIRE_RX_OPIOID ASSIST_ISSUES_RX_OPIOID ASSIST_FAILED_RX_OPIOID ASSIST_WORRY_RX_OPIOID ASSIST_NO_CURB_RX_OPIOID 0 175702 341 3 6 0 0 0 0 0 1 958356 120 3 4 0 0 0 0 0 2 280698 451 3 6 6 0 0 0 0 3 324612 381 3 2 0 0 0 0 0 4 453755 321 0 nan nan nan nan nan nan Clean Data \u00b6 Map fields from string to integer values, remove observations with missing ASSIST responses, and replace missing values. df = df [ df . NARCOTICSCORE != 'Not in Appriss Database' ] . copy () df . NARCOTICSCORE = df . NARCOTICSCORE . astype ( int ) df = df [ df . ASSIST_EVER_RX_OPIOID != 999 ] . copy () df . replace ( np . nan , 0 , inplace = True ) Calculate ASSIST Risk Levels \u00b6 From their paper, Cochran et al., use the ASSIST prescription opioid risk subscale questionnaire to map subjects to their respective prescription opioid risk levels and remove subjects with incomplete questionnaire responses. assist_score = ( df . ASSIST_3MONTH_RX_OPIOID + df . ASSIST_DESIRE_RX_OPIOID + df . ASSIST_ISSUES_RX_OPIOID + df . ASSIST_FAILED_RX_OPIOID + df . ASSIST_WORRY_RX_OPIOID + df . ASSIST_NO_CURB_RX_OPIOID ) df [ 'ASSIST_SCORE' ] = assist_score df = df [ df . ASSIST_SCORE < 999 ] df [ 'ASSIST_LOW' ] = ( df . ASSIST_SCORE <= 3 ) df [ 'ASSIST_MEDIUM' ] = (( 4 <= df . ASSIST_SCORE ) & ( df . ASSIST_SCORE <= 26 )) df [ 'ASSIST_HIGH' ] = ( 27 <= df . ASSIST_SCORE ) print ( f \"\"\"Number of subjects with ASSIST low risk: { sum ( df [ 'ASSIST_LOW' ]) } \\n Number of subjects with ASSIST moderate risk: { sum ( df [ 'ASSIST_MEDIUM' ]) } \\n Number of subjects with ASSIST high risk: { sum ( df [ 'ASSIST_HIGH' ]) } \\n \"\"\" ) Number of subjects with ASSIST low risk: 772 Number of subjects with ASSIST moderate risk: 623 Number of subjects with ASSIST high risk: 33 Calculate Narcotic Score Risk Levels \u00b6 Cochran et al. applied grid search cross validation to select the risk thresholds by finding the NS metrics that gave the lowest average misclassification rate when segmenting low vs. medium and high risk and high vs. low and medium risk. The threshold for high risk individuals was a score of 602 and for low risk individuals was 291. df [ 'NS_LOW' ] = ( df . NARCOTICSCORE <= 291 ) df [ 'NS_MEDIUM' ] = (( 291 < df . NARCOTICSCORE ) & ( df . NARCOTICSCORE < 602 )) df [ 'NS_HIGH' ] = ( 602 < df . NARCOTICSCORE ) print ( f \"\"\"Number of subjects with NS low risk: { sum ( df [ 'NS_LOW' ]) } \\n Number of subjects with NS moderate risk: { sum ( df [ 'NS_MEDIUM' ]) } \\n Number of subjects with NS high risk: { sum ( df [ 'NS_HIGH' ]) } \\n \"\"\" ) Number of subjects with NS low risk: 733 Number of subjects with NS moderate risk: 689 Number of subjects with NS high risk: 6 Discriminating Validity of the NS metric \u00b6 They applied receiver operating characteristic (ROC) analysis to the ability to seperate high and moderate risk subjects and moderate and low risk subjects on the ASSIST subscale for prescription opioids using the NS metric. This application demonstrated to be reasonably successful. ns_metrics = df . NARCOTICSCORE . sort_values () . unique () y_high = df . ASSIST_HIGH y_low = df . ASSIST_LOW sensitivity_high = np . ones ( len ( ns_metrics )) specificity_high = np . ones ( len ( ns_metrics )) sensitivity_low = np . ones ( len ( ns_metrics )) specificity_low = np . ones ( len ( ns_metrics )) for i in range ( 0 , len ( ns_metrics )): y_pred_high = 1 * ( df . NARCOTICSCORE > ns_metrics [ i ]) y_pred_low = 1 * ( df . NARCOTICSCORE <= ns_metrics [ i ]) sensitivity_low [ i ] = sum ( y_low * y_pred_low ) / ( sum ( y_low * y_pred_low ) + sum ( - 1 * ( y_low ) * ( y_pred_low - 1 ))) specificity_low [ i ] = sum (( y_low - 1 ) * ( y_pred_low - 1 )) / ( sum (( y_low - 1 ) * ( y_pred_low - 1 )) + sum ( - 1 * ( y_low - 1 ) * ( y_pred_low ))) sensitivity_high [ i ] = sum ( y_high * y_pred_high ) / ( sum ( y_high * y_pred_high ) + sum ( - 1 * ( y_high ) * ( y_pred_high - 1 ))) specificity_high [ i ] = sum (( y_high - 1 ) * ( y_pred_high - 1 )) / ( sum (( y_high - 1 ) * ( y_pred_high - 1 )) + sum ( - 1 * ( y_high - 1 ) * ( y_pred_high ))) fig = plt . figure () plt . plot ( 1 - specificity_high , sensitivity_high ) plt . plot ( 1 - specificity_low , sensitivity_low ) high_auc = metrics . auc ( 1 - specificity_high , sensitivity_high ) low_auc = metrics . auc ( 1 - specificity_low , sensitivity_low ) plt . grid () plt . legend ([ f 'Moderate-High Risk Determination \\n AUC = { round ( high_auc , 2 ) } ' , f 'Low-Moderate Risk Determination \\n AUC = { round ( low_auc , 2 ) } ' ]) plt . title ( 'ROC curve for Narcotic Score Discriminating High vs. \\n Moderate risk and Moderate vs. Low risk Prescription Opioid Use' ) fig . savefig ( 'img/Opioid_Risk_Metric_Threshold_Identification/figure1.png' ) plt . close () Image ( filename = 'img/Opioid_Risk_Metric_Threshold_Identification/figure1.png' ) Risk Threshold Scores \u00b6 They next measured the agreement betwen the NS metric risk thresholds and the ASSIST score established risk thresholds using a confusion matrix below. Approximately 67.2% of the subjects were accurately mapped to the appropriate risk threshold using the NS metric, 17.0% of the participant classifications are false positives and the remaining 15.8% are false negatives. x = pd . DataFrame ( np . array ((( sum (( df . ASSIST_LOW == 1 ) & ( df . NS_LOW == 1 )), sum (( df . ASSIST_MEDIUM == 1 ) & ( df . NS_LOW == 1 )), sum (( df . ASSIST_HIGH == 1 ) & ( df . NS_LOW == 1 ))), ( sum (( df . ASSIST_LOW == 1 ) & ( df . NS_MEDIUM == 1 )), sum (( df . ASSIST_MEDIUM == 1 ) & ( df . NS_MEDIUM == 1 )), sum (( df . ASSIST_HIGH == 1 ) & ( df . NS_MEDIUM == 1 ))), ( sum (( df . ASSIST_LOW == 1 ) & ( df . NS_HIGH == 1 )), sum (( df . ASSIST_MEDIUM == 1 ) & ( df . NS_HIGH == 1 )), sum (( df . ASSIST_HIGH == 1 ) & ( df . NS_HIGH == 1 ))), ))) x . rename ( columns = { 0 : 'ASSIT Low Risk' , 1 : 'ASSIT Moderate Risk' , 2 : 'ASSIT High Risk' }, index = { 0 : 'NS Low Risk' , 1 : 'NS Moderate Risk' , 2 : 'NS High Risk' }, inplace = True ) table = x . astype ( str ) + ' - ' + ( 100 * x / x . sum () . sum ()) . round ( 1 ) . astype ( str ) + '%' Markdown ( table . to_markdown ()) ASSIT Low Risk ASSIT Moderate Risk ASSIT High Risk NS Low Risk 532 - 37.3% 194 - 13.6% 7 - 0.5% NS Moderate Risk 239 - 16.7% 426 - 29.8% 24 - 1.7% NS High Risk 1 - 0.1% 3 - 0.2% 2 - 0.1% Discussion And Conclusions \u00b6 Cochran et al. argue that the accuracy of the NS metric in segmenting subjects by their opioid risk demonstrates that the NS metric is a fair screening tool for detecting risky prescription opioid use. Additionally, combining the number of correctly identified risk profiles with the number of subjects who have high opioid use but low reported risk (those subjects likely needing additional screening), the NS metric provides a meaningful level (86%) of clinically useful and actionable information. Cochran et al. argue that this high rate of accurate, clinically actionable insights would suggest that the NS metric may have an impactful role as a \"universal screen\" because of its high availability to community pharmacists and physicians and its relatively low barriers of use. They beleive that inn application, after pharmacists or clinicians receive a subject's NS metric, the pharmacists or clinicians may use the scores to triage subjects based on their respective risk profiles. If subjects are of moderate or high risk, as determined by their Narcotic Score, pharmacists may then use a decision support tool like the Prescription Drug Monitoring Clinical Decision Support Tool to assess which further risk assessment tools and patient recommendations to make. According to the paper, false positive misclassification is greatest among subjects with significant outlying factors to their pain management or prescription opioid use, such as disability or generally poor health. If the NS metric is applied in clinical practice, these false positive classifications would require further patient screening to rule out risks of opioid misuse and to allow pharmacists and clinicians to recommend additional pain management solutions. The study from Cochran et al. explains how the NS metric can be used as a universal screening tool for prescription opioid misuse risk by clinicians and pharmacists at the community level. In particular, the NS metric offers an easy-to-use format for identifying risky subject profiles with minimal effort required from either the subject or the pharmacist, and utilization of the NS metric is well positioned to inform decision-making by pharmacists and to compliment existing surveys for assessing subjects' risks of prescription opioid misuse. References \u00b6 Paper \u00b6 Cochran G, Brown J, Yu Z, Frede S, Bryan MA, Ferguson A, Bayyari N, Taylor B, Snyder ME, Charron E, Adeoye-Olatunde OA, Ghitza UE, Winhusen T. Validation and threshold identification of a prescription drug monitoring program clinical opioid risk metric with the WHO alcohol, smoking, and substance involvement screening test. Drug Alcohol Depend. 2021 Nov 1;228:109067. doi: 10.1016/j.drugalcdep.2021.109067. Epub 2021 Sep 24. PMID: 34610516; PMCID: PMC8612015. Study \u00b6 Cochran G, Winhusen T. Validation of a Community Pharmacy-Based Prescription Drug Monitoring Program Risk Screening Tool. NIDA-CTN-0093. https://datashare.nida.nih.gov/study/nida-ctn-0093","title":"Opioid Risk Metric Threshold Identification - Study Recreation"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#opioid-risk-metric-threshold-identification-study-recreation","text":"","title":"Opioid Risk Metric Threshold Identification - Study Recreation"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#-j-m-maxwell","text":"In this notebook we will be recreating the work by Cochran et al. from the paper Validation and Threshold Identification of a Prescription Drug Monitoring Program Clinical Opioid Risk Metric with the WHO Alcohol, Smoking, and Substance Involvement Screening Test . We will be utilizing data from the study Validation of a Community Pharmacy-Based Prescription Drug Monitoring Program Risk Screening Tool to recreate a number of the images and graphs as seen in the paper. This work was strictly done to demonstrate the advantages of the HEAL Platform's Workspace feature and the ability to utilize data that is joined under the HEAL data mesh. While all the work here was completed by J M. Maxwell and members of the HEAL Platform team, this is not original work, and it is exclusively based off of the work completed by Cochran et al. Due to compounding factors relating to variations in data cleaning methodologies, the work presented here will slightly vary from the results published in Validation and Threshold Identification... by Cochran et al. The work here does not represent the official opinions, recommendations, or conclusions of Cochran et al. and this work does not represent policy or medical recommendations on behalf of the NIH HEAL Initiative, The Center For Translational Data Science, or The University of Chicago.","title":"- J M. Maxwell"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#access-data","text":"To access the data from this study make sure you are logged in to the InCommon login option and then: 1) Go to the HEAL discovery page to select the study 2) Select the 'Open In Workspace' option and choose the (Tutorials) Example Analysis Jupyter Lab Notebooks workspace option 3) Use the exported study manifest to download the study. Otherwise you may run the follwowing gen3-sdk command to download the relevant CSV file from the study. ! gen3 drs - pull object dg . H34L / f3de0abd - 5338 - 4 b42 - 8689 - 04 dfc46a6dbb {\"succeeded\": [\"dg.H34L/f3de0abd-5338-4b42-8689-04dfc46a6dbb\"], \"failed\": []}","title":"Access Data"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#introduction","text":"The Prescription Drug Monitoring Program (PDMP) is a highly available tool pharmacists may use to identify patients who are potentially misusing or abusing opioids. However, in practice, mixed results have been achieved in the application of PDMP to improve opioid safety. The output of PDMP information that pharmacists have access to is often un-summarized and of limited clinical value. Appriss Health has developed the Narcotic Score (NS) metric, a novel opioid risk identification metric, with the hope of offering to community pharmacists a clinical metric for identifying subjects with a high risk of opioid misuse and guidelines for promoting response and resources to those high risk individuals.","title":"Introduction"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#methods","text":"In their paper, Cochran et al. describe how the NS metric, composed of a collection of survey responses, is a continuous scale from 000-999; the first two numbers are a composite risk score derived from a collection of well known risk indicators and the third number is the total number of active opioid prescriptions (coded 0-9+). They compared and scaled the NS metric to the WHO Alcohol, Smoking, and Substance Involvement Screening Test (ASSIST), which is considered a gold-standard for assessing drug use risk. They then calculated the risk threshold identifications using the ASSIST prescription opioid subscale and all participants were sorted into one of three risk categories - low, moderate, and high.","title":"Methods"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#data-preprocessing","text":"! pip install matplotlib - q ! pip install scikit_learn - q import pandas as pd import numpy as np import os import matplotlib.pyplot as plt import matplotlib.image as mpimg from sklearn import metrics from zipfile import ZipFile from IPython.display import Markdown , Image , display os . makedirs ( 'img/Opioid_Risk_Metric_Threshold_Identification' )","title":"Data Preprocessing"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#read-data","text":"Read in the data and filter by the relevant data fields: Unique Identifier, Narcotic Score, and ASSIST prescription opioid subscale responses. with ZipFile ( 'CTN0093_csv.zip' , 'r' ) as zip_object : zip_object . extractall () df = pd . read_csv ( 'CTN0093_FINAL_DATASET.csv' ) cols = [ x for x in df . columns if 'RX_OPIOID' in x ] df = df [[ 'ID' , 'NARCOTICSCORE' ] + cols ] . copy () Markdown ( df . head () . to_markdown ()) ID NARCOTICSCORE ASSIST_EVER_RX_OPIOID ASSIST_3MONTH_RX_OPIOID ASSIST_DESIRE_RX_OPIOID ASSIST_ISSUES_RX_OPIOID ASSIST_FAILED_RX_OPIOID ASSIST_WORRY_RX_OPIOID ASSIST_NO_CURB_RX_OPIOID 0 175702 341 3 6 0 0 0 0 0 1 958356 120 3 4 0 0 0 0 0 2 280698 451 3 6 6 0 0 0 0 3 324612 381 3 2 0 0 0 0 0 4 453755 321 0 nan nan nan nan nan nan","title":"Read Data"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#clean-data","text":"Map fields from string to integer values, remove observations with missing ASSIST responses, and replace missing values. df = df [ df . NARCOTICSCORE != 'Not in Appriss Database' ] . copy () df . NARCOTICSCORE = df . NARCOTICSCORE . astype ( int ) df = df [ df . ASSIST_EVER_RX_OPIOID != 999 ] . copy () df . replace ( np . nan , 0 , inplace = True )","title":"Clean Data"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#calculate-assist-risk-levels","text":"From their paper, Cochran et al., use the ASSIST prescription opioid risk subscale questionnaire to map subjects to their respective prescription opioid risk levels and remove subjects with incomplete questionnaire responses. assist_score = ( df . ASSIST_3MONTH_RX_OPIOID + df . ASSIST_DESIRE_RX_OPIOID + df . ASSIST_ISSUES_RX_OPIOID + df . ASSIST_FAILED_RX_OPIOID + df . ASSIST_WORRY_RX_OPIOID + df . ASSIST_NO_CURB_RX_OPIOID ) df [ 'ASSIST_SCORE' ] = assist_score df = df [ df . ASSIST_SCORE < 999 ] df [ 'ASSIST_LOW' ] = ( df . ASSIST_SCORE <= 3 ) df [ 'ASSIST_MEDIUM' ] = (( 4 <= df . ASSIST_SCORE ) & ( df . ASSIST_SCORE <= 26 )) df [ 'ASSIST_HIGH' ] = ( 27 <= df . ASSIST_SCORE ) print ( f \"\"\"Number of subjects with ASSIST low risk: { sum ( df [ 'ASSIST_LOW' ]) } \\n Number of subjects with ASSIST moderate risk: { sum ( df [ 'ASSIST_MEDIUM' ]) } \\n Number of subjects with ASSIST high risk: { sum ( df [ 'ASSIST_HIGH' ]) } \\n \"\"\" ) Number of subjects with ASSIST low risk: 772 Number of subjects with ASSIST moderate risk: 623 Number of subjects with ASSIST high risk: 33","title":"Calculate ASSIST Risk Levels"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#calculate-narcotic-score-risk-levels","text":"Cochran et al. applied grid search cross validation to select the risk thresholds by finding the NS metrics that gave the lowest average misclassification rate when segmenting low vs. medium and high risk and high vs. low and medium risk. The threshold for high risk individuals was a score of 602 and for low risk individuals was 291. df [ 'NS_LOW' ] = ( df . NARCOTICSCORE <= 291 ) df [ 'NS_MEDIUM' ] = (( 291 < df . NARCOTICSCORE ) & ( df . NARCOTICSCORE < 602 )) df [ 'NS_HIGH' ] = ( 602 < df . NARCOTICSCORE ) print ( f \"\"\"Number of subjects with NS low risk: { sum ( df [ 'NS_LOW' ]) } \\n Number of subjects with NS moderate risk: { sum ( df [ 'NS_MEDIUM' ]) } \\n Number of subjects with NS high risk: { sum ( df [ 'NS_HIGH' ]) } \\n \"\"\" ) Number of subjects with NS low risk: 733 Number of subjects with NS moderate risk: 689 Number of subjects with NS high risk: 6","title":"Calculate Narcotic Score Risk Levels"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#discriminating-validity-of-the-ns-metric","text":"They applied receiver operating characteristic (ROC) analysis to the ability to seperate high and moderate risk subjects and moderate and low risk subjects on the ASSIST subscale for prescription opioids using the NS metric. This application demonstrated to be reasonably successful. ns_metrics = df . NARCOTICSCORE . sort_values () . unique () y_high = df . ASSIST_HIGH y_low = df . ASSIST_LOW sensitivity_high = np . ones ( len ( ns_metrics )) specificity_high = np . ones ( len ( ns_metrics )) sensitivity_low = np . ones ( len ( ns_metrics )) specificity_low = np . ones ( len ( ns_metrics )) for i in range ( 0 , len ( ns_metrics )): y_pred_high = 1 * ( df . NARCOTICSCORE > ns_metrics [ i ]) y_pred_low = 1 * ( df . NARCOTICSCORE <= ns_metrics [ i ]) sensitivity_low [ i ] = sum ( y_low * y_pred_low ) / ( sum ( y_low * y_pred_low ) + sum ( - 1 * ( y_low ) * ( y_pred_low - 1 ))) specificity_low [ i ] = sum (( y_low - 1 ) * ( y_pred_low - 1 )) / ( sum (( y_low - 1 ) * ( y_pred_low - 1 )) + sum ( - 1 * ( y_low - 1 ) * ( y_pred_low ))) sensitivity_high [ i ] = sum ( y_high * y_pred_high ) / ( sum ( y_high * y_pred_high ) + sum ( - 1 * ( y_high ) * ( y_pred_high - 1 ))) specificity_high [ i ] = sum (( y_high - 1 ) * ( y_pred_high - 1 )) / ( sum (( y_high - 1 ) * ( y_pred_high - 1 )) + sum ( - 1 * ( y_high - 1 ) * ( y_pred_high ))) fig = plt . figure () plt . plot ( 1 - specificity_high , sensitivity_high ) plt . plot ( 1 - specificity_low , sensitivity_low ) high_auc = metrics . auc ( 1 - specificity_high , sensitivity_high ) low_auc = metrics . auc ( 1 - specificity_low , sensitivity_low ) plt . grid () plt . legend ([ f 'Moderate-High Risk Determination \\n AUC = { round ( high_auc , 2 ) } ' , f 'Low-Moderate Risk Determination \\n AUC = { round ( low_auc , 2 ) } ' ]) plt . title ( 'ROC curve for Narcotic Score Discriminating High vs. \\n Moderate risk and Moderate vs. Low risk Prescription Opioid Use' ) fig . savefig ( 'img/Opioid_Risk_Metric_Threshold_Identification/figure1.png' ) plt . close () Image ( filename = 'img/Opioid_Risk_Metric_Threshold_Identification/figure1.png' )","title":"Discriminating Validity of the NS metric"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#risk-threshold-scores","text":"They next measured the agreement betwen the NS metric risk thresholds and the ASSIST score established risk thresholds using a confusion matrix below. Approximately 67.2% of the subjects were accurately mapped to the appropriate risk threshold using the NS metric, 17.0% of the participant classifications are false positives and the remaining 15.8% are false negatives. x = pd . DataFrame ( np . array ((( sum (( df . ASSIST_LOW == 1 ) & ( df . NS_LOW == 1 )), sum (( df . ASSIST_MEDIUM == 1 ) & ( df . NS_LOW == 1 )), sum (( df . ASSIST_HIGH == 1 ) & ( df . NS_LOW == 1 ))), ( sum (( df . ASSIST_LOW == 1 ) & ( df . NS_MEDIUM == 1 )), sum (( df . ASSIST_MEDIUM == 1 ) & ( df . NS_MEDIUM == 1 )), sum (( df . ASSIST_HIGH == 1 ) & ( df . NS_MEDIUM == 1 ))), ( sum (( df . ASSIST_LOW == 1 ) & ( df . NS_HIGH == 1 )), sum (( df . ASSIST_MEDIUM == 1 ) & ( df . NS_HIGH == 1 )), sum (( df . ASSIST_HIGH == 1 ) & ( df . NS_HIGH == 1 ))), ))) x . rename ( columns = { 0 : 'ASSIT Low Risk' , 1 : 'ASSIT Moderate Risk' , 2 : 'ASSIT High Risk' }, index = { 0 : 'NS Low Risk' , 1 : 'NS Moderate Risk' , 2 : 'NS High Risk' }, inplace = True ) table = x . astype ( str ) + ' - ' + ( 100 * x / x . sum () . sum ()) . round ( 1 ) . astype ( str ) + '%' Markdown ( table . to_markdown ()) ASSIT Low Risk ASSIT Moderate Risk ASSIT High Risk NS Low Risk 532 - 37.3% 194 - 13.6% 7 - 0.5% NS Moderate Risk 239 - 16.7% 426 - 29.8% 24 - 1.7% NS High Risk 1 - 0.1% 3 - 0.2% 2 - 0.1%","title":"Risk Threshold Scores"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#discussion-and-conclusions","text":"Cochran et al. argue that the accuracy of the NS metric in segmenting subjects by their opioid risk demonstrates that the NS metric is a fair screening tool for detecting risky prescription opioid use. Additionally, combining the number of correctly identified risk profiles with the number of subjects who have high opioid use but low reported risk (those subjects likely needing additional screening), the NS metric provides a meaningful level (86%) of clinically useful and actionable information. Cochran et al. argue that this high rate of accurate, clinically actionable insights would suggest that the NS metric may have an impactful role as a \"universal screen\" because of its high availability to community pharmacists and physicians and its relatively low barriers of use. They beleive that inn application, after pharmacists or clinicians receive a subject's NS metric, the pharmacists or clinicians may use the scores to triage subjects based on their respective risk profiles. If subjects are of moderate or high risk, as determined by their Narcotic Score, pharmacists may then use a decision support tool like the Prescription Drug Monitoring Clinical Decision Support Tool to assess which further risk assessment tools and patient recommendations to make. According to the paper, false positive misclassification is greatest among subjects with significant outlying factors to their pain management or prescription opioid use, such as disability or generally poor health. If the NS metric is applied in clinical practice, these false positive classifications would require further patient screening to rule out risks of opioid misuse and to allow pharmacists and clinicians to recommend additional pain management solutions. The study from Cochran et al. explains how the NS metric can be used as a universal screening tool for prescription opioid misuse risk by clinicians and pharmacists at the community level. In particular, the NS metric offers an easy-to-use format for identifying risky subject profiles with minimal effort required from either the subject or the pharmacist, and utilization of the NS metric is well positioned to inform decision-making by pharmacists and to compliment existing surveys for assessing subjects' risks of prescription opioid misuse.","title":"Discussion And Conclusions"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#references","text":"","title":"References"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#paper","text":"Cochran G, Brown J, Yu Z, Frede S, Bryan MA, Ferguson A, Bayyari N, Taylor B, Snyder ME, Charron E, Adeoye-Olatunde OA, Ghitza UE, Winhusen T. Validation and threshold identification of a prescription drug monitoring program clinical opioid risk metric with the WHO alcohol, smoking, and substance involvement screening test. Drug Alcohol Depend. 2021 Nov 1;228:109067. doi: 10.1016/j.drugalcdep.2021.109067. Epub 2021 Sep 24. PMID: 34610516; PMCID: PMC8612015.","title":"Paper"},{"location":"notebooks/Opioid_Risk_Metric_Threshold_Identification-Study_Recreation/#study","text":"Cochran G, Winhusen T. Validation of a Community Pharmacy-Based Prescription Drug Monitoring Program Risk Screening Tool. NIDA-CTN-0093. https://datashare.nida.nih.gov/study/nida-ctn-0093","title":"Study"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/","text":"Stigma Reduction among Primary Care Clinicians towards People with OUD - A Study and Research Validation Analysis \u00b6 By J M Maxwell - Data Science, Sr. Analyst - CTDS \u00b6 Introduction \u00b6 In this notebook, we\u2019ll be replicating the published analyses by Hooker et al. in A randomized controlled trial of an intervention to reduce stigma toward people with opioid use disorder among primary care clinicians ( PMC9922036 ), in order to demonstrate how users might use these data. These data are available from NIDA Data Share through the HEAL Data Platform. There is an ongoing, dramatic rise in the number of opioid related overdose deaths in the United States, however only a small portion of patients who are diagnosed with Opioid Use Disorders (OUD) seek treatment and recieve medications for OUD (MOUD). MOUDs, like buprenorphine, can be effective forms of treatment for OUD patients, but only a portion of clinicians are waivered to, and in actuality do, prescribe buprenophine. A potential barrier to care for OUD patients may be the stigma held by primary care clinicians (PCCs) towards people with OUD. There are a limited number of interventions available for reducing OUD stigma among PCCs and a need for analytical support for the efficacy of these interventions. A randomized controlled trial of an intervention... examines whether PCCs' stigma towards people with OUD may be reduced and PCCs' intentions to treat OUD patients increased through online training interventions. This work was done exclusively to demonstrate the advantages of the HEAL Platform's Workspace feature and the ability to utilize data that is joined under the HEAL data mesh. While all the work here was completed by J M. Maxwell and members of the HEAL Platform team, this is not original work, and it is exclusively based off of the work completed by Hooker et al. The work here does not represent the official opinions, recommendations, or conclusions of Hooker et al. and this work does not represent policy or medical recommendations on behalf of the authors, the NIH HEAL Initiative, The Center For Translational Data Science, or The University of Chicago. Hooker, Stephanie A et al. \u201cA randomized controlled trial of an intervention to reduce stigma toward people with opioid use disorder among primary care clinicians.\u201d Addiction science & clinical practice vol. 18,1 10. 11 Feb. 2023, doi:10.1186/s13722-023-00366-1 Import Python Libraries \u00b6 ! pip install matplotlib - q ! pip install scikit - learn - q import zipfile import pandas as pd import numpy as np import scipy import matplotlib.pyplot as plt import sklearn from sklearn import metrics from IPython.display import Markdown Ingest And Prepare Data \u00b6 In this section we ingest and prepare the data. We're particularly interested in the data fields related to the PCCs' attitude towards people with OUD, their attitudes towards treating people with OUD, and their demographic information. ! gen3 drs - pull object dg . H34L / a6c7fc23 - 3534 - 401 c - 88 ca - 9 fbbb495dcf4 {\"succeeded\": [\"dg.H34L/a6c7fc23-3534-401c-88ca-9fbbb495dcf4\"], \"failed\": []} with zipfile . ZipFile ( 'ascii-crf-data-files_nida-ctn-0095a2 v1-1.zip' , 'r' ) as zip_ref : zip_ref . extractall ( '.' ) def clean_df ( df ): col_names = { 'DDBS' : 'Overall Stigma' , 'DDBS_DIFF' : 'Difference' , 'DDBS_DISDAIN' : 'Disdain' , 'DDBS_BLAME2' : 'Blame' , 'INTEND_WAIVER' : 'Intentions to get waivered' , 'INTEND_PRESCRIBE' : 'Intentions to prescribe buprenorphine' , 'WILLWORK' : 'Willingness to work with OUD' , 'TX_EFFECTIVE' : 'Perceived OUD treatment effectiveness' , 'TX_ADHERENCE' : 'Perceived OUD treatment adherence' , 'PCC_AGE' : 'Age' , 'PCC_GENDER' : 'Gender' , 'PCC_RACE' : 'Race' , 'PCC_HISPANIC' : 'Ethnicity' , 'STIGMA_GROUP' : 'Stigma Group' , 'PCC_WAIVERED' : 'Waivered to prescribe buprenorphine' , 'PCC_MD' : 'Degree' } df . rename ( columns = col_names , inplace = True ) for field in [ 'STIG_CLIN_ID' , 'HLTH_SYS_ID' , 'PCC_ID' , 'COMPLETE_TRAINING' , 'COMPLETE_SURVEY' ]: if field in df . columns : df . drop ([ field ], axis = 1 , inplace = True ) df . Gender = df . Gender . fillna ( 7.0 ) df . Ethnicity = df . Ethnicity . fillna ( 7.0 ) df [ 'Race' ] = df . Race . map ({ '5 White' : 'White' , '9 Prefer not to answer' : 'Prefer not to answer' , '2 Asian' : 'Asian' , '3 Black or African American' : 'Black or African American' , '7 Multiple selected' : 'Multiple selected' , '6 Some other race' : 'Some other race' }) df [ 'Gender' ] = df . Gender . map ({ 2.0 : 'Female' , 1.0 : 'Male' , 6.0 : 'Not Listed' , 7.0 : 'Prefer not to answer' }) df [ 'Ethnicity' ] = df . Ethnicity . map ({ 0.0 : 'Not Hispanic or Latino' , 1.0 : 'Hispanic or Latino' , 7.0 : 'Missing' }) df [ 'Waivered to prescribe buprenorphine' ] = df [ 'Waivered to prescribe buprenorphine' ] . map ({ 0 : 'False' , 1 : 'True' }) df [ 'Degree' ] = df . Degree . map ({ 1 : 'MD/DO' , 0 : 'PA/NP' }) keep_list = list ( set ( df . columns ) & set ([ 'Stigma Group' , 'Overall Stigma' , 'Difference' , 'Disdain' , 'Blame' , 'Intentions to get waivered' , 'Intentions to prescribe buprenorphine' , 'Willingness to work with OUD' , 'Perceived OUD treatment effectiveness' , 'Perceived OUD treatment adherence' , 'Waivered to prescribe buprenorphine' , 'Gender' , 'Ethnicity' , 'Race' , 'Degree' ])) df = df [ keep_list ] return df def make_print_df ( df ): features = [ 'Gender' , 'Ethnicity' , 'Race' , 'Waivered to prescribe buprenorphine' , 'Degree' ] all_subj = [] print_df = pd . DataFrame () N_AC = int ( df [ 'Stigma Group' ] . value_counts ()[ 'STIG_CTRL' ]) N_SR = int ( df [ 'Stigma Group' ] . value_counts ()[ 'STIG_INT' ]) N = N_AC + N_SR for feat in features : print_df1 = pd . DataFrame ({ 'Category' : f ' { feat } - ' + df [ feat ] . value_counts () . index , f 'All N= { N } ' : ( 100 * df [ feat ] . value_counts () / len ( df )) . values . round ( 2 )} ) print_df2 = pd . DataFrame ({ 'Category' : f ' { feat } - ' + ( 100 * df [ df [ 'Stigma Group' ] == 'STIG_INT' ][ feat ] . value_counts () / len ( df [ df [ 'Stigma Group' ] == 'STIG_INT' ])) . index , f 'Stigma reduction n\u2009=\u2009 { N_SR } ' : ( 100 * df [ df [ 'Stigma Group' ] == 'STIG_INT' ][ feat ] . value_counts () / len ( df [ df [ 'Stigma Group' ] == 'STIG_INT' ])) . values . round ( 2 )} ) print_df3 = pd . DataFrame ({ 'Category' : f ' { feat } - ' + ( 100 * df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ][ feat ] . value_counts () / len ( df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ])) . index , f 'Attention-control n\u2009=\u2009 { N_AC } ' : ( 100 * df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ][ feat ] . value_counts () / len ( df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ])) . values . round ( 2 )} ) print_df1 = print_df1 . merge ( print_df2 , how = 'left' , on = 'Category' ) print_df1 = print_df1 . merge ( print_df3 , how = 'left' , on = 'Category' ) print_df1 . fillna ( 0 , inplace = True ) print_df1 [[ f 'All N= { N } ' , f 'Stigma reduction n\u2009=\u2009 { N_SR } ' , f 'Attention-control n\u2009=\u2009 { N_AC } ' ]] = print_df1 [[ f 'All N= { N } ' , f 'Stigma reduction n\u2009=\u2009 { N_SR } ' , f 'Attention-control n\u2009=\u2009 { N_AC } ' ]] . astype ( str ) print_df1 [ f 'All N= { N } ' ] = print_df1 [ f 'All N= { N } ' ] . apply ( lambda x : str ( x ) + '%' ) print_df1 [ f 'Stigma reduction n\u2009=\u2009 { N_SR } ' ] = print_df1 [ f 'Stigma reduction n\u2009=\u2009 { N_SR } ' ] . apply ( lambda x : str ( x ) + '%' ) print_df1 [ f 'Attention-control n\u2009=\u2009 { N_AC } ' ] = print_df1 [ f 'Attention-control n\u2009=\u2009 { N_AC } ' ] . apply ( lambda x : str ( x ) + '%' ) print_df = pd . concat ([ print_df , print_df1 ]) if feat != 'Degree' : print_df = pd . concat ([ print_df , pd . DataFrame ({ 'Category' : [ '-' ], f 'All N= { N } ' : [ '-' ], f 'Stigma reduction n\u2009=\u2009 { N_SR } ' : [ '-' ], f 'Attention-control n\u2009=\u2009 { N_AC } ' : [ '-' ] })]) return print_df def make_impact_df ( df , features ): stig_int = [] stig_ctrl = [] t_vals = [] p_vals = [] d_vals = [] def cohen_d ( x , y ): nx = len ( x ) ny = len ( y ) dof = nx + ny - 2 return ( np . mean ( x ) - np . mean ( y )) / np . sqrt ((( nx - 1 ) * np . std ( x , ddof = 1 ) ** 2 + ( ny - 1 ) * np . std ( y , ddof = 1 ) ** 2 ) / dof ) for feat in features : x = df [ df [ 'Stigma Group' ] == 'STIG_INT' ][ feat ] . dropna () y = df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ][ feat ] . dropna () # Perform the t-test t_statistic , p_value = scipy . stats . ttest_ind ( x , y ) d = cohen_d ( x , y ) . round ( 2 ) stig_int . append ( f ' { x . mean () . round ( 1 ) } ( { x . std () . round ( 1 ) } )' ) stig_ctrl . append ( f ' { y . mean () . round ( 1 ) } ( { y . std () . round ( 1 ) } )' ) t_vals . append ( t_statistic ) p_vals . append ( p_value ) d_vals . append ( d ) impact_df = pd . DataFrame ({ \"Feature\" : features , \"Stigma Reduction Mean (SD)\" : stig_int , \"Attention Control Mean (SD)\" : stig_ctrl , \"t-statistic\" : np . round ( t_vals , 3 ), \"p-value\" : np . round ( p_vals , 3 ), \"Cohen's d-value\" : d_vals }) return impact_df df = pd . read_csv ( 'stigma_supp.csv' ) df = clean_df ( df ) Markdown ( df . head () . to_markdown ()) Race Intentions to prescribe buprenorphine Degree Overall Stigma Difference Willingness to work with OUD Stigma Group Blame Intentions to get waivered Perceived OUD treatment effectiveness Ethnicity Waivered to prescribe buprenorphine Disdain Gender Perceived OUD treatment adherence 0 White 3 MD/DO 5.75 5.33 2 STIG_CTRL 5.5 1 2 Not Hispanic or Latino False 6.33 Male 2 1 White 2 MD/DO 4.5 3.33 3 STIG_INT 5 2 3 Not Hispanic or Latino False 5.33 Male 3 2 White 3 MD/DO 4.88 4.33 3 STIG_CTRL 5 2 3 Not Hispanic or Latino False 5.33 Male 2 3 White 2 MD/DO 4 3.67 2.67 STIG_INT 3.5 2 2 Not Hispanic or Latino False 4.67 Female 3 4 White 3 PA/NP 4.25 4.33 2.67 STIG_INT 3 3 3 Not Hispanic or Latino False 5 Female 2 About The Study \u00b6 The study used by Hooker et. al. for their research was conducted by a nonprofit healthcare organization, HealthPartners, servicing Minnesota and Wisconsin. PCCs who are part of the 15 HealPartners clinics that have access to a CDS tool for identifying and treating people with OUD were invited to participate in the study. The study was a randomized, controlled trial where PCCs recieved one of two trainings: a stigma reduction training or an attention-control training. Following training, the PCCs were assesed at 6 months, 3 months and immediately following completion of the training for their stigma against people with OUD, their intention to get waivered, and their intention to prescribe buprenorphine. Of the 162 PCCs who were eligible, 85 completed both the training and the immediate post training survey (n=46 stigma training and n=39 attention-control training). The stigma reduction training was a series of videos recounting OUD patient narratives, examples of using non-stigmatizing language, and explanantions on how to use a Clincal Decision Support (CDS) tool designed to enable PCCs to screen, diagnose, and treat patients with OUD. The attention-control training controlled for contact, attention, and extra CDS tool training, but did not include the OUD patient narratives or examples of non-stigmatized language. The outcome measures which were used in this analysis were assessed through a survey immediately following training. The relevant primary and secondary outcome measurements were: - OUD Stigma - measured using the Blame , Disdain , and Difference scales and the composite Overall Stigma scale. - Intentions to get waivered or prescribe buprenorphine - measured on a 1-5 scale the likelihood to get waivered to prescribe buprenorphine or to prescribe buprenorphine should a waiver no longer be required. - Willingness to work with people with OUD - measured as the average of 3 questionnaire items (each scaled 1-5) from the Drug Problems Perceptions Questionnaire, where a higher score indicates a greater overall willingness to work with patients with OUD. - Opioid treatment outcome expectations - measured on a scale 1-4 on PCCs expecations for the effectiveness and likelihood of patient adherence to OUD treatment. Demographic Summary Statistics of PCCs who completed stigma or attention control training \u00b6 print_df = make_print_df ( df ) Markdown ( print_df . to_markdown ()) Category All N=85 Stigma reduction n\u2009=\u200946 Attention-control n\u2009=\u200939 0 Gender - Female 57.65% 58.7% 56.41% 1 Gender - Male 36.47% 36.96% 35.9% 2 Gender - Prefer not to answer 4.71% 2.17% 7.69% 3 Gender - Not Listed 1.18% 2.17% 0.0% 0 - - - - 0 Ethnicity - Not Hispanic or Latino 94.12% 97.83% 89.74% 1 Ethnicity - Hispanic or Latino 3.53% 2.17% 5.13% 2 Ethnicity - Missing 2.35% 0.0% 5.13% 0 - - - - 0 Race - White 67.06% 63.04% 71.79% 1 Race - Prefer not to answer 14.12% 15.22% 12.82% 2 Race - Asian 9.41% 13.04% 5.13% 3 Race - Black or African American 7.06% 6.52% 7.69% 4 Race - Multiple selected 1.18% 0.0% 2.56% 5 Race - Some other race 1.18% 2.17% 0.0% 0 - - - - 0 Waivered to prescribe buprenorphine - False 90.59% 93.48% 87.18% 1 Waivered to prescribe buprenorphine - True 9.41% 6.52% 12.82% 0 - - - - 0 Degree - MD/DO 64.71% 65.22% 64.1% 1 Degree - PA/NP 35.29% 34.78% 35.9% In this first table we have a breakdown of the demographic characteristics of the participating PCCs split amongst the two training formats. There are no significant differences between the stigma and attention-control training groups in their demographics, their medical degree type, or their pre-existing waiver to prescribe burprenorphine. Stigma Reduction and Attention-Control Training on Self-Reported Stigma and Intentions to Treat People \u00b6 features = [ 'Overall Stigma' , 'Difference' , 'Disdain' , 'Blame' , 'Intentions to get waivered' , 'Intentions to prescribe buprenorphine' , 'Willingness to work with OUD' , 'Perceived OUD treatment effectiveness' , 'Perceived OUD treatment adherence' ] impact_df = make_impact_df ( df , features ) Markdown ( impact_df . to_markdown ()) Feature Stigma Reduction Mean (SD) Attention Control Mean (SD) t-statistic p-value Cohen's d-value 0 Overall Stigma 4.1 (1.3) 4.2 (1.2) -0.481 0.632 -0.1 1 Difference 3.4 (1.7) 3.1 (1.7) 0.741 0.461 0.16 2 Disdain 4.7 (1.4) 4.9 (1.4) -0.859 0.393 -0.19 3 Blame 4.4 (1.6) 4.8 (1.6) -1.286 0.202 -0.28 4 Intentions to get waivered 2.3 (0.7) 2.1 (0.8) 1.113 0.269 0.26 5 Intentions to prescribe buprenorphine 3.2 (1.0) 3.0 (0.9) 0.899 0.372 0.21 6 Willingness to work with OUD 3.0 (0.7) 3.1 (0.9) -0.828 0.41 -0.18 7 Perceived OUD treatment effectiveness 2.6 (0.8) 2.7 (0.7) -0.745 0.459 -0.16 8 Perceived OUD treatment adherence 2.5 (0.6) 2.4 (0.6) 0.15 0.881 0.03 In the second table we show a number of descriptive statistics for measuring the difference amongst the two training groups in self-reported stigma (Overall Stigma, Difference, Disdain, and Blame), intentions for getting waivered or to prescribe buprenophine if waivered, and perceptions of people with OUD and OUD treatment. The mean and standard deviations for both training groups, as well as, the t-statistic, corresponding p-value, and Cohen's d-value all demonstrate that there are minimal or no significant differences between the two training groups across all measured training outcomes. Correlations among Self-Reported Sitgma and Intentions to Treat People \u00b6 corr_matrix = df [ features ] . corr () . round ( 2 ) mask = np . triu ( np . ones_like ( corr_matrix , dtype = bool )) corr_matrix . columns = [ '1' , '2' , '3' , '4' , '5' , '6' , '7' , '8' , '9' ] Markdown ( corr_matrix . mask ( mask ) . to_markdown ()) 1 2 3 4 5 6 7 8 9 Overall Stigma nan nan nan nan nan nan nan nan nan Difference 0.84 nan nan nan nan nan nan nan nan Disdain 0.79 0.47 nan nan nan nan nan nan nan Blame 0.64 0.31 0.33 nan nan nan nan nan nan Intentions to get waivered -0.25 -0.06 -0.23 -0.35 nan nan nan nan nan Intentions to prescribe buprenorphine -0.25 -0.11 -0.18 -0.35 0.61 nan nan nan nan Willingness to work with OUD -0.4 -0.34 -0.29 -0.34 0.42 0.46 nan nan nan Perceived OUD treatment effectiveness -0.32 -0.19 -0.26 -0.38 0.21 0.29 0.46 nan nan Perceived OUD treatment adherence -0.39 -0.28 -0.31 -0.35 0.17 0.22 0.36 0.62 nan In the final table above, we can see how self-reported stigma, intentions for getting waivered or to prescribe buprenophine if waivered, and perceptions of people with OUD and OUD treatment are related. We use Pearson's correlation coefficients to measure the relation between the measured training outcomes. Unsurprisingly, the components for measuring stigma are strongly, positively correlated. We can also see moderate or high positive correlations between Perceived OUD treatment adherence and treatment effectiveness, between PCCs' intentions to get waivered and to prescribe buprenorphine, and between PCCs' willingness to work with OUD patients and the PCCs intentions to prescribe buprenorphine and their perceived OUD treatment effectiveness/adherence. There is also a slight or moderate negative correlation between PCCs' self-reported stigma and their intensions to work with OUD patients, their percieved OUD treatment effectiveness/adherence, and their intention to get waivered and prescribe buprenorphine. Conclusions \u00b6 The study demonstrated there was little relation between the provided stigma reduction training and PCCs' stigma, future intentions, willingness to work with OUD patients, or PCCs' perception of treatment effectiveness or patient treatment adherence. As was expected, there was a relation amongst PCCs' established stigma and their willingness to work with OUD patients and their perceptions of OUD treatment effectiveness and adherence. Since greater established PCC stigma is shown to inversely relate to PCCs' willingness to treat people with OUD, intentions to prescribe buprenophine, and perceptions regarding treatment effectiveness and patient adherence to treatment, it is important to find more effective intervention methods for reducing stigma. Citations \u00b6 Hooker, Stephanie A et al. \u201cA randomized controlled trial of an intervention to reduce stigma toward people with opioid use disorder among primary care clinicians.\u201d Addiction science & clinical practice vol. 18,1 10. 11 Feb. 2023, doi:10.1186/s13722-023-00366-1 Hooker, S., Rossum, R., Crain, L., Bart, G. \"Reducing Stigma toward People with Opioid Use Disorder among Primary Care Clinicians.\" NIDA Data Share. May 2024, NIDA-CTN-0095A2","title":"Stigma Reduction Among PCCs"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#stigma-reduction-among-primary-care-clinicians-towards-people-with-oud-a-study-and-research-validation-analysis","text":"","title":"Stigma Reduction among Primary Care Clinicians towards People with OUD - A Study and Research Validation Analysis"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#by-j-m-maxwell-data-science-sr-analyst-ctds","text":"","title":"By J M Maxwell - Data Science, Sr. Analyst - CTDS"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#introduction","text":"In this notebook, we\u2019ll be replicating the published analyses by Hooker et al. in A randomized controlled trial of an intervention to reduce stigma toward people with opioid use disorder among primary care clinicians ( PMC9922036 ), in order to demonstrate how users might use these data. These data are available from NIDA Data Share through the HEAL Data Platform. There is an ongoing, dramatic rise in the number of opioid related overdose deaths in the United States, however only a small portion of patients who are diagnosed with Opioid Use Disorders (OUD) seek treatment and recieve medications for OUD (MOUD). MOUDs, like buprenorphine, can be effective forms of treatment for OUD patients, but only a portion of clinicians are waivered to, and in actuality do, prescribe buprenophine. A potential barrier to care for OUD patients may be the stigma held by primary care clinicians (PCCs) towards people with OUD. There are a limited number of interventions available for reducing OUD stigma among PCCs and a need for analytical support for the efficacy of these interventions. A randomized controlled trial of an intervention... examines whether PCCs' stigma towards people with OUD may be reduced and PCCs' intentions to treat OUD patients increased through online training interventions. This work was done exclusively to demonstrate the advantages of the HEAL Platform's Workspace feature and the ability to utilize data that is joined under the HEAL data mesh. While all the work here was completed by J M. Maxwell and members of the HEAL Platform team, this is not original work, and it is exclusively based off of the work completed by Hooker et al. The work here does not represent the official opinions, recommendations, or conclusions of Hooker et al. and this work does not represent policy or medical recommendations on behalf of the authors, the NIH HEAL Initiative, The Center For Translational Data Science, or The University of Chicago. Hooker, Stephanie A et al. \u201cA randomized controlled trial of an intervention to reduce stigma toward people with opioid use disorder among primary care clinicians.\u201d Addiction science & clinical practice vol. 18,1 10. 11 Feb. 2023, doi:10.1186/s13722-023-00366-1","title":"Introduction"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#import-python-libraries","text":"! pip install matplotlib - q ! pip install scikit - learn - q import zipfile import pandas as pd import numpy as np import scipy import matplotlib.pyplot as plt import sklearn from sklearn import metrics from IPython.display import Markdown","title":"Import Python Libraries"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#ingest-and-prepare-data","text":"In this section we ingest and prepare the data. We're particularly interested in the data fields related to the PCCs' attitude towards people with OUD, their attitudes towards treating people with OUD, and their demographic information. ! gen3 drs - pull object dg . H34L / a6c7fc23 - 3534 - 401 c - 88 ca - 9 fbbb495dcf4 {\"succeeded\": [\"dg.H34L/a6c7fc23-3534-401c-88ca-9fbbb495dcf4\"], \"failed\": []} with zipfile . ZipFile ( 'ascii-crf-data-files_nida-ctn-0095a2 v1-1.zip' , 'r' ) as zip_ref : zip_ref . extractall ( '.' ) def clean_df ( df ): col_names = { 'DDBS' : 'Overall Stigma' , 'DDBS_DIFF' : 'Difference' , 'DDBS_DISDAIN' : 'Disdain' , 'DDBS_BLAME2' : 'Blame' , 'INTEND_WAIVER' : 'Intentions to get waivered' , 'INTEND_PRESCRIBE' : 'Intentions to prescribe buprenorphine' , 'WILLWORK' : 'Willingness to work with OUD' , 'TX_EFFECTIVE' : 'Perceived OUD treatment effectiveness' , 'TX_ADHERENCE' : 'Perceived OUD treatment adherence' , 'PCC_AGE' : 'Age' , 'PCC_GENDER' : 'Gender' , 'PCC_RACE' : 'Race' , 'PCC_HISPANIC' : 'Ethnicity' , 'STIGMA_GROUP' : 'Stigma Group' , 'PCC_WAIVERED' : 'Waivered to prescribe buprenorphine' , 'PCC_MD' : 'Degree' } df . rename ( columns = col_names , inplace = True ) for field in [ 'STIG_CLIN_ID' , 'HLTH_SYS_ID' , 'PCC_ID' , 'COMPLETE_TRAINING' , 'COMPLETE_SURVEY' ]: if field in df . columns : df . drop ([ field ], axis = 1 , inplace = True ) df . Gender = df . Gender . fillna ( 7.0 ) df . Ethnicity = df . Ethnicity . fillna ( 7.0 ) df [ 'Race' ] = df . Race . map ({ '5 White' : 'White' , '9 Prefer not to answer' : 'Prefer not to answer' , '2 Asian' : 'Asian' , '3 Black or African American' : 'Black or African American' , '7 Multiple selected' : 'Multiple selected' , '6 Some other race' : 'Some other race' }) df [ 'Gender' ] = df . Gender . map ({ 2.0 : 'Female' , 1.0 : 'Male' , 6.0 : 'Not Listed' , 7.0 : 'Prefer not to answer' }) df [ 'Ethnicity' ] = df . Ethnicity . map ({ 0.0 : 'Not Hispanic or Latino' , 1.0 : 'Hispanic or Latino' , 7.0 : 'Missing' }) df [ 'Waivered to prescribe buprenorphine' ] = df [ 'Waivered to prescribe buprenorphine' ] . map ({ 0 : 'False' , 1 : 'True' }) df [ 'Degree' ] = df . Degree . map ({ 1 : 'MD/DO' , 0 : 'PA/NP' }) keep_list = list ( set ( df . columns ) & set ([ 'Stigma Group' , 'Overall Stigma' , 'Difference' , 'Disdain' , 'Blame' , 'Intentions to get waivered' , 'Intentions to prescribe buprenorphine' , 'Willingness to work with OUD' , 'Perceived OUD treatment effectiveness' , 'Perceived OUD treatment adherence' , 'Waivered to prescribe buprenorphine' , 'Gender' , 'Ethnicity' , 'Race' , 'Degree' ])) df = df [ keep_list ] return df def make_print_df ( df ): features = [ 'Gender' , 'Ethnicity' , 'Race' , 'Waivered to prescribe buprenorphine' , 'Degree' ] all_subj = [] print_df = pd . DataFrame () N_AC = int ( df [ 'Stigma Group' ] . value_counts ()[ 'STIG_CTRL' ]) N_SR = int ( df [ 'Stigma Group' ] . value_counts ()[ 'STIG_INT' ]) N = N_AC + N_SR for feat in features : print_df1 = pd . DataFrame ({ 'Category' : f ' { feat } - ' + df [ feat ] . value_counts () . index , f 'All N= { N } ' : ( 100 * df [ feat ] . value_counts () / len ( df )) . values . round ( 2 )} ) print_df2 = pd . DataFrame ({ 'Category' : f ' { feat } - ' + ( 100 * df [ df [ 'Stigma Group' ] == 'STIG_INT' ][ feat ] . value_counts () / len ( df [ df [ 'Stigma Group' ] == 'STIG_INT' ])) . index , f 'Stigma reduction n\u2009=\u2009 { N_SR } ' : ( 100 * df [ df [ 'Stigma Group' ] == 'STIG_INT' ][ feat ] . value_counts () / len ( df [ df [ 'Stigma Group' ] == 'STIG_INT' ])) . values . round ( 2 )} ) print_df3 = pd . DataFrame ({ 'Category' : f ' { feat } - ' + ( 100 * df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ][ feat ] . value_counts () / len ( df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ])) . index , f 'Attention-control n\u2009=\u2009 { N_AC } ' : ( 100 * df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ][ feat ] . value_counts () / len ( df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ])) . values . round ( 2 )} ) print_df1 = print_df1 . merge ( print_df2 , how = 'left' , on = 'Category' ) print_df1 = print_df1 . merge ( print_df3 , how = 'left' , on = 'Category' ) print_df1 . fillna ( 0 , inplace = True ) print_df1 [[ f 'All N= { N } ' , f 'Stigma reduction n\u2009=\u2009 { N_SR } ' , f 'Attention-control n\u2009=\u2009 { N_AC } ' ]] = print_df1 [[ f 'All N= { N } ' , f 'Stigma reduction n\u2009=\u2009 { N_SR } ' , f 'Attention-control n\u2009=\u2009 { N_AC } ' ]] . astype ( str ) print_df1 [ f 'All N= { N } ' ] = print_df1 [ f 'All N= { N } ' ] . apply ( lambda x : str ( x ) + '%' ) print_df1 [ f 'Stigma reduction n\u2009=\u2009 { N_SR } ' ] = print_df1 [ f 'Stigma reduction n\u2009=\u2009 { N_SR } ' ] . apply ( lambda x : str ( x ) + '%' ) print_df1 [ f 'Attention-control n\u2009=\u2009 { N_AC } ' ] = print_df1 [ f 'Attention-control n\u2009=\u2009 { N_AC } ' ] . apply ( lambda x : str ( x ) + '%' ) print_df = pd . concat ([ print_df , print_df1 ]) if feat != 'Degree' : print_df = pd . concat ([ print_df , pd . DataFrame ({ 'Category' : [ '-' ], f 'All N= { N } ' : [ '-' ], f 'Stigma reduction n\u2009=\u2009 { N_SR } ' : [ '-' ], f 'Attention-control n\u2009=\u2009 { N_AC } ' : [ '-' ] })]) return print_df def make_impact_df ( df , features ): stig_int = [] stig_ctrl = [] t_vals = [] p_vals = [] d_vals = [] def cohen_d ( x , y ): nx = len ( x ) ny = len ( y ) dof = nx + ny - 2 return ( np . mean ( x ) - np . mean ( y )) / np . sqrt ((( nx - 1 ) * np . std ( x , ddof = 1 ) ** 2 + ( ny - 1 ) * np . std ( y , ddof = 1 ) ** 2 ) / dof ) for feat in features : x = df [ df [ 'Stigma Group' ] == 'STIG_INT' ][ feat ] . dropna () y = df [ df [ 'Stigma Group' ] == 'STIG_CTRL' ][ feat ] . dropna () # Perform the t-test t_statistic , p_value = scipy . stats . ttest_ind ( x , y ) d = cohen_d ( x , y ) . round ( 2 ) stig_int . append ( f ' { x . mean () . round ( 1 ) } ( { x . std () . round ( 1 ) } )' ) stig_ctrl . append ( f ' { y . mean () . round ( 1 ) } ( { y . std () . round ( 1 ) } )' ) t_vals . append ( t_statistic ) p_vals . append ( p_value ) d_vals . append ( d ) impact_df = pd . DataFrame ({ \"Feature\" : features , \"Stigma Reduction Mean (SD)\" : stig_int , \"Attention Control Mean (SD)\" : stig_ctrl , \"t-statistic\" : np . round ( t_vals , 3 ), \"p-value\" : np . round ( p_vals , 3 ), \"Cohen's d-value\" : d_vals }) return impact_df df = pd . read_csv ( 'stigma_supp.csv' ) df = clean_df ( df ) Markdown ( df . head () . to_markdown ()) Race Intentions to prescribe buprenorphine Degree Overall Stigma Difference Willingness to work with OUD Stigma Group Blame Intentions to get waivered Perceived OUD treatment effectiveness Ethnicity Waivered to prescribe buprenorphine Disdain Gender Perceived OUD treatment adherence 0 White 3 MD/DO 5.75 5.33 2 STIG_CTRL 5.5 1 2 Not Hispanic or Latino False 6.33 Male 2 1 White 2 MD/DO 4.5 3.33 3 STIG_INT 5 2 3 Not Hispanic or Latino False 5.33 Male 3 2 White 3 MD/DO 4.88 4.33 3 STIG_CTRL 5 2 3 Not Hispanic or Latino False 5.33 Male 2 3 White 2 MD/DO 4 3.67 2.67 STIG_INT 3.5 2 2 Not Hispanic or Latino False 4.67 Female 3 4 White 3 PA/NP 4.25 4.33 2.67 STIG_INT 3 3 3 Not Hispanic or Latino False 5 Female 2","title":"Ingest And Prepare Data"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#about-the-study","text":"The study used by Hooker et. al. for their research was conducted by a nonprofit healthcare organization, HealthPartners, servicing Minnesota and Wisconsin. PCCs who are part of the 15 HealPartners clinics that have access to a CDS tool for identifying and treating people with OUD were invited to participate in the study. The study was a randomized, controlled trial where PCCs recieved one of two trainings: a stigma reduction training or an attention-control training. Following training, the PCCs were assesed at 6 months, 3 months and immediately following completion of the training for their stigma against people with OUD, their intention to get waivered, and their intention to prescribe buprenorphine. Of the 162 PCCs who were eligible, 85 completed both the training and the immediate post training survey (n=46 stigma training and n=39 attention-control training). The stigma reduction training was a series of videos recounting OUD patient narratives, examples of using non-stigmatizing language, and explanantions on how to use a Clincal Decision Support (CDS) tool designed to enable PCCs to screen, diagnose, and treat patients with OUD. The attention-control training controlled for contact, attention, and extra CDS tool training, but did not include the OUD patient narratives or examples of non-stigmatized language. The outcome measures which were used in this analysis were assessed through a survey immediately following training. The relevant primary and secondary outcome measurements were: - OUD Stigma - measured using the Blame , Disdain , and Difference scales and the composite Overall Stigma scale. - Intentions to get waivered or prescribe buprenorphine - measured on a 1-5 scale the likelihood to get waivered to prescribe buprenorphine or to prescribe buprenorphine should a waiver no longer be required. - Willingness to work with people with OUD - measured as the average of 3 questionnaire items (each scaled 1-5) from the Drug Problems Perceptions Questionnaire, where a higher score indicates a greater overall willingness to work with patients with OUD. - Opioid treatment outcome expectations - measured on a scale 1-4 on PCCs expecations for the effectiveness and likelihood of patient adherence to OUD treatment.","title":"About The Study"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#demographic-summary-statistics-of-pccs-who-completed-stigma-or-attention-control-training","text":"print_df = make_print_df ( df ) Markdown ( print_df . to_markdown ()) Category All N=85 Stigma reduction n\u2009=\u200946 Attention-control n\u2009=\u200939 0 Gender - Female 57.65% 58.7% 56.41% 1 Gender - Male 36.47% 36.96% 35.9% 2 Gender - Prefer not to answer 4.71% 2.17% 7.69% 3 Gender - Not Listed 1.18% 2.17% 0.0% 0 - - - - 0 Ethnicity - Not Hispanic or Latino 94.12% 97.83% 89.74% 1 Ethnicity - Hispanic or Latino 3.53% 2.17% 5.13% 2 Ethnicity - Missing 2.35% 0.0% 5.13% 0 - - - - 0 Race - White 67.06% 63.04% 71.79% 1 Race - Prefer not to answer 14.12% 15.22% 12.82% 2 Race - Asian 9.41% 13.04% 5.13% 3 Race - Black or African American 7.06% 6.52% 7.69% 4 Race - Multiple selected 1.18% 0.0% 2.56% 5 Race - Some other race 1.18% 2.17% 0.0% 0 - - - - 0 Waivered to prescribe buprenorphine - False 90.59% 93.48% 87.18% 1 Waivered to prescribe buprenorphine - True 9.41% 6.52% 12.82% 0 - - - - 0 Degree - MD/DO 64.71% 65.22% 64.1% 1 Degree - PA/NP 35.29% 34.78% 35.9% In this first table we have a breakdown of the demographic characteristics of the participating PCCs split amongst the two training formats. There are no significant differences between the stigma and attention-control training groups in their demographics, their medical degree type, or their pre-existing waiver to prescribe burprenorphine.","title":"Demographic Summary Statistics of PCCs who completed stigma or attention control training"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#stigma-reduction-and-attention-control-training-on-self-reported-stigma-and-intentions-to-treat-people","text":"features = [ 'Overall Stigma' , 'Difference' , 'Disdain' , 'Blame' , 'Intentions to get waivered' , 'Intentions to prescribe buprenorphine' , 'Willingness to work with OUD' , 'Perceived OUD treatment effectiveness' , 'Perceived OUD treatment adherence' ] impact_df = make_impact_df ( df , features ) Markdown ( impact_df . to_markdown ()) Feature Stigma Reduction Mean (SD) Attention Control Mean (SD) t-statistic p-value Cohen's d-value 0 Overall Stigma 4.1 (1.3) 4.2 (1.2) -0.481 0.632 -0.1 1 Difference 3.4 (1.7) 3.1 (1.7) 0.741 0.461 0.16 2 Disdain 4.7 (1.4) 4.9 (1.4) -0.859 0.393 -0.19 3 Blame 4.4 (1.6) 4.8 (1.6) -1.286 0.202 -0.28 4 Intentions to get waivered 2.3 (0.7) 2.1 (0.8) 1.113 0.269 0.26 5 Intentions to prescribe buprenorphine 3.2 (1.0) 3.0 (0.9) 0.899 0.372 0.21 6 Willingness to work with OUD 3.0 (0.7) 3.1 (0.9) -0.828 0.41 -0.18 7 Perceived OUD treatment effectiveness 2.6 (0.8) 2.7 (0.7) -0.745 0.459 -0.16 8 Perceived OUD treatment adherence 2.5 (0.6) 2.4 (0.6) 0.15 0.881 0.03 In the second table we show a number of descriptive statistics for measuring the difference amongst the two training groups in self-reported stigma (Overall Stigma, Difference, Disdain, and Blame), intentions for getting waivered or to prescribe buprenophine if waivered, and perceptions of people with OUD and OUD treatment. The mean and standard deviations for both training groups, as well as, the t-statistic, corresponding p-value, and Cohen's d-value all demonstrate that there are minimal or no significant differences between the two training groups across all measured training outcomes.","title":"Stigma Reduction and Attention-Control Training on Self-Reported Stigma and Intentions to Treat People"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#correlations-among-self-reported-sitgma-and-intentions-to-treat-people","text":"corr_matrix = df [ features ] . corr () . round ( 2 ) mask = np . triu ( np . ones_like ( corr_matrix , dtype = bool )) corr_matrix . columns = [ '1' , '2' , '3' , '4' , '5' , '6' , '7' , '8' , '9' ] Markdown ( corr_matrix . mask ( mask ) . to_markdown ()) 1 2 3 4 5 6 7 8 9 Overall Stigma nan nan nan nan nan nan nan nan nan Difference 0.84 nan nan nan nan nan nan nan nan Disdain 0.79 0.47 nan nan nan nan nan nan nan Blame 0.64 0.31 0.33 nan nan nan nan nan nan Intentions to get waivered -0.25 -0.06 -0.23 -0.35 nan nan nan nan nan Intentions to prescribe buprenorphine -0.25 -0.11 -0.18 -0.35 0.61 nan nan nan nan Willingness to work with OUD -0.4 -0.34 -0.29 -0.34 0.42 0.46 nan nan nan Perceived OUD treatment effectiveness -0.32 -0.19 -0.26 -0.38 0.21 0.29 0.46 nan nan Perceived OUD treatment adherence -0.39 -0.28 -0.31 -0.35 0.17 0.22 0.36 0.62 nan In the final table above, we can see how self-reported stigma, intentions for getting waivered or to prescribe buprenophine if waivered, and perceptions of people with OUD and OUD treatment are related. We use Pearson's correlation coefficients to measure the relation between the measured training outcomes. Unsurprisingly, the components for measuring stigma are strongly, positively correlated. We can also see moderate or high positive correlations between Perceived OUD treatment adherence and treatment effectiveness, between PCCs' intentions to get waivered and to prescribe buprenorphine, and between PCCs' willingness to work with OUD patients and the PCCs intentions to prescribe buprenorphine and their perceived OUD treatment effectiveness/adherence. There is also a slight or moderate negative correlation between PCCs' self-reported stigma and their intensions to work with OUD patients, their percieved OUD treatment effectiveness/adherence, and their intention to get waivered and prescribe buprenorphine.","title":"Correlations among Self-Reported Sitgma and Intentions to Treat People"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#conclusions","text":"The study demonstrated there was little relation between the provided stigma reduction training and PCCs' stigma, future intentions, willingness to work with OUD patients, or PCCs' perception of treatment effectiveness or patient treatment adherence. As was expected, there was a relation amongst PCCs' established stigma and their willingness to work with OUD patients and their perceptions of OUD treatment effectiveness and adherence. Since greater established PCC stigma is shown to inversely relate to PCCs' willingness to treat people with OUD, intentions to prescribe buprenophine, and perceptions regarding treatment effectiveness and patient adherence to treatment, it is important to find more effective intervention methods for reducing stigma.","title":"Conclusions"},{"location":"notebooks/Stigma-Reduction-Among_PCCs/#citations","text":"Hooker, Stephanie A et al. \u201cA randomized controlled trial of an intervention to reduce stigma toward people with opioid use disorder among primary care clinicians.\u201d Addiction science & clinical practice vol. 18,1 10. 11 Feb. 2023, doi:10.1186/s13722-023-00366-1 Hooker, S., Rossum, R., Crain, L., Bart, G. \"Reducing Stigma toward People with Opioid Use Disorder among Primary Care Clinicians.\" NIDA Data Share. May 2024, NIDA-CTN-0095A2","title":"Citations"}]}